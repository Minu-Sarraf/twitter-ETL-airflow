[2022-01-03 04:04:46,444] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [queued]>
[2022-01-03 04:04:46,458] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [queued]>
[2022-01-03 04:04:46,458] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-03 04:04:46,458] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-03 04:04:46,458] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-03 04:04:46,476] {taskinstance.py:1259} INFO - Executing <Task(PostgresOperator): tweet_load> on 2021-12-31 03:00:00+00:00
[2022-01-03 04:04:46,483] {standard_task_runner.py:52} INFO - Started process 795 to run task
[2022-01-03 04:04:46,487] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T03:00:00+00:00', '--job-id', '22', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmpdc66hv25', '--error-file', '/tmp/tmpowkfaj58']
[2022-01-03 04:04:46,488] {standard_task_runner.py:77} INFO - Job 22: Subtask tweet_load
[2022-01-03 04:04:46,557] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [running]> on host 2b1d65872a35
[2022-01-03 04:04:46,634] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T03:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T03:00:00+00:00
[2022-01-03 04:04:46,646] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: dev, Login: awsuser, Password: ***, extra: {}
[2022-01-03 04:06:57,524] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/postgres/operators/postgres.py", line 69, in execute
    self.hook.run(self.sql, self.autocommit, parameters=self.parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/hooks/dbapi.py", line 198, in run
    with closing(self.get_conn()) as conn:
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/postgres/hooks/postgres.py", line 115, in get_conn
    self.conn = psycopg2.connect(**conn_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com" (172.31.45.95), port 5439 failed: Connection timed out
	Is the server running on that host and accepting TCP/IP connections?

[2022-01-03 04:06:57,538] {taskinstance.py:1277} INFO - Marking task as FAILED. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T030000, start_date=20220103T040446, end_date=20220103T040657
[2022-01-03 04:06:57,562] {standard_task_runner.py:92} ERROR - Failed to execute job 22 for task tweet_load
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/postgres/operators/postgres.py", line 69, in execute
    self.hook.run(self.sql, self.autocommit, parameters=self.parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/hooks/dbapi.py", line 198, in run
    with closing(self.get_conn()) as conn:
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/postgres/hooks/postgres.py", line 115, in get_conn
    self.conn = psycopg2.connect(**conn_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com" (172.31.45.95), port 5439 failed: Connection timed out
	Is the server running on that host and accepting TCP/IP connections?

[2022-01-03 04:06:57,594] {local_task_job.py:154} INFO - Task exited with return code 1
[2022-01-03 04:06:57,636] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-01-05 05:18:33,744] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [queued]>
[2022-01-05 05:18:33,791] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [queued]>
[2022-01-05 05:18:33,792] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 05:18:33,792] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 05:18:33,792] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 05:18:33,811] {taskinstance.py:1259} INFO - Executing <Task(PostgresOperator): tweet_load> on 2021-12-31 03:00:00+00:00
[2022-01-05 05:18:33,825] {standard_task_runner.py:52} INFO - Started process 2952 to run task
[2022-01-05 05:18:33,839] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T03:00:00+00:00', '--job-id', '44', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmp6p3hwzk7', '--error-file', '/tmp/tmp_wiasax6']
[2022-01-05 05:18:33,841] {standard_task_runner.py:77} INFO - Job 44: Subtask tweet_load
[2022-01-05 05:18:33,991] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [running]> on host 2b1d65872a35
[2022-01-05 05:18:34,092] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T03:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T03:00:00+00:00
[2022-01-05 05:18:34,107] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 05:18:34,520] {dbapi.py:225} INFO - Running statement: select * test, parameters: None
[2022-01-05 05:18:34,637] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/postgres/operators/postgres.py", line 69, in execute
    self.hook.run(self.sql, self.autocommit, parameters=self.parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/hooks/dbapi.py", line 205, in run
    self._run_command(cur, sql_statement, parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/hooks/dbapi.py", line 229, in _run_command
    cur.execute(sql_statement)
psycopg2.errors.SyntaxError: syntax error at or near "test"
LINE 1: select * test
                 ^

[2022-01-05 05:18:34,657] {taskinstance.py:1277} INFO - Marking task as FAILED. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T030000, start_date=20220105T051833, end_date=20220105T051834
[2022-01-05 05:18:34,689] {standard_task_runner.py:92} ERROR - Failed to execute job 44 for task tweet_load
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/postgres/operators/postgres.py", line 69, in execute
    self.hook.run(self.sql, self.autocommit, parameters=self.parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/hooks/dbapi.py", line 205, in run
    self._run_command(cur, sql_statement, parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/hooks/dbapi.py", line 229, in _run_command
    cur.execute(sql_statement)
psycopg2.errors.SyntaxError: syntax error at or near "test"
LINE 1: select * test
                 ^

[2022-01-05 05:18:34,736] {local_task_job.py:154} INFO - Task exited with return code 1
[2022-01-05 05:18:34,928] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-01-05 05:23:15,976] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [queued]>
[2022-01-05 05:23:15,996] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [queued]>
[2022-01-05 05:23:15,996] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 05:23:15,996] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 05:23:15,996] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 05:23:16,018] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 03:00:00+00:00
[2022-01-05 05:23:16,024] {standard_task_runner.py:52} INFO - Started process 3246 to run task
[2022-01-05 05:23:16,032] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T03:00:00+00:00', '--job-id', '74', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmp_902kp_4', '--error-file', '/tmp/tmppd0nqlyy']
[2022-01-05 05:23:16,041] {standard_task_runner.py:77} INFO - Job 74: Subtask tweet_load
[2022-01-05 05:23:16,186] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [running]> on host 2b1d65872a35
[2022-01-05 05:23:16,392] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T03:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T03:00:00+00:00
[2022-01-05 05:23:16,394] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:23:16,395] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:23:16,395] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:23:16,395] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:23:16,395] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:23:16,395] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:23:16,395] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:23:16,396] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:23:16,396] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:23:16,396] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:23:16,396] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:23:16,396] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:23:16,397] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7f88b8fac810>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 03:00:00+00:00: scheduled__2021-12-31T03:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-31', 'prev_ds_nodash': '20211231', 'prev_execution_date': DateTime(2021, 12, 31, 2, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T03:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T03:00:00+00:00', 'ts_nodash': '20211231T030000', 'ts_nodash_with_tz': '20211231T030000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T03:00:00+00:00', 'tsnodash_var': '20211231T030000', 'templates_dict': None}
[2022-01-05 05:23:16,398] {logging_mixin.py:109} INFO - Hello, Current Time:05:23:16 Execution time is 2021-12-31T03:00:00+00:00
[2022-01-05 05:23:16,441] {logging_mixin.py:109} INFO -    Unnamed: 0  ...       location
0           0  ...            NaN
1           1  ...            NaN
2           2  ...            NaN
3           3  ...      UofGuelph
4           4  ...            NaN
5           5  ...  Westbrook, ME
6           6  ...            NaN
7           7  ...            NaN
8           8  ...            NaN
9           9  ...   General Roca

[10 rows x 6 columns]
[2022-01-05 05:23:16,460] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 05:23:16,481] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 05:23:17,019] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2336, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 364, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 778, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 495, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 140, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 137, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 309, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 440, in __init__
    self.__connect(first_connect_check=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 656, in __connect
    connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/strategies.py", line 114, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 508, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com" (3.132.179.48), port 5439 failed: FATAL:  password authentication failed for user "awsuser"
connection to server at "tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com" (3.132.179.48), port 5439 failed: FATAL:  password authentication failed for user "awsuser"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 139, in load_tweets
    df.to_sql('test', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1758, in to_sql
    dtype=dtype,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1650, in prep_table
    table.create()
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 856, in create
    if self.exists():
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 840, in exists
    return self.pd_sql.has_table(self.name, self.schema)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1787, in has_table
    self.connectable.dialect.has_table, name, schema or self.meta.schema
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2211, in run_callable
    with self._contextual_connect() as conn:
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2302, in _contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2340, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1584, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2336, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 364, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 778, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 495, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 140, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 137, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 309, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 440, in __init__
    self.__connect(first_connect_check=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 656, in __connect
    connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/strategies.py", line 114, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 508, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com" (3.132.179.48), port 5439 failed: FATAL:  password authentication failed for user "awsuser"
connection to server at "tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com" (3.132.179.48), port 5439 failed: FATAL:  password authentication failed for user "awsuser"

(Background on this error at: http://sqlalche.me/e/13/e3q8)
[2022-01-05 05:23:17,044] {taskinstance.py:1277} INFO - Marking task as FAILED. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T030000, start_date=20220105T052315, end_date=20220105T052317
[2022-01-05 05:23:17,064] {standard_task_runner.py:92} ERROR - Failed to execute job 74 for task tweet_load
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2336, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 364, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 778, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 495, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 140, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 137, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 309, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 440, in __init__
    self.__connect(first_connect_check=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 656, in __connect
    connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/strategies.py", line 114, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 508, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com" (3.132.179.48), port 5439 failed: FATAL:  password authentication failed for user "awsuser"
connection to server at "tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com" (3.132.179.48), port 5439 failed: FATAL:  password authentication failed for user "awsuser"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 139, in load_tweets
    df.to_sql('test', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1758, in to_sql
    dtype=dtype,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1650, in prep_table
    table.create()
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 856, in create
    if self.exists():
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 840, in exists
    return self.pd_sql.has_table(self.name, self.schema)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1787, in has_table
    self.connectable.dialect.has_table, name, schema or self.meta.schema
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2211, in run_callable
    with self._contextual_connect() as conn:
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2302, in _contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2340, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1584, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2336, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 364, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 778, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 495, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 140, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 137, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 309, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 440, in __init__
    self.__connect(first_connect_check=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 656, in __connect
    connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/strategies.py", line 114, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 508, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com" (3.132.179.48), port 5439 failed: FATAL:  password authentication failed for user "awsuser"
connection to server at "tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com" (3.132.179.48), port 5439 failed: FATAL:  password authentication failed for user "awsuser"

(Background on this error at: http://sqlalche.me/e/13/e3q8)
[2022-01-05 05:23:17,110] {local_task_job.py:154} INFO - Task exited with return code 1
[2022-01-05 05:23:17,227] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-01-05 05:35:11,376] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [queued]>
[2022-01-05 05:35:11,389] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [queued]>
[2022-01-05 05:35:11,389] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 05:35:11,390] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 05:35:11,390] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 05:35:11,404] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 03:00:00+00:00
[2022-01-05 05:35:11,410] {standard_task_runner.py:52} INFO - Started process 229 to run task
[2022-01-05 05:35:11,413] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T03:00:00+00:00', '--job-id', '109', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmpbs7_c0no', '--error-file', '/tmp/tmp10sofnig']
[2022-01-05 05:35:11,414] {standard_task_runner.py:77} INFO - Job 109: Subtask tweet_load
[2022-01-05 05:35:11,461] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [running]> on host 2b1d65872a35
[2022-01-05 05:35:11,515] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T03:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T03:00:00+00:00
[2022-01-05 05:35:11,517] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:35:11,517] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:35:11,517] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:35:11,517] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:35:11,518] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:35:11,518] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:35:11,518] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:35:11,518] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:35:11,518] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:35:11,518] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:35:11,518] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:35:11,518] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:35:11,519] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7fd8b40b1950>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 03:00:00+00:00: scheduled__2021-12-31T03:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-31', 'prev_ds_nodash': '20211231', 'prev_execution_date': DateTime(2021, 12, 31, 2, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T03:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T03:00:00+00:00', 'ts_nodash': '20211231T030000', 'ts_nodash_with_tz': '20211231T030000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T03:00:00+00:00', 'tsnodash_var': '20211231T030000', 'templates_dict': None}
[2022-01-05 05:35:11,519] {logging_mixin.py:109} INFO - Hello, Current Time:05:35:11 Execution time is 2021-12-31T03:00:00+00:00
[2022-01-05 05:35:11,535] {logging_mixin.py:109} INFO -    Unnamed: 0  ...       location
0           0  ...            NaN
1           1  ...            NaN
2           2  ...            NaN
3           3  ...      UofGuelph
4           4  ...            NaN
5           5  ...  Westbrook, ME
6           6  ...            NaN
7           7  ...            NaN
8           8  ...            NaN
9           9  ...   General Roca

[10 rows x 6 columns]
[2022-01-05 05:35:11,544] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 05:35:11,551] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 05:35:14,110] {python.py:175} INFO - Done. Returned value was: None
[2022-01-05 05:35:14,128] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T030000, start_date=20220105T053511, end_date=20220105T053514
[2022-01-05 05:35:14,153] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-01-05 05:35:14,183] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-01-05 05:49:55,331] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [queued]>
[2022-01-05 05:49:55,362] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [queued]>
[2022-01-05 05:49:55,363] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 05:49:55,363] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 05:49:55,363] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 05:49:55,392] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 03:00:00+00:00
[2022-01-05 05:49:55,398] {standard_task_runner.py:52} INFO - Started process 927 to run task
[2022-01-05 05:49:55,406] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T03:00:00+00:00', '--job-id', '128', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmpe_68tu_a', '--error-file', '/tmp/tmpg0_18vg8']
[2022-01-05 05:49:55,409] {standard_task_runner.py:77} INFO - Job 128: Subtask tweet_load
[2022-01-05 05:49:55,574] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [running]> on host 2b1d65872a35
[2022-01-05 05:49:55,662] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T03:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T03:00:00+00:00
[2022-01-05 05:49:55,663] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:49:55,663] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:49:55,664] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:49:55,664] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:49:55,664] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:49:55,664] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:49:55,664] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:49:55,664] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:49:55,664] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:49:55,665] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:49:55,665] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:49:55,665] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:49:55,665] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7fd8b40b1950>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 03:00:00+00:00: scheduled__2021-12-31T03:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-31', 'prev_ds_nodash': '20211231', 'prev_execution_date': DateTime(2021, 12, 31, 2, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T03:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T03:00:00+00:00', 'ts_nodash': '20211231T030000', 'ts_nodash_with_tz': '20211231T030000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T03:00:00+00:00', 'tsnodash_var': '20211231T030000', 'templates_dict': None}
[2022-01-05 05:49:55,666] {logging_mixin.py:109} INFO - Hello, Current Time:05:49:55 Execution time is 2021-12-31T03:00:00+00:00
[2022-01-05 05:49:55,684] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 05:49:55,692] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 05:49:57,082] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
psycopg2.errors.UndefinedColumn: column "unnamed: 0" of relation "tweet" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 133, in load_tweets
    tweet_data.to_sql('tweet', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1770, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1350, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1340, in insert_records
    table.insert(chunksize=chunksize, method=method)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 967, in insert
    exec_insert(conn, keys, chunk_iter)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 882, in _execute_insert
    conn.execute(self.table.insert(), data)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "unnamed: 0" of relation "tweet" does not exist

[SQL: INSERT INTO tweet ("Unnamed: 0", id, created_at, author_id, original_text, location) VALUES (%(Unnamed: 0)s, %(id)s, %(created_at)s, %(author_id)s, %(original_text)s, %(location)s)]
[parameters: ({'Unnamed: 0': 0, 'id': 1476752468910428178, 'created_at': '2021-12-31T03:09:59.000Z', 'author_id': 68825587, 'original_text': 'The vaccines work. Theyve always worked.', 'location': None}, {'Unnamed: 0': 1, 'id': 1476752468906110978, 'created_at': '2021-12-31T03:09:59.000Z', 'author_id': 1265748177698738177, 'original_text': "@DavidLWindt @benmagelsen Hence it's important now to build that natural immunity up before the next round hits.", 'location': 'East Valley'}, {'Unnamed: 0': 2, 'id': 1476752468650381319, 'created_at': '2021-12-31T03:09:59.000Z', 'author_id': 743918830196523008, 'original_text': 'The police seem keen to break up Extinction Rebellion and Insulate Britain protests, along with peaceful vigils held for murder victims, but rather reluctant to do much about Downing St parties, Anti-Vax rallies and protesters smashing up a Covid test centre in Milton Keynes.', 'location': None}, {'Unnamed: 0': 3, 'id': 1476752468642091009, 'created_at': '2021-12-31T03:09:59.000Z', 'author_id': 117772607, 'original_text': 'In case anyone needs to hear it- the COVID numbers youre seeing are likely massively undercounted. Consider all the rapid tests being done at home (meaning, not reported) and hurdles getting confirmatory PCRs tests. Please stay safe folks ', 'location': None}, {'Unnamed: 0': 4, 'id': 1476752468394577923, 'created_at': '2021-12-31T03:09:59.000Z', 'author_id': 1476594801881587715, 'original_text': "Things I've manifested: \n\nAn Xbox Series X within a week\n\nMore communication/specific things with my SP \n\nSick family member w/covid to be better within a week\n\nSmall instant/ day manifestations", 'location': None}, {'Unnamed: 0': 5, 'id': 1476752468394459137, 'created_at': '2021-12-31T03:09:59.000Z', 'author_id': 1873386590, 'original_text': 'The valley of the shadow of death is in fact a Covid ICU', 'location': None}, {'Unnamed: 0': 6, 'id': 1476752468327505924, 'created_at': '2021-12-31T03:09:59.000Z', 'author_id': 1294419039905878016, 'original_text': 'SHOCK REPORT: This Week CDC Quietly Updated COVID-19 Numbers - Only 9,210 Americans Died From COVID-19 Alone - Rest Had Different Other Serious Illnesses https://t.co/Ashimz3zrb via @gatewaypundit', 'location': None}, {'Unnamed: 0': 7, 'id': 1476752468100927508, 'created_at': '2021-12-31T03:09:59.000Z', 'author_id': 1340523219812573185, 'original_text': 'Wul a unu have covid ', 'location': None}, {'Unnamed: 0': 8, 'id': 1476752467933212672, 'created_at': '2021-12-31T03:09:59.000Z', 'author_id': 874654984977043457, 'original_text': 'Case rates in South America, Asia and much of Africa have so far remained relatively low. \n\nRead more  and see a full list of which countries are seeing record case rates this month  here. https://t.co/VMTmb47YJV', 'location': 'Prince Edward Island, Canada'}, {'Unnamed: 0': 9, 'id': 1476752467752857602, 'created_at': '2021-12-31T03:09:59.000Z', 'author_id': 52770562, 'original_text': 'Democracy dies in darkness  https://t.co/9s5ScVyVYx', 'location': None})]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-01-05 05:49:57,139] {taskinstance.py:1277} INFO - Marking task as FAILED. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T030000, start_date=20220105T054955, end_date=20220105T054957
[2022-01-05 05:49:57,322] {standard_task_runner.py:92} ERROR - Failed to execute job 128 for task tweet_load
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
psycopg2.errors.UndefinedColumn: column "unnamed: 0" of relation "tweet" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 133, in load_tweets
    tweet_data.to_sql('tweet', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1770, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1350, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1340, in insert_records
    table.insert(chunksize=chunksize, method=method)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 967, in insert
    exec_insert(conn, keys, chunk_iter)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 882, in _execute_insert
    conn.execute(self.table.insert(), data)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "unnamed: 0" of relation "tweet" does not exist

[SQL: INSERT INTO tweet ("Unnamed: 0", id, created_at, author_id, original_text, location) VALUES (%(Unnamed: 0)s, %(id)s, %(created_at)s, %(author_id)s, %(original_text)s, %(location)s)]
[parameters: ({'Unnamed: 0': 0, 'id': 1476752468910428178, 'created_at': '2021-12-31T03:09:59.000Z', 'author_id': 68825587, 'original_text': 'The vaccines work. Theyve always worked.', 'location': None}, {'Unnamed: 0': 1, 'id': 1476752468906110978, 'created_at': '2021-12-31T03:09:59.000Z', 'author_id': 1265748177698738177, 'original_text': "@DavidLWindt @benmagelsen Hence it's important now to build that natural immunity up before the next round hits.", 'location': 'East Valley'}, {'Unnamed: 0': 2, 'id': 1476752468650381319, 'created_at': '2021-12-31T03:09:59.000Z', 'author_id': 743918830196523008, 'original_text': 'The police seem keen to break up Extinction Rebellion and Insulate Britain protests, along with peaceful vigils held for murder victims, but rather reluctant to do much about Downing St parties, Anti-Vax rallies and protesters smashing up a Covid test centre in Milton Keynes.', 'location': None}, {'Unnamed: 0': 3, 'id': 1476752468642091009, 'created_at': '2021-12-31T03:09:59.000Z', 'author_id': 117772607, 'original_text': 'In case anyone needs to hear it- the COVID numbers youre seeing are likely massively undercounted. Consider all the rapid tests being done at home (meaning, not reported) and hurdles getting confirmatory PCRs tests. Please stay safe folks ', 'location': None}, {'Unnamed: 0': 4, 'id': 1476752468394577923, 'created_at': '2021-12-31T03:09:59.000Z', 'author_id': 1476594801881587715, 'original_text': "Things I've manifested: \n\nAn Xbox Series X within a week\n\nMore communication/specific things with my SP \n\nSick family member w/covid to be better within a week\n\nSmall instant/ day manifestations", 'location': None}, {'Unnamed: 0': 5, 'id': 1476752468394459137, 'created_at': '2021-12-31T03:09:59.000Z', 'author_id': 1873386590, 'original_text': 'The valley of the shadow of death is in fact a Covid ICU', 'location': None}, {'Unnamed: 0': 6, 'id': 1476752468327505924, 'created_at': '2021-12-31T03:09:59.000Z', 'author_id': 1294419039905878016, 'original_text': 'SHOCK REPORT: This Week CDC Quietly Updated COVID-19 Numbers - Only 9,210 Americans Died From COVID-19 Alone - Rest Had Different Other Serious Illnesses https://t.co/Ashimz3zrb via @gatewaypundit', 'location': None}, {'Unnamed: 0': 7, 'id': 1476752468100927508, 'created_at': '2021-12-31T03:09:59.000Z', 'author_id': 1340523219812573185, 'original_text': 'Wul a unu have covid ', 'location': None}, {'Unnamed: 0': 8, 'id': 1476752467933212672, 'created_at': '2021-12-31T03:09:59.000Z', 'author_id': 874654984977043457, 'original_text': 'Case rates in South America, Asia and much of Africa have so far remained relatively low. \n\nRead more  and see a full list of which countries are seeing record case rates this month  here. https://t.co/VMTmb47YJV', 'location': 'Prince Edward Island, Canada'}, {'Unnamed: 0': 9, 'id': 1476752467752857602, 'created_at': '2021-12-31T03:09:59.000Z', 'author_id': 52770562, 'original_text': 'Democracy dies in darkness  https://t.co/9s5ScVyVYx', 'location': None})]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-01-05 05:49:57,372] {local_task_job.py:154} INFO - Task exited with return code 1
[2022-01-05 05:49:57,441] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-01-05 05:51:29,751] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [queued]>
[2022-01-05 05:51:29,771] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [queued]>
[2022-01-05 05:51:29,771] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 05:51:29,771] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 05:51:29,771] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 05:51:29,804] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 03:00:00+00:00
[2022-01-05 05:51:29,817] {standard_task_runner.py:52} INFO - Started process 1052 to run task
[2022-01-05 05:51:29,826] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T03:00:00+00:00', '--job-id', '144', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmpxpzi4_uc', '--error-file', '/tmp/tmpe3g222jj']
[2022-01-05 05:51:29,827] {standard_task_runner.py:77} INFO - Job 144: Subtask tweet_load
[2022-01-05 05:51:29,950] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [running]> on host 2b1d65872a35
[2022-01-05 05:51:30,022] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T03:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T03:00:00+00:00
[2022-01-05 05:51:30,024] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:51:30,024] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:51:30,024] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:51:30,024] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:51:30,024] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:51:30,025] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:51:30,025] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:51:30,025] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:51:30,025] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:51:30,025] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:51:30,025] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:51:30,025] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:51:30,026] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7fd8b40b1950>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 03:00:00+00:00: scheduled__2021-12-31T03:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-31', 'prev_ds_nodash': '20211231', 'prev_execution_date': DateTime(2021, 12, 31, 2, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T03:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T03:00:00+00:00', 'ts_nodash': '20211231T030000', 'ts_nodash_with_tz': '20211231T030000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T03:00:00+00:00', 'tsnodash_var': '20211231T030000', 'templates_dict': None}
[2022-01-05 05:51:30,026] {logging_mixin.py:109} INFO - Hello, Current Time:05:51:30 Execution time is 2021-12-31T03:00:00+00:00
[2022-01-05 05:51:30,044] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 05:51:30,054] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 05:51:31,416] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
psycopg2.errors.UndefinedColumn: column "original_text" of relation "tweet" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 133, in load_tweets
    tweet_data.to_sql('tweet', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1770, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1350, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1340, in insert_records
    table.insert(chunksize=chunksize, method=method)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 967, in insert
    exec_insert(conn, keys, chunk_iter)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 882, in _execute_insert
    conn.execute(self.table.insert(), data)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "original_text" of relation "tweet" does not exist

[SQL: INSERT INTO tweet (created_at, author_id, id, original_text, location) VALUES (%(created_at)s, %(author_id)s, %(id)s, %(original_text)s, %(location)s)]
[parameters: ({'created_at': '2021-12-31T03:09:59.000Z', 'author_id': 68825587, 'id': 1476752468910428178, 'original_text': 'The vaccines work. Theyve always worked.', 'location': None}, {'created_at': '2021-12-31T03:09:59.000Z', 'author_id': 1265748177698738177, 'id': 1476752468906110978, 'original_text': "@DavidLWindt @benmagelsen Hence it's important now to build that natural immunity up before the next round hits.", 'location': 'East Valley'}, {'created_at': '2021-12-31T03:09:59.000Z', 'author_id': 743918830196523008, 'id': 1476752468650381319, 'original_text': 'The police seem keen to break up Extinction Rebellion and Insulate Britain protests, along with peaceful vigils held for murder victims, but rather reluctant to do much about Downing St parties, Anti-Vax rallies and protesters smashing up a Covid test centre in Milton Keynes.', 'location': None}, {'created_at': '2021-12-31T03:09:59.000Z', 'author_id': 117772607, 'id': 1476752468642091009, 'original_text': 'In case anyone needs to hear it- the COVID numbers youre seeing are likely massively undercounted. Consider all the rapid tests being done at home (meaning, not reported) and hurdles getting confirmatory PCRs tests. Please stay safe folks ', 'location': None}, {'created_at': '2021-12-31T03:09:59.000Z', 'author_id': 1476594801881587715, 'id': 1476752468394577923, 'original_text': "Things I've manifested: \n\nAn Xbox Series X within a week\n\nMore communication/specific things with my SP \n\nSick family member w/covid to be better within a week\n\nSmall instant/ day manifestations", 'location': None}, {'created_at': '2021-12-31T03:09:59.000Z', 'author_id': 1873386590, 'id': 1476752468394459137, 'original_text': 'The valley of the shadow of death is in fact a Covid ICU', 'location': None}, {'created_at': '2021-12-31T03:09:59.000Z', 'author_id': 1294419039905878016, 'id': 1476752468327505924, 'original_text': 'SHOCK REPORT: This Week CDC Quietly Updated COVID-19 Numbers - Only 9,210 Americans Died From COVID-19 Alone - Rest Had Different Other Serious Illnesses https://t.co/Ashimz3zrb via @gatewaypundit', 'location': None}, {'created_at': '2021-12-31T03:09:59.000Z', 'author_id': 1340523219812573185, 'id': 1476752468100927508, 'original_text': 'Wul a unu have covid ', 'location': None}, {'created_at': '2021-12-31T03:09:59.000Z', 'author_id': 874654984977043457, 'id': 1476752467933212672, 'original_text': 'Case rates in South America, Asia and much of Africa have so far remained relatively low. \n\nRead more  and see a full list of which countries are seeing record case rates this month  here. https://t.co/VMTmb47YJV', 'location': 'Prince Edward Island, Canada'}, {'created_at': '2021-12-31T03:09:59.000Z', 'author_id': 52770562, 'id': 1476752467752857602, 'original_text': 'Democracy dies in darkness  https://t.co/9s5ScVyVYx', 'location': None})]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-01-05 05:51:31,464] {taskinstance.py:1277} INFO - Marking task as FAILED. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T030000, start_date=20220105T055129, end_date=20220105T055131
[2022-01-05 05:51:31,497] {standard_task_runner.py:92} ERROR - Failed to execute job 144 for task tweet_load
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
psycopg2.errors.UndefinedColumn: column "original_text" of relation "tweet" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 133, in load_tweets
    tweet_data.to_sql('tweet', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1770, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1350, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1340, in insert_records
    table.insert(chunksize=chunksize, method=method)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 967, in insert
    exec_insert(conn, keys, chunk_iter)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 882, in _execute_insert
    conn.execute(self.table.insert(), data)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "original_text" of relation "tweet" does not exist

[SQL: INSERT INTO tweet (created_at, author_id, id, original_text, location) VALUES (%(created_at)s, %(author_id)s, %(id)s, %(original_text)s, %(location)s)]
[parameters: ({'created_at': '2021-12-31T03:09:59.000Z', 'author_id': 68825587, 'id': 1476752468910428178, 'original_text': 'The vaccines work. Theyve always worked.', 'location': None}, {'created_at': '2021-12-31T03:09:59.000Z', 'author_id': 1265748177698738177, 'id': 1476752468906110978, 'original_text': "@DavidLWindt @benmagelsen Hence it's important now to build that natural immunity up before the next round hits.", 'location': 'East Valley'}, {'created_at': '2021-12-31T03:09:59.000Z', 'author_id': 743918830196523008, 'id': 1476752468650381319, 'original_text': 'The police seem keen to break up Extinction Rebellion and Insulate Britain protests, along with peaceful vigils held for murder victims, but rather reluctant to do much about Downing St parties, Anti-Vax rallies and protesters smashing up a Covid test centre in Milton Keynes.', 'location': None}, {'created_at': '2021-12-31T03:09:59.000Z', 'author_id': 117772607, 'id': 1476752468642091009, 'original_text': 'In case anyone needs to hear it- the COVID numbers youre seeing are likely massively undercounted. Consider all the rapid tests being done at home (meaning, not reported) and hurdles getting confirmatory PCRs tests. Please stay safe folks ', 'location': None}, {'created_at': '2021-12-31T03:09:59.000Z', 'author_id': 1476594801881587715, 'id': 1476752468394577923, 'original_text': "Things I've manifested: \n\nAn Xbox Series X within a week\n\nMore communication/specific things with my SP \n\nSick family member w/covid to be better within a week\n\nSmall instant/ day manifestations", 'location': None}, {'created_at': '2021-12-31T03:09:59.000Z', 'author_id': 1873386590, 'id': 1476752468394459137, 'original_text': 'The valley of the shadow of death is in fact a Covid ICU', 'location': None}, {'created_at': '2021-12-31T03:09:59.000Z', 'author_id': 1294419039905878016, 'id': 1476752468327505924, 'original_text': 'SHOCK REPORT: This Week CDC Quietly Updated COVID-19 Numbers - Only 9,210 Americans Died From COVID-19 Alone - Rest Had Different Other Serious Illnesses https://t.co/Ashimz3zrb via @gatewaypundit', 'location': None}, {'created_at': '2021-12-31T03:09:59.000Z', 'author_id': 1340523219812573185, 'id': 1476752468100927508, 'original_text': 'Wul a unu have covid ', 'location': None}, {'created_at': '2021-12-31T03:09:59.000Z', 'author_id': 874654984977043457, 'id': 1476752467933212672, 'original_text': 'Case rates in South America, Asia and much of Africa have so far remained relatively low. \n\nRead more  and see a full list of which countries are seeing record case rates this month  here. https://t.co/VMTmb47YJV', 'location': 'Prince Edward Island, Canada'}, {'created_at': '2021-12-31T03:09:59.000Z', 'author_id': 52770562, 'id': 1476752467752857602, 'original_text': 'Democracy dies in darkness  https://t.co/9s5ScVyVYx', 'location': None})]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-01-05 05:51:31,552] {local_task_job.py:154} INFO - Task exited with return code 1
[2022-01-05 05:51:31,612] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-01-05 06:00:46,319] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [queued]>
[2022-01-05 06:00:46,338] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [queued]>
[2022-01-05 06:00:46,338] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 06:00:46,338] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 06:00:46,338] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 06:00:46,357] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 03:00:00+00:00
[2022-01-05 06:00:46,364] {standard_task_runner.py:52} INFO - Started process 1510 to run task
[2022-01-05 06:00:46,370] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T03:00:00+00:00', '--job-id', '161', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmp6x2r9iuk', '--error-file', '/tmp/tmpu6v6mzfq']
[2022-01-05 06:00:46,371] {standard_task_runner.py:77} INFO - Job 161: Subtask tweet_load
[2022-01-05 06:00:46,496] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [running]> on host 2b1d65872a35
[2022-01-05 06:00:46,662] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T03:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T03:00:00+00:00
[2022-01-05 06:00:46,664] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:00:46,665] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:00:46,665] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:00:46,665] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:00:46,665] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:00:46,666] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:00:46,666] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:00:46,666] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:00:46,666] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:00:46,666] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:00:46,666] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:00:46,667] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:00:46,667] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7fd8b40b1950>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 03:00:00+00:00: scheduled__2021-12-31T03:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-31', 'prev_ds_nodash': '20211231', 'prev_execution_date': DateTime(2021, 12, 31, 2, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T03:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T03:00:00+00:00', 'ts_nodash': '20211231T030000', 'ts_nodash_with_tz': '20211231T030000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T03:00:00+00:00', 'tsnodash_var': '20211231T030000', 'templates_dict': None}
[2022-01-05 06:00:46,667] {logging_mixin.py:109} INFO - Hello, Current Time:06:00:46 Execution time is 2021-12-31T03:00:00+00:00
[2022-01-05 06:00:46,697] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 06:00:46,707] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 06:00:48,106] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
psycopg2.errors.NumericValueOutOfRange: numeric value "1476752468910428178" out of range for integer


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 133, in load_tweets
    tweet_data.to_sql('tweet', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1770, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1350, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1340, in insert_records
    table.insert(chunksize=chunksize, method=method)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 967, in insert
    exec_insert(conn, keys, chunk_iter)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 882, in _execute_insert
    conn.execute(self.table.insert(), data)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
sqlalchemy.exc.DataError: (psycopg2.errors.NumericValueOutOfRange) numeric value "1476752468910428178" out of range for integer

[SQL: INSERT INTO tweet (id, author_id, created_at, original_text, location) VALUES (%(id)s, %(author_id)s, %(created_at)s, %(original_text)s, %(location)s)]
[parameters: ({'id': 1476752468910428178, 'author_id': 68825587, 'created_at': '2021-12-31T03:09:59.000Z', 'original_text': 'The vaccines work. Theyve always worked.', 'location': None}, {'id': 1476752468906110978, 'author_id': 1265748177698738177, 'created_at': '2021-12-31T03:09:59.000Z', 'original_text': "@DavidLWindt @benmagelsen Hence it's important now to build that natural immunity up before the next round hits.", 'location': 'East Valley'}, {'id': 1476752468650381319, 'author_id': 743918830196523008, 'created_at': '2021-12-31T03:09:59.000Z', 'original_text': 'The police seem keen to break up Extinction Rebellion and Insulate Britain protests, along with peaceful vigils held for murder victims, but rather reluctant to do much about Downing St parties, Anti-Vax rallies and protesters smashing up a Covid test centre in Milton Keynes.', 'location': None}, {'id': 1476752468642091009, 'author_id': 117772607, 'created_at': '2021-12-31T03:09:59.000Z', 'original_text': 'In case anyone needs to hear it- the COVID numbers youre seeing are likely massively undercounted. Consider all the rapid tests being done at home (meaning, not reported) and hurdles getting confirmatory PCRs tests. Please stay safe folks ', 'location': None}, {'id': 1476752468394577923, 'author_id': 1476594801881587715, 'created_at': '2021-12-31T03:09:59.000Z', 'original_text': "Things I've manifested: \n\nAn Xbox Series X within a week\n\nMore communication/specific things with my SP \n\nSick family member w/covid to be better within a week\n\nSmall instant/ day manifestations", 'location': None}, {'id': 1476752468394459137, 'author_id': 1873386590, 'created_at': '2021-12-31T03:09:59.000Z', 'original_text': 'The valley of the shadow of death is in fact a Covid ICU', 'location': None}, {'id': 1476752468327505924, 'author_id': 1294419039905878016, 'created_at': '2021-12-31T03:09:59.000Z', 'original_text': 'SHOCK REPORT: This Week CDC Quietly Updated COVID-19 Numbers - Only 9,210 Americans Died From COVID-19 Alone - Rest Had Different Other Serious Illnesses https://t.co/Ashimz3zrb via @gatewaypundit', 'location': None}, {'id': 1476752468100927508, 'author_id': 1340523219812573185, 'created_at': '2021-12-31T03:09:59.000Z', 'original_text': 'Wul a unu have covid ', 'location': None}, {'id': 1476752467933212672, 'author_id': 874654984977043457, 'created_at': '2021-12-31T03:09:59.000Z', 'original_text': 'Case rates in South America, Asia and much of Africa have so far remained relatively low. \n\nRead more  and see a full list of which countries are seeing record case rates this month  here. https://t.co/VMTmb47YJV', 'location': 'Prince Edward Island, Canada'}, {'id': 1476752467752857602, 'author_id': 52770562, 'created_at': '2021-12-31T03:09:59.000Z', 'original_text': 'Democracy dies in darkness  https://t.co/9s5ScVyVYx', 'location': None})]
(Background on this error at: http://sqlalche.me/e/13/9h9h)
[2022-01-05 06:00:48,133] {taskinstance.py:1277} INFO - Marking task as FAILED. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T030000, start_date=20220105T060046, end_date=20220105T060048
[2022-01-05 06:00:48,147] {standard_task_runner.py:92} ERROR - Failed to execute job 161 for task tweet_load
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
psycopg2.errors.NumericValueOutOfRange: numeric value "1476752468910428178" out of range for integer


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 133, in load_tweets
    tweet_data.to_sql('tweet', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1770, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1350, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1340, in insert_records
    table.insert(chunksize=chunksize, method=method)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 967, in insert
    exec_insert(conn, keys, chunk_iter)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 882, in _execute_insert
    conn.execute(self.table.insert(), data)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
sqlalchemy.exc.DataError: (psycopg2.errors.NumericValueOutOfRange) numeric value "1476752468910428178" out of range for integer

[SQL: INSERT INTO tweet (id, author_id, created_at, original_text, location) VALUES (%(id)s, %(author_id)s, %(created_at)s, %(original_text)s, %(location)s)]
[parameters: ({'id': 1476752468910428178, 'author_id': 68825587, 'created_at': '2021-12-31T03:09:59.000Z', 'original_text': 'The vaccines work. Theyve always worked.', 'location': None}, {'id': 1476752468906110978, 'author_id': 1265748177698738177, 'created_at': '2021-12-31T03:09:59.000Z', 'original_text': "@DavidLWindt @benmagelsen Hence it's important now to build that natural immunity up before the next round hits.", 'location': 'East Valley'}, {'id': 1476752468650381319, 'author_id': 743918830196523008, 'created_at': '2021-12-31T03:09:59.000Z', 'original_text': 'The police seem keen to break up Extinction Rebellion and Insulate Britain protests, along with peaceful vigils held for murder victims, but rather reluctant to do much about Downing St parties, Anti-Vax rallies and protesters smashing up a Covid test centre in Milton Keynes.', 'location': None}, {'id': 1476752468642091009, 'author_id': 117772607, 'created_at': '2021-12-31T03:09:59.000Z', 'original_text': 'In case anyone needs to hear it- the COVID numbers youre seeing are likely massively undercounted. Consider all the rapid tests being done at home (meaning, not reported) and hurdles getting confirmatory PCRs tests. Please stay safe folks ', 'location': None}, {'id': 1476752468394577923, 'author_id': 1476594801881587715, 'created_at': '2021-12-31T03:09:59.000Z', 'original_text': "Things I've manifested: \n\nAn Xbox Series X within a week\n\nMore communication/specific things with my SP \n\nSick family member w/covid to be better within a week\n\nSmall instant/ day manifestations", 'location': None}, {'id': 1476752468394459137, 'author_id': 1873386590, 'created_at': '2021-12-31T03:09:59.000Z', 'original_text': 'The valley of the shadow of death is in fact a Covid ICU', 'location': None}, {'id': 1476752468327505924, 'author_id': 1294419039905878016, 'created_at': '2021-12-31T03:09:59.000Z', 'original_text': 'SHOCK REPORT: This Week CDC Quietly Updated COVID-19 Numbers - Only 9,210 Americans Died From COVID-19 Alone - Rest Had Different Other Serious Illnesses https://t.co/Ashimz3zrb via @gatewaypundit', 'location': None}, {'id': 1476752468100927508, 'author_id': 1340523219812573185, 'created_at': '2021-12-31T03:09:59.000Z', 'original_text': 'Wul a unu have covid ', 'location': None}, {'id': 1476752467933212672, 'author_id': 874654984977043457, 'created_at': '2021-12-31T03:09:59.000Z', 'original_text': 'Case rates in South America, Asia and much of Africa have so far remained relatively low. \n\nRead more  and see a full list of which countries are seeing record case rates this month  here. https://t.co/VMTmb47YJV', 'location': 'Prince Edward Island, Canada'}, {'id': 1476752467752857602, 'author_id': 52770562, 'created_at': '2021-12-31T03:09:59.000Z', 'original_text': 'Democracy dies in darkness  https://t.co/9s5ScVyVYx', 'location': None})]
(Background on this error at: http://sqlalche.me/e/13/9h9h)
[2022-01-05 06:00:48,194] {local_task_job.py:154} INFO - Task exited with return code 1
[2022-01-05 06:00:48,231] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-01-05 06:01:48,650] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [queued]>
[2022-01-05 06:01:48,664] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [queued]>
[2022-01-05 06:01:48,665] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 06:01:48,665] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 06:01:48,665] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 06:01:48,680] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 03:00:00+00:00
[2022-01-05 06:01:48,685] {standard_task_runner.py:52} INFO - Started process 1610 to run task
[2022-01-05 06:01:48,689] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T03:00:00+00:00', '--job-id', '180', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmpdezybrwp', '--error-file', '/tmp/tmpfc7a544c']
[2022-01-05 06:01:48,691] {standard_task_runner.py:77} INFO - Job 180: Subtask tweet_load
[2022-01-05 06:01:48,764] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [running]> on host 2b1d65872a35
[2022-01-05 06:01:48,843] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T03:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T03:00:00+00:00
[2022-01-05 06:01:48,846] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:01:48,847] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:01:48,847] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:01:48,848] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:01:48,848] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:01:48,848] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:01:48,848] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:01:48,848] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:01:48,848] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:01:48,848] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:01:48,848] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:01:48,849] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:01:48,849] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7fd8b40b1950>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 03:00:00+00:00: scheduled__2021-12-31T03:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-31', 'prev_ds_nodash': '20211231', 'prev_execution_date': DateTime(2021, 12, 31, 2, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T03:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T03:00:00+00:00', 'ts_nodash': '20211231T030000', 'ts_nodash_with_tz': '20211231T030000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T03:00:00+00:00', 'tsnodash_var': '20211231T030000', 'templates_dict': None}
[2022-01-05 06:01:48,849] {logging_mixin.py:109} INFO - Hello, Current Time:06:01:48 Execution time is 2021-12-31T03:00:00+00:00
[2022-01-05 06:01:48,868] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 06:01:48,880] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 06:01:50,290] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
psycopg2.errors.NumericValueOutOfRange: numeric value "1476752468910428178" out of range for integer


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 133, in load_tweets
    tweet_data.to_sql('tweet', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1770, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1350, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1340, in insert_records
    table.insert(chunksize=chunksize, method=method)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 967, in insert
    exec_insert(conn, keys, chunk_iter)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 882, in _execute_insert
    conn.execute(self.table.insert(), data)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
sqlalchemy.exc.DataError: (psycopg2.errors.NumericValueOutOfRange) numeric value "1476752468910428178" out of range for integer

[SQL: INSERT INTO tweet (author_id, created_at, id, original_text, location) VALUES (%(author_id)s, %(created_at)s, %(id)s, %(original_text)s, %(location)s)]
[parameters: ({'author_id': 68825587, 'created_at': '2021-12-31T03:09:59.000Z', 'id': 1476752468910428178, 'original_text': 'The vaccines work. Theyve always worked.', 'location': None}, {'author_id': 1265748177698738177, 'created_at': '2021-12-31T03:09:59.000Z', 'id': 1476752468906110978, 'original_text': "@DavidLWindt @benmagelsen Hence it's important now to build that natural immunity up before the next round hits.", 'location': 'East Valley'}, {'author_id': 743918830196523008, 'created_at': '2021-12-31T03:09:59.000Z', 'id': 1476752468650381319, 'original_text': 'The police seem keen to break up Extinction Rebellion and Insulate Britain protests, along with peaceful vigils held for murder victims, but rather reluctant to do much about Downing St parties, Anti-Vax rallies and protesters smashing up a Covid test centre in Milton Keynes.', 'location': None}, {'author_id': 117772607, 'created_at': '2021-12-31T03:09:59.000Z', 'id': 1476752468642091009, 'original_text': 'In case anyone needs to hear it- the COVID numbers youre seeing are likely massively undercounted. Consider all the rapid tests being done at home (meaning, not reported) and hurdles getting confirmatory PCRs tests. Please stay safe folks ', 'location': None}, {'author_id': 1476594801881587715, 'created_at': '2021-12-31T03:09:59.000Z', 'id': 1476752468394577923, 'original_text': "Things I've manifested: \n\nAn Xbox Series X within a week\n\nMore communication/specific things with my SP \n\nSick family member w/covid to be better within a week\n\nSmall instant/ day manifestations", 'location': None}, {'author_id': 1873386590, 'created_at': '2021-12-31T03:09:59.000Z', 'id': 1476752468394459137, 'original_text': 'The valley of the shadow of death is in fact a Covid ICU', 'location': None}, {'author_id': 1294419039905878016, 'created_at': '2021-12-31T03:09:59.000Z', 'id': 1476752468327505924, 'original_text': 'SHOCK REPORT: This Week CDC Quietly Updated COVID-19 Numbers - Only 9,210 Americans Died From COVID-19 Alone - Rest Had Different Other Serious Illnesses https://t.co/Ashimz3zrb via @gatewaypundit', 'location': None}, {'author_id': 1340523219812573185, 'created_at': '2021-12-31T03:09:59.000Z', 'id': 1476752468100927508, 'original_text': 'Wul a unu have covid ', 'location': None}, {'author_id': 874654984977043457, 'created_at': '2021-12-31T03:09:59.000Z', 'id': 1476752467933212672, 'original_text': 'Case rates in South America, Asia and much of Africa have so far remained relatively low. \n\nRead more  and see a full list of which countries are seeing record case rates this month  here. https://t.co/VMTmb47YJV', 'location': 'Prince Edward Island, Canada'}, {'author_id': 52770562, 'created_at': '2021-12-31T03:09:59.000Z', 'id': 1476752467752857602, 'original_text': 'Democracy dies in darkness  https://t.co/9s5ScVyVYx', 'location': None})]
(Background on this error at: http://sqlalche.me/e/13/9h9h)
[2022-01-05 06:01:50,304] {taskinstance.py:1277} INFO - Marking task as FAILED. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T030000, start_date=20220105T060148, end_date=20220105T060150
[2022-01-05 06:01:50,318] {standard_task_runner.py:92} ERROR - Failed to execute job 180 for task tweet_load
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
psycopg2.errors.NumericValueOutOfRange: numeric value "1476752468910428178" out of range for integer


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 133, in load_tweets
    tweet_data.to_sql('tweet', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1770, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1350, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1340, in insert_records
    table.insert(chunksize=chunksize, method=method)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 967, in insert
    exec_insert(conn, keys, chunk_iter)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 882, in _execute_insert
    conn.execute(self.table.insert(), data)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
sqlalchemy.exc.DataError: (psycopg2.errors.NumericValueOutOfRange) numeric value "1476752468910428178" out of range for integer

[SQL: INSERT INTO tweet (author_id, created_at, id, original_text, location) VALUES (%(author_id)s, %(created_at)s, %(id)s, %(original_text)s, %(location)s)]
[parameters: ({'author_id': 68825587, 'created_at': '2021-12-31T03:09:59.000Z', 'id': 1476752468910428178, 'original_text': 'The vaccines work. Theyve always worked.', 'location': None}, {'author_id': 1265748177698738177, 'created_at': '2021-12-31T03:09:59.000Z', 'id': 1476752468906110978, 'original_text': "@DavidLWindt @benmagelsen Hence it's important now to build that natural immunity up before the next round hits.", 'location': 'East Valley'}, {'author_id': 743918830196523008, 'created_at': '2021-12-31T03:09:59.000Z', 'id': 1476752468650381319, 'original_text': 'The police seem keen to break up Extinction Rebellion and Insulate Britain protests, along with peaceful vigils held for murder victims, but rather reluctant to do much about Downing St parties, Anti-Vax rallies and protesters smashing up a Covid test centre in Milton Keynes.', 'location': None}, {'author_id': 117772607, 'created_at': '2021-12-31T03:09:59.000Z', 'id': 1476752468642091009, 'original_text': 'In case anyone needs to hear it- the COVID numbers youre seeing are likely massively undercounted. Consider all the rapid tests being done at home (meaning, not reported) and hurdles getting confirmatory PCRs tests. Please stay safe folks ', 'location': None}, {'author_id': 1476594801881587715, 'created_at': '2021-12-31T03:09:59.000Z', 'id': 1476752468394577923, 'original_text': "Things I've manifested: \n\nAn Xbox Series X within a week\n\nMore communication/specific things with my SP \n\nSick family member w/covid to be better within a week\n\nSmall instant/ day manifestations", 'location': None}, {'author_id': 1873386590, 'created_at': '2021-12-31T03:09:59.000Z', 'id': 1476752468394459137, 'original_text': 'The valley of the shadow of death is in fact a Covid ICU', 'location': None}, {'author_id': 1294419039905878016, 'created_at': '2021-12-31T03:09:59.000Z', 'id': 1476752468327505924, 'original_text': 'SHOCK REPORT: This Week CDC Quietly Updated COVID-19 Numbers - Only 9,210 Americans Died From COVID-19 Alone - Rest Had Different Other Serious Illnesses https://t.co/Ashimz3zrb via @gatewaypundit', 'location': None}, {'author_id': 1340523219812573185, 'created_at': '2021-12-31T03:09:59.000Z', 'id': 1476752468100927508, 'original_text': 'Wul a unu have covid ', 'location': None}, {'author_id': 874654984977043457, 'created_at': '2021-12-31T03:09:59.000Z', 'id': 1476752467933212672, 'original_text': 'Case rates in South America, Asia and much of Africa have so far remained relatively low. \n\nRead more  and see a full list of which countries are seeing record case rates this month  here. https://t.co/VMTmb47YJV', 'location': 'Prince Edward Island, Canada'}, {'author_id': 52770562, 'created_at': '2021-12-31T03:09:59.000Z', 'id': 1476752467752857602, 'original_text': 'Democracy dies in darkness  https://t.co/9s5ScVyVYx', 'location': None})]
(Background on this error at: http://sqlalche.me/e/13/9h9h)
[2022-01-05 06:01:50,345] {local_task_job.py:154} INFO - Task exited with return code 1
[2022-01-05 06:01:50,380] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-01-05 06:06:15,042] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [queued]>
[2022-01-05 06:06:15,058] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [queued]>
[2022-01-05 06:06:15,059] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 06:06:15,059] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 06:06:15,059] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 06:06:15,077] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 03:00:00+00:00
[2022-01-05 06:06:15,086] {standard_task_runner.py:52} INFO - Started process 1862 to run task
[2022-01-05 06:06:15,109] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T03:00:00+00:00', '--job-id', '198', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmprd1lk64n', '--error-file', '/tmp/tmp19vb0ctm']
[2022-01-05 06:06:15,110] {standard_task_runner.py:77} INFO - Job 198: Subtask tweet_load
[2022-01-05 06:06:15,256] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [running]> on host 2b1d65872a35
[2022-01-05 06:06:15,445] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T03:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T03:00:00+00:00
[2022-01-05 06:06:15,446] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:06:15,447] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:06:15,447] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:06:15,447] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:06:15,447] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:06:15,447] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:06:15,448] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:06:15,448] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:06:15,450] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:06:15,450] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:06:15,451] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:06:15,451] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:06:15,451] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7fd8b40b1950>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 03:00:00+00:00: scheduled__2021-12-31T03:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-31', 'prev_ds_nodash': '20211231', 'prev_execution_date': DateTime(2021, 12, 31, 2, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T03:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T03:00:00+00:00', 'ts_nodash': '20211231T030000', 'ts_nodash_with_tz': '20211231T030000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T03:00:00+00:00', 'tsnodash_var': '20211231T030000', 'templates_dict': None}
[2022-01-05 06:06:15,452] {logging_mixin.py:109} INFO - Hello, Current Time:06:06:15 Execution time is 2021-12-31T03:00:00+00:00
[2022-01-05 06:06:15,483] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 06:06:15,495] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 06:06:26,860] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
psycopg2.errors.StringDataRightTruncation: value too long for type character varying(200)


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 136, in load_tweets
    tweet_data.to_sql('tweet', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1770, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1350, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1340, in insert_records
    table.insert(chunksize=chunksize, method=method)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 967, in insert
    exec_insert(conn, keys, chunk_iter)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 882, in _execute_insert
    conn.execute(self.table.insert(), data)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
sqlalchemy.exc.DataError: (psycopg2.errors.StringDataRightTruncation) value too long for type character varying(200)

[SQL: INSERT INTO tweet (author_id, created_at, id, original_text, location) VALUES (%(author_id)s, %(created_at)s, %(id)s, %(original_text)s, %(location)s)]
[parameters: ({'author_id': 68825587, 'created_at': '2021-12-31T03:09:59.000Z', 'id': 68825587, 'original_text': 'The vaccines work. Theyve always worked.', 'location': None}, {'author_id': 1265748177698738177, 'created_at': '2021-12-31T03:09:59.000Z', 'id': 1265748177698738177, 'original_text': "@DavidLWindt @benmagelsen Hence it's important now to build that natural immunity up before the next round hits.", 'location': 'East Valley'}, {'author_id': 743918830196523008, 'created_at': '2021-12-31T03:09:59.000Z', 'id': 743918830196523008, 'original_text': 'The police seem keen to break up Extinction Rebellion and Insulate Britain protests, along with peaceful vigils held for murder victims, but rather reluctant to do much about Downing St parties, Anti-Vax rallies and protesters smashing up a Covid test centre in Milton Keynes.', 'location': None}, {'author_id': 117772607, 'created_at': '2021-12-31T03:09:59.000Z', 'id': 117772607, 'original_text': 'In case anyone needs to hear it- the COVID numbers youre seeing are likely massively undercounted. Consider all the rapid tests being done at home (meaning, not reported) and hurdles getting confirmatory PCRs tests. Please stay safe folks ', 'location': None}, {'author_id': 1476594801881587715, 'created_at': '2021-12-31T03:09:59.000Z', 'id': 1476594801881587715, 'original_text': "Things I've manifested: \n\nAn Xbox Series X within a week\n\nMore communication/specific things with my SP \n\nSick family member w/covid to be better within a week\n\nSmall instant/ day manifestations", 'location': None}, {'author_id': 1873386590, 'created_at': '2021-12-31T03:09:59.000Z', 'id': 1873386590, 'original_text': 'The valley of the shadow of death is in fact a Covid ICU', 'location': None}, {'author_id': 1294419039905878016, 'created_at': '2021-12-31T03:09:59.000Z', 'id': 1294419039905878016, 'original_text': 'SHOCK REPORT: This Week CDC Quietly Updated COVID-19 Numbers - Only 9,210 Americans Died From COVID-19 Alone - Rest Had Different Other Serious Illnesses https://t.co/Ashimz3zrb via @gatewaypundit', 'location': None}, {'author_id': 1340523219812573185, 'created_at': '2021-12-31T03:09:59.000Z', 'id': 1340523219812573185, 'original_text': 'Wul a unu have covid ', 'location': None}, {'author_id': 874654984977043457, 'created_at': '2021-12-31T03:09:59.000Z', 'id': 874654984977043457, 'original_text': 'Case rates in South America, Asia and much of Africa have so far remained relatively low. \n\nRead more  and see a full list of which countries are seeing record case rates this month  here. https://t.co/VMTmb47YJV', 'location': 'Prince Edward Island, Canada'}, {'author_id': 52770562, 'created_at': '2021-12-31T03:09:59.000Z', 'id': 52770562, 'original_text': 'Democracy dies in darkness  https://t.co/9s5ScVyVYx', 'location': None})]
(Background on this error at: http://sqlalche.me/e/13/9h9h)
[2022-01-05 06:06:26,872] {taskinstance.py:1277} INFO - Marking task as FAILED. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T030000, start_date=20220105T060615, end_date=20220105T060626
[2022-01-05 06:06:26,883] {standard_task_runner.py:92} ERROR - Failed to execute job 198 for task tweet_load
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
psycopg2.errors.StringDataRightTruncation: value too long for type character varying(200)


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 136, in load_tweets
    tweet_data.to_sql('tweet', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1770, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1350, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1340, in insert_records
    table.insert(chunksize=chunksize, method=method)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 967, in insert
    exec_insert(conn, keys, chunk_iter)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 882, in _execute_insert
    conn.execute(self.table.insert(), data)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
sqlalchemy.exc.DataError: (psycopg2.errors.StringDataRightTruncation) value too long for type character varying(200)

[SQL: INSERT INTO tweet (author_id, created_at, id, original_text, location) VALUES (%(author_id)s, %(created_at)s, %(id)s, %(original_text)s, %(location)s)]
[parameters: ({'author_id': 68825587, 'created_at': '2021-12-31T03:09:59.000Z', 'id': 68825587, 'original_text': 'The vaccines work. Theyve always worked.', 'location': None}, {'author_id': 1265748177698738177, 'created_at': '2021-12-31T03:09:59.000Z', 'id': 1265748177698738177, 'original_text': "@DavidLWindt @benmagelsen Hence it's important now to build that natural immunity up before the next round hits.", 'location': 'East Valley'}, {'author_id': 743918830196523008, 'created_at': '2021-12-31T03:09:59.000Z', 'id': 743918830196523008, 'original_text': 'The police seem keen to break up Extinction Rebellion and Insulate Britain protests, along with peaceful vigils held for murder victims, but rather reluctant to do much about Downing St parties, Anti-Vax rallies and protesters smashing up a Covid test centre in Milton Keynes.', 'location': None}, {'author_id': 117772607, 'created_at': '2021-12-31T03:09:59.000Z', 'id': 117772607, 'original_text': 'In case anyone needs to hear it- the COVID numbers youre seeing are likely massively undercounted. Consider all the rapid tests being done at home (meaning, not reported) and hurdles getting confirmatory PCRs tests. Please stay safe folks ', 'location': None}, {'author_id': 1476594801881587715, 'created_at': '2021-12-31T03:09:59.000Z', 'id': 1476594801881587715, 'original_text': "Things I've manifested: \n\nAn Xbox Series X within a week\n\nMore communication/specific things with my SP \n\nSick family member w/covid to be better within a week\n\nSmall instant/ day manifestations", 'location': None}, {'author_id': 1873386590, 'created_at': '2021-12-31T03:09:59.000Z', 'id': 1873386590, 'original_text': 'The valley of the shadow of death is in fact a Covid ICU', 'location': None}, {'author_id': 1294419039905878016, 'created_at': '2021-12-31T03:09:59.000Z', 'id': 1294419039905878016, 'original_text': 'SHOCK REPORT: This Week CDC Quietly Updated COVID-19 Numbers - Only 9,210 Americans Died From COVID-19 Alone - Rest Had Different Other Serious Illnesses https://t.co/Ashimz3zrb via @gatewaypundit', 'location': None}, {'author_id': 1340523219812573185, 'created_at': '2021-12-31T03:09:59.000Z', 'id': 1340523219812573185, 'original_text': 'Wul a unu have covid ', 'location': None}, {'author_id': 874654984977043457, 'created_at': '2021-12-31T03:09:59.000Z', 'id': 874654984977043457, 'original_text': 'Case rates in South America, Asia and much of Africa have so far remained relatively low. \n\nRead more  and see a full list of which countries are seeing record case rates this month  here. https://t.co/VMTmb47YJV', 'location': 'Prince Edward Island, Canada'}, {'author_id': 52770562, 'created_at': '2021-12-31T03:09:59.000Z', 'id': 52770562, 'original_text': 'Democracy dies in darkness  https://t.co/9s5ScVyVYx', 'location': None})]
(Background on this error at: http://sqlalche.me/e/13/9h9h)
[2022-01-05 06:06:26,907] {local_task_job.py:154} INFO - Task exited with return code 1
[2022-01-05 06:06:26,936] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-01-05 06:09:21,707] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [queued]>
[2022-01-05 06:09:21,727] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [queued]>
[2022-01-05 06:09:21,728] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 06:09:21,728] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 06:09:21,728] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 06:09:21,746] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 03:00:00+00:00
[2022-01-05 06:09:21,755] {standard_task_runner.py:52} INFO - Started process 2055 to run task
[2022-01-05 06:09:21,763] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T03:00:00+00:00', '--job-id', '215', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmponlmdlxg', '--error-file', '/tmp/tmp2261d8f3']
[2022-01-05 06:09:21,764] {standard_task_runner.py:77} INFO - Job 215: Subtask tweet_load
[2022-01-05 06:09:21,895] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [running]> on host 2b1d65872a35
[2022-01-05 06:09:21,996] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T03:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T03:00:00+00:00
[2022-01-05 06:09:22,000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:09:22,001] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:09:22,001] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:09:22,001] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:09:22,001] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:09:22,001] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:09:22,001] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:09:22,002] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:09:22,002] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:09:22,002] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:09:22,002] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:09:22,002] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:09:22,003] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7fd8b40b1950>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 03:00:00+00:00: scheduled__2021-12-31T03:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-31', 'prev_ds_nodash': '20211231', 'prev_execution_date': DateTime(2021, 12, 31, 2, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T03:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T03:00:00+00:00', 'ts_nodash': '20211231T030000', 'ts_nodash_with_tz': '20211231T030000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T03:00:00+00:00', 'tsnodash_var': '20211231T030000', 'templates_dict': None}
[2022-01-05 06:09:22,003] {logging_mixin.py:109} INFO - Hello, Current Time:06:09:21 Execution time is 2021-12-31T03:00:00+00:00
[2022-01-05 06:09:22,024] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 06:09:22,042] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 06:09:23,758] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
psycopg2.errors.StringDataRightTruncation: value too long for type character varying(256)


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 136, in load_tweets
    tweet_data.to_sql('tweet', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1770, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1350, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1340, in insert_records
    table.insert(chunksize=chunksize, method=method)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 967, in insert
    exec_insert(conn, keys, chunk_iter)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 882, in _execute_insert
    conn.execute(self.table.insert(), data)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
sqlalchemy.exc.DataError: (psycopg2.errors.StringDataRightTruncation) value too long for type character varying(256)

[SQL: INSERT INTO tweet (id, author_id, created_at, original_text, location) VALUES (%(id)s, %(author_id)s, %(created_at)s, %(original_text)s, %(location)s)]
[parameters: ({'id': 68825587, 'author_id': 68825587, 'created_at': '2021-12-31T03:09:59.000Z', 'original_text': 'The vaccines work. Theyve always worked.', 'location': None}, {'id': 1265748177698738177, 'author_id': 1265748177698738177, 'created_at': '2021-12-31T03:09:59.000Z', 'original_text': "@DavidLWindt @benmagelsen Hence it's important now to build that natural immunity up before the next round hits.", 'location': 'East Valley'}, {'id': 743918830196523008, 'author_id': 743918830196523008, 'created_at': '2021-12-31T03:09:59.000Z', 'original_text': 'The police seem keen to break up Extinction Rebellion and Insulate Britain protests, along with peaceful vigils held for murder victims, but rather reluctant to do much about Downing St parties, Anti-Vax rallies and protesters smashing up a Covid test centre in Milton Keynes.', 'location': None}, {'id': 117772607, 'author_id': 117772607, 'created_at': '2021-12-31T03:09:59.000Z', 'original_text': 'In case anyone needs to hear it- the COVID numbers youre seeing are likely massively undercounted. Consider all the rapid tests being done at home (meaning, not reported) and hurdles getting confirmatory PCRs tests. Please stay safe folks ', 'location': None}, {'id': 1476594801881587715, 'author_id': 1476594801881587715, 'created_at': '2021-12-31T03:09:59.000Z', 'original_text': "Things I've manifested: \n\nAn Xbox Series X within a week\n\nMore communication/specific things with my SP \n\nSick family member w/covid to be better within a week\n\nSmall instant/ day manifestations", 'location': None}, {'id': 1873386590, 'author_id': 1873386590, 'created_at': '2021-12-31T03:09:59.000Z', 'original_text': 'The valley of the shadow of death is in fact a Covid ICU', 'location': None}, {'id': 1294419039905878016, 'author_id': 1294419039905878016, 'created_at': '2021-12-31T03:09:59.000Z', 'original_text': 'SHOCK REPORT: This Week CDC Quietly Updated COVID-19 Numbers - Only 9,210 Americans Died From COVID-19 Alone - Rest Had Different Other Serious Illnesses https://t.co/Ashimz3zrb via @gatewaypundit', 'location': None}, {'id': 1340523219812573185, 'author_id': 1340523219812573185, 'created_at': '2021-12-31T03:09:59.000Z', 'original_text': 'Wul a unu have covid ', 'location': None}, {'id': 874654984977043457, 'author_id': 874654984977043457, 'created_at': '2021-12-31T03:09:59.000Z', 'original_text': 'Case rates in South America, Asia and much of Africa have so far remained relatively low. \n\nRead more  and see a full list of which countries are seeing record case rates this month  here. https://t.co/VMTmb47YJV', 'location': 'Prince Edward Island, Canada'}, {'id': 52770562, 'author_id': 52770562, 'created_at': '2021-12-31T03:09:59.000Z', 'original_text': 'Democracy dies in darkness  https://t.co/9s5ScVyVYx', 'location': None})]
(Background on this error at: http://sqlalche.me/e/13/9h9h)
[2022-01-05 06:09:23,784] {taskinstance.py:1277} INFO - Marking task as FAILED. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T030000, start_date=20220105T060921, end_date=20220105T060923
[2022-01-05 06:09:23,807] {standard_task_runner.py:92} ERROR - Failed to execute job 215 for task tweet_load
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
psycopg2.errors.StringDataRightTruncation: value too long for type character varying(256)


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 136, in load_tweets
    tweet_data.to_sql('tweet', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1770, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1350, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1340, in insert_records
    table.insert(chunksize=chunksize, method=method)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 967, in insert
    exec_insert(conn, keys, chunk_iter)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 882, in _execute_insert
    conn.execute(self.table.insert(), data)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
sqlalchemy.exc.DataError: (psycopg2.errors.StringDataRightTruncation) value too long for type character varying(256)

[SQL: INSERT INTO tweet (id, author_id, created_at, original_text, location) VALUES (%(id)s, %(author_id)s, %(created_at)s, %(original_text)s, %(location)s)]
[parameters: ({'id': 68825587, 'author_id': 68825587, 'created_at': '2021-12-31T03:09:59.000Z', 'original_text': 'The vaccines work. Theyve always worked.', 'location': None}, {'id': 1265748177698738177, 'author_id': 1265748177698738177, 'created_at': '2021-12-31T03:09:59.000Z', 'original_text': "@DavidLWindt @benmagelsen Hence it's important now to build that natural immunity up before the next round hits.", 'location': 'East Valley'}, {'id': 743918830196523008, 'author_id': 743918830196523008, 'created_at': '2021-12-31T03:09:59.000Z', 'original_text': 'The police seem keen to break up Extinction Rebellion and Insulate Britain protests, along with peaceful vigils held for murder victims, but rather reluctant to do much about Downing St parties, Anti-Vax rallies and protesters smashing up a Covid test centre in Milton Keynes.', 'location': None}, {'id': 117772607, 'author_id': 117772607, 'created_at': '2021-12-31T03:09:59.000Z', 'original_text': 'In case anyone needs to hear it- the COVID numbers youre seeing are likely massively undercounted. Consider all the rapid tests being done at home (meaning, not reported) and hurdles getting confirmatory PCRs tests. Please stay safe folks ', 'location': None}, {'id': 1476594801881587715, 'author_id': 1476594801881587715, 'created_at': '2021-12-31T03:09:59.000Z', 'original_text': "Things I've manifested: \n\nAn Xbox Series X within a week\n\nMore communication/specific things with my SP \n\nSick family member w/covid to be better within a week\n\nSmall instant/ day manifestations", 'location': None}, {'id': 1873386590, 'author_id': 1873386590, 'created_at': '2021-12-31T03:09:59.000Z', 'original_text': 'The valley of the shadow of death is in fact a Covid ICU', 'location': None}, {'id': 1294419039905878016, 'author_id': 1294419039905878016, 'created_at': '2021-12-31T03:09:59.000Z', 'original_text': 'SHOCK REPORT: This Week CDC Quietly Updated COVID-19 Numbers - Only 9,210 Americans Died From COVID-19 Alone - Rest Had Different Other Serious Illnesses https://t.co/Ashimz3zrb via @gatewaypundit', 'location': None}, {'id': 1340523219812573185, 'author_id': 1340523219812573185, 'created_at': '2021-12-31T03:09:59.000Z', 'original_text': 'Wul a unu have covid ', 'location': None}, {'id': 874654984977043457, 'author_id': 874654984977043457, 'created_at': '2021-12-31T03:09:59.000Z', 'original_text': 'Case rates in South America, Asia and much of Africa have so far remained relatively low. \n\nRead more  and see a full list of which countries are seeing record case rates this month  here. https://t.co/VMTmb47YJV', 'location': 'Prince Edward Island, Canada'}, {'id': 52770562, 'author_id': 52770562, 'created_at': '2021-12-31T03:09:59.000Z', 'original_text': 'Democracy dies in darkness  https://t.co/9s5ScVyVYx', 'location': None})]
(Background on this error at: http://sqlalche.me/e/13/9h9h)
[2022-01-05 06:09:23,857] {local_task_job.py:154} INFO - Task exited with return code 1
[2022-01-05 06:09:23,911] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-01-05 06:25:33,848] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [queued]>
[2022-01-05 06:25:33,876] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [queued]>
[2022-01-05 06:25:33,877] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 06:25:33,877] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 06:25:33,877] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 06:25:33,895] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 03:00:00+00:00
[2022-01-05 06:25:33,902] {standard_task_runner.py:52} INFO - Started process 2826 to run task
[2022-01-05 06:25:33,909] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T03:00:00+00:00', '--job-id', '233', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmp15qfy2zl', '--error-file', '/tmp/tmpi7b9hbbd']
[2022-01-05 06:25:33,910] {standard_task_runner.py:77} INFO - Job 233: Subtask tweet_load
[2022-01-05 06:25:33,987] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [running]> on host 2b1d65872a35
[2022-01-05 06:25:34,100] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T03:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T03:00:00+00:00
[2022-01-05 06:25:34,102] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:25:34,103] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:25:34,103] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:25:34,103] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:25:34,103] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:25:34,103] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:25:34,104] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:25:34,104] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:25:34,104] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:25:34,104] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:25:34,104] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:25:34,104] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:25:34,105] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7fd8b40b1950>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 03:00:00+00:00: scheduled__2021-12-31T03:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-31', 'prev_ds_nodash': '20211231', 'prev_execution_date': DateTime(2021, 12, 31, 2, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T03:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T03:00:00+00:00', 'ts_nodash': '20211231T030000', 'ts_nodash_with_tz': '20211231T030000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T03:00:00+00:00', 'tsnodash_var': '20211231T030000', 'templates_dict': None}
[2022-01-05 06:25:34,105] {logging_mixin.py:109} INFO - Hello, Current Time:06:25:34 Execution time is 2021-12-31T03:00:00+00:00
[2022-01-05 06:25:34,175] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 06:25:34,186] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 06:25:35,741] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
psycopg2.errors.StringDataRightTruncation: value too long for type character varying(256)


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 137, in load_tweets
    tweet_data.to_sql('tweet', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1770, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1350, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1340, in insert_records
    table.insert(chunksize=chunksize, method=method)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 967, in insert
    exec_insert(conn, keys, chunk_iter)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 882, in _execute_insert
    conn.execute(self.table.insert(), data)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
sqlalchemy.exc.DataError: (psycopg2.errors.StringDataRightTruncation) value too long for type character varying(256)

[SQL: INSERT INTO tweet (created_at, author_id, id, original_text, location) VALUES (%(created_at)s, %(author_id)s, %(id)s, %(original_text)s, %(location)s)]
[parameters: ({'created_at': '2021-12-31T03:09:59.000Z', 'author_id': 68825587, 'id': 68825587, 'original_text': 'The vaccines work. Theyve always worked.', 'location': None}, {'created_at': '2021-12-31T03:09:59.000Z', 'author_id': 1265748177698738177, 'id': 1265748177698738177, 'original_text': "@DavidLWindt @benmagelsen Hence it's important now to build that natural immunity up before the next round hits.", 'location': 'East Valley'}, {'created_at': '2021-12-31T03:09:59.000Z', 'author_id': 743918830196523008, 'id': 743918830196523008, 'original_text': 'The police seem keen to break up Extinction Rebellion and Insulate Britain protests, along with peaceful vigils held for murder victims, but rather reluctant to do much about Downing St parties, Anti-Vax rallies and protesters smashing up a Covid test centre in Milton Keynes.', 'location': None}, {'created_at': '2021-12-31T03:09:59.000Z', 'author_id': 117772607, 'id': 117772607, 'original_text': 'In case anyone needs to hear it- the COVID numbers youre seeing are likely massively undercounted. Consider all the rapid tests being done at home (meaning, not reported) and hurdles getting confirmatory PCRs tests. Please stay safe folks ', 'location': None}, {'created_at': '2021-12-31T03:09:59.000Z', 'author_id': 1476594801881587715, 'id': 1476594801881587715, 'original_text': "Things I've manifested: \n\nAn Xbox Series X within a week\n\nMore communication/specific things with my SP \n\nSick family member w/covid to be better within a week\n\nSmall instant/ day manifestations", 'location': None}, {'created_at': '2021-12-31T03:09:59.000Z', 'author_id': 1873386590, 'id': 1873386590, 'original_text': 'The valley of the shadow of death is in fact a Covid ICU', 'location': None}, {'created_at': '2021-12-31T03:09:59.000Z', 'author_id': 1294419039905878016, 'id': 1294419039905878016, 'original_text': 'SHOCK REPORT: This Week CDC Quietly Updated COVID-19 Numbers - Only 9,210 Americans Died From COVID-19 Alone - Rest Had Different Other Serious Illnesses https://t.co/Ashimz3zrb via @gatewaypundit', 'location': None}, {'created_at': '2021-12-31T03:09:59.000Z', 'author_id': 1340523219812573185, 'id': 1340523219812573185, 'original_text': 'Wul a unu have covid ', 'location': None}, {'created_at': '2021-12-31T03:09:59.000Z', 'author_id': 874654984977043457, 'id': 874654984977043457, 'original_text': 'Case rates in South America, Asia and much of Africa have so far remained relatively low. \n\nRead more  and see a full list of which countries are seeing record case rates this month  here. https://t.co/VMTmb47YJV', 'location': 'Prince Edward Island, Canada'}, {'created_at': '2021-12-31T03:09:59.000Z', 'author_id': 52770562, 'id': 52770562, 'original_text': 'Democracy dies in darkness  https://t.co/9s5ScVyVYx', 'location': None})]
(Background on this error at: http://sqlalche.me/e/13/9h9h)
[2022-01-05 06:25:35,755] {taskinstance.py:1277} INFO - Marking task as FAILED. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T030000, start_date=20220105T062533, end_date=20220105T062535
[2022-01-05 06:25:35,769] {standard_task_runner.py:92} ERROR - Failed to execute job 233 for task tweet_load
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
psycopg2.errors.StringDataRightTruncation: value too long for type character varying(256)


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 137, in load_tweets
    tweet_data.to_sql('tweet', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1770, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1350, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1340, in insert_records
    table.insert(chunksize=chunksize, method=method)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 967, in insert
    exec_insert(conn, keys, chunk_iter)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 882, in _execute_insert
    conn.execute(self.table.insert(), data)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
sqlalchemy.exc.DataError: (psycopg2.errors.StringDataRightTruncation) value too long for type character varying(256)

[SQL: INSERT INTO tweet (created_at, author_id, id, original_text, location) VALUES (%(created_at)s, %(author_id)s, %(id)s, %(original_text)s, %(location)s)]
[parameters: ({'created_at': '2021-12-31T03:09:59.000Z', 'author_id': 68825587, 'id': 68825587, 'original_text': 'The vaccines work. Theyve always worked.', 'location': None}, {'created_at': '2021-12-31T03:09:59.000Z', 'author_id': 1265748177698738177, 'id': 1265748177698738177, 'original_text': "@DavidLWindt @benmagelsen Hence it's important now to build that natural immunity up before the next round hits.", 'location': 'East Valley'}, {'created_at': '2021-12-31T03:09:59.000Z', 'author_id': 743918830196523008, 'id': 743918830196523008, 'original_text': 'The police seem keen to break up Extinction Rebellion and Insulate Britain protests, along with peaceful vigils held for murder victims, but rather reluctant to do much about Downing St parties, Anti-Vax rallies and protesters smashing up a Covid test centre in Milton Keynes.', 'location': None}, {'created_at': '2021-12-31T03:09:59.000Z', 'author_id': 117772607, 'id': 117772607, 'original_text': 'In case anyone needs to hear it- the COVID numbers youre seeing are likely massively undercounted. Consider all the rapid tests being done at home (meaning, not reported) and hurdles getting confirmatory PCRs tests. Please stay safe folks ', 'location': None}, {'created_at': '2021-12-31T03:09:59.000Z', 'author_id': 1476594801881587715, 'id': 1476594801881587715, 'original_text': "Things I've manifested: \n\nAn Xbox Series X within a week\n\nMore communication/specific things with my SP \n\nSick family member w/covid to be better within a week\n\nSmall instant/ day manifestations", 'location': None}, {'created_at': '2021-12-31T03:09:59.000Z', 'author_id': 1873386590, 'id': 1873386590, 'original_text': 'The valley of the shadow of death is in fact a Covid ICU', 'location': None}, {'created_at': '2021-12-31T03:09:59.000Z', 'author_id': 1294419039905878016, 'id': 1294419039905878016, 'original_text': 'SHOCK REPORT: This Week CDC Quietly Updated COVID-19 Numbers - Only 9,210 Americans Died From COVID-19 Alone - Rest Had Different Other Serious Illnesses https://t.co/Ashimz3zrb via @gatewaypundit', 'location': None}, {'created_at': '2021-12-31T03:09:59.000Z', 'author_id': 1340523219812573185, 'id': 1340523219812573185, 'original_text': 'Wul a unu have covid ', 'location': None}, {'created_at': '2021-12-31T03:09:59.000Z', 'author_id': 874654984977043457, 'id': 874654984977043457, 'original_text': 'Case rates in South America, Asia and much of Africa have so far remained relatively low. \n\nRead more  and see a full list of which countries are seeing record case rates this month  here. https://t.co/VMTmb47YJV', 'location': 'Prince Edward Island, Canada'}, {'created_at': '2021-12-31T03:09:59.000Z', 'author_id': 52770562, 'id': 52770562, 'original_text': 'Democracy dies in darkness  https://t.co/9s5ScVyVYx', 'location': None})]
(Background on this error at: http://sqlalche.me/e/13/9h9h)
[2022-01-05 06:25:35,810] {local_task_job.py:154} INFO - Task exited with return code 1
[2022-01-05 06:25:35,842] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-01-05 06:28:27,871] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [queued]>
[2022-01-05 06:28:27,891] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [queued]>
[2022-01-05 06:28:27,891] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 06:28:27,891] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 06:28:27,891] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 06:28:27,910] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 03:00:00+00:00
[2022-01-05 06:28:27,922] {standard_task_runner.py:52} INFO - Started process 3007 to run task
[2022-01-05 06:28:27,928] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T03:00:00+00:00', '--job-id', '252', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmplx7vvqty', '--error-file', '/tmp/tmp_b7no5js']
[2022-01-05 06:28:27,929] {standard_task_runner.py:77} INFO - Job 252: Subtask tweet_load
[2022-01-05 06:28:28,005] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [running]> on host 2b1d65872a35
[2022-01-05 06:28:28,085] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T03:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T03:00:00+00:00
[2022-01-05 06:28:28,089] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:28:28,089] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:28:28,090] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:28:28,090] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:28:28,090] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:28:28,090] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:28:28,090] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:28:28,090] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:28:28,090] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:28:28,090] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:28:28,090] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:28:28,091] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:28:28,091] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7fd8b40b1950>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 03:00:00+00:00: scheduled__2021-12-31T03:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-31', 'prev_ds_nodash': '20211231', 'prev_execution_date': DateTime(2021, 12, 31, 2, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T03:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T03:00:00+00:00', 'ts_nodash': '20211231T030000', 'ts_nodash_with_tz': '20211231T030000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T03:00:00+00:00', 'tsnodash_var': '20211231T030000', 'templates_dict': None}
[2022-01-05 06:28:28,091] {logging_mixin.py:109} INFO - Hello, Current Time:06:28:28 Execution time is 2021-12-31T03:00:00+00:00
[2022-01-05 06:28:28,113] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 06:28:28,125] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 06:28:29,836] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
psycopg2.errors.StringDataRightTruncation: value too long for type character varying(256)


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 139, in load_tweets
    tweet_data.to_sql('tweet', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1770, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1350, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1340, in insert_records
    table.insert(chunksize=chunksize, method=method)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 967, in insert
    exec_insert(conn, keys, chunk_iter)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 882, in _execute_insert
    conn.execute(self.table.insert(), data)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
sqlalchemy.exc.DataError: (psycopg2.errors.StringDataRightTruncation) value too long for type character varying(256)

[SQL: INSERT INTO tweet (id, author_id, created_at, original_text, location) VALUES (%(id)s, %(author_id)s, %(created_at)s, %(original_text)s, %(location)s)]
[parameters: ({'id': 68825587, 'author_id': 68825587, 'created_at': '2021-12-31T03:09:59.000Z', 'original_text': 'The vaccines work. Theyve always worked.', 'location': None}, {'id': 1265748177698738177, 'author_id': 1265748177698738177, 'created_at': '2021-12-31T03:09:59.000Z', 'original_text': "@DavidLWindt @benmagelsen Hence it's important now to build that natural immunity up before the next round hits.", 'location': 'East Valley'}, {'id': 743918830196523008, 'author_id': 743918830196523008, 'created_at': '2021-12-31T03:09:59.000Z', 'original_text': 'The police seem keen to break up Extinction Rebellion and Insulate Britain protests, along with peaceful vigils held for murder victims, but rather reluctant to do much about Downing St parties, Anti-Vax rallies and protesters smashing up a Covid test centre in Milton Keynes.', 'location': None}, {'id': 117772607, 'author_id': 117772607, 'created_at': '2021-12-31T03:09:59.000Z', 'original_text': 'In case anyone needs to hear it- the COVID numbers youre seeing are likely massively undercounted. Consider all the rapid tests being done at home (meaning, not reported) and hurdles getting confirmatory PCRs tests. Please stay safe folks ', 'location': None}, {'id': 1476594801881587715, 'author_id': 1476594801881587715, 'created_at': '2021-12-31T03:09:59.000Z', 'original_text': "Things I've manifested: \n\nAn Xbox Series X within a week\n\nMore communication/specific things with my SP \n\nSick family member w/covid to be better within a week\n\nSmall instant/ day manifestations", 'location': None}, {'id': 1873386590, 'author_id': 1873386590, 'created_at': '2021-12-31T03:09:59.000Z', 'original_text': 'The valley of the shadow of death is in fact a Covid ICU', 'location': None}, {'id': 1294419039905878016, 'author_id': 1294419039905878016, 'created_at': '2021-12-31T03:09:59.000Z', 'original_text': 'SHOCK REPORT: This Week CDC Quietly Updated COVID-19 Numbers - Only 9,210 Americans Died From COVID-19 Alone - Rest Had Different Other Serious Illnesses https://t.co/Ashimz3zrb via @gatewaypundit', 'location': None}, {'id': 1340523219812573185, 'author_id': 1340523219812573185, 'created_at': '2021-12-31T03:09:59.000Z', 'original_text': 'Wul a unu have covid ', 'location': None}, {'id': 874654984977043457, 'author_id': 874654984977043457, 'created_at': '2021-12-31T03:09:59.000Z', 'original_text': 'Case rates in South America, Asia and much of Africa have so far remained relatively low. \n\nRead more  and see a full list of which countries are seeing record case rates this month  here. https://t.co/VMTmb47YJV', 'location': 'Prince Edward Island, Canada'}, {'id': 52770562, 'author_id': 52770562, 'created_at': '2021-12-31T03:09:59.000Z', 'original_text': 'Democracy dies in darkness  https://t.co/9s5ScVyVYx', 'location': None})]
(Background on this error at: http://sqlalche.me/e/13/9h9h)
[2022-01-05 06:28:29,873] {taskinstance.py:1277} INFO - Marking task as FAILED. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T030000, start_date=20220105T062827, end_date=20220105T062829
[2022-01-05 06:28:29,893] {standard_task_runner.py:92} ERROR - Failed to execute job 252 for task tweet_load
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
psycopg2.errors.StringDataRightTruncation: value too long for type character varying(256)


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 139, in load_tweets
    tweet_data.to_sql('tweet', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1770, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1350, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1340, in insert_records
    table.insert(chunksize=chunksize, method=method)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 967, in insert
    exec_insert(conn, keys, chunk_iter)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 882, in _execute_insert
    conn.execute(self.table.insert(), data)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
sqlalchemy.exc.DataError: (psycopg2.errors.StringDataRightTruncation) value too long for type character varying(256)

[SQL: INSERT INTO tweet (id, author_id, created_at, original_text, location) VALUES (%(id)s, %(author_id)s, %(created_at)s, %(original_text)s, %(location)s)]
[parameters: ({'id': 68825587, 'author_id': 68825587, 'created_at': '2021-12-31T03:09:59.000Z', 'original_text': 'The vaccines work. Theyve always worked.', 'location': None}, {'id': 1265748177698738177, 'author_id': 1265748177698738177, 'created_at': '2021-12-31T03:09:59.000Z', 'original_text': "@DavidLWindt @benmagelsen Hence it's important now to build that natural immunity up before the next round hits.", 'location': 'East Valley'}, {'id': 743918830196523008, 'author_id': 743918830196523008, 'created_at': '2021-12-31T03:09:59.000Z', 'original_text': 'The police seem keen to break up Extinction Rebellion and Insulate Britain protests, along with peaceful vigils held for murder victims, but rather reluctant to do much about Downing St parties, Anti-Vax rallies and protesters smashing up a Covid test centre in Milton Keynes.', 'location': None}, {'id': 117772607, 'author_id': 117772607, 'created_at': '2021-12-31T03:09:59.000Z', 'original_text': 'In case anyone needs to hear it- the COVID numbers youre seeing are likely massively undercounted. Consider all the rapid tests being done at home (meaning, not reported) and hurdles getting confirmatory PCRs tests. Please stay safe folks ', 'location': None}, {'id': 1476594801881587715, 'author_id': 1476594801881587715, 'created_at': '2021-12-31T03:09:59.000Z', 'original_text': "Things I've manifested: \n\nAn Xbox Series X within a week\n\nMore communication/specific things with my SP \n\nSick family member w/covid to be better within a week\n\nSmall instant/ day manifestations", 'location': None}, {'id': 1873386590, 'author_id': 1873386590, 'created_at': '2021-12-31T03:09:59.000Z', 'original_text': 'The valley of the shadow of death is in fact a Covid ICU', 'location': None}, {'id': 1294419039905878016, 'author_id': 1294419039905878016, 'created_at': '2021-12-31T03:09:59.000Z', 'original_text': 'SHOCK REPORT: This Week CDC Quietly Updated COVID-19 Numbers - Only 9,210 Americans Died From COVID-19 Alone - Rest Had Different Other Serious Illnesses https://t.co/Ashimz3zrb via @gatewaypundit', 'location': None}, {'id': 1340523219812573185, 'author_id': 1340523219812573185, 'created_at': '2021-12-31T03:09:59.000Z', 'original_text': 'Wul a unu have covid ', 'location': None}, {'id': 874654984977043457, 'author_id': 874654984977043457, 'created_at': '2021-12-31T03:09:59.000Z', 'original_text': 'Case rates in South America, Asia and much of Africa have so far remained relatively low. \n\nRead more  and see a full list of which countries are seeing record case rates this month  here. https://t.co/VMTmb47YJV', 'location': 'Prince Edward Island, Canada'}, {'id': 52770562, 'author_id': 52770562, 'created_at': '2021-12-31T03:09:59.000Z', 'original_text': 'Democracy dies in darkness  https://t.co/9s5ScVyVYx', 'location': None})]
(Background on this error at: http://sqlalche.me/e/13/9h9h)
[2022-01-05 06:28:29,931] {local_task_job.py:154} INFO - Task exited with return code 1
[2022-01-05 06:28:29,984] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-01-05 06:31:59,671] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [queued]>
[2022-01-05 06:31:59,707] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [queued]>
[2022-01-05 06:31:59,707] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 06:31:59,707] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 06:31:59,707] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 06:31:59,750] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 03:00:00+00:00
[2022-01-05 06:31:59,767] {standard_task_runner.py:52} INFO - Started process 3212 to run task
[2022-01-05 06:31:59,773] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T03:00:00+00:00', '--job-id', '265', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmpk2fwftv2', '--error-file', '/tmp/tmpdqj_d6ql']
[2022-01-05 06:31:59,775] {standard_task_runner.py:77} INFO - Job 265: Subtask tweet_load
[2022-01-05 06:32:00,091] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [running]> on host 2b1d65872a35
[2022-01-05 06:32:00,333] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T03:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T03:00:00+00:00
[2022-01-05 06:32:00,342] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:32:00,342] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:32:00,342] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:32:00,352] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:32:00,352] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:32:00,352] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:32:00,352] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:32:00,352] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:32:00,353] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:32:00,353] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:32:00,353] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:32:00,353] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:32:00,353] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7fd8b40b1950>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 03:00:00+00:00: scheduled__2021-12-31T03:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-31', 'prev_ds_nodash': '20211231', 'prev_execution_date': DateTime(2021, 12, 31, 2, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T03:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T03:00:00+00:00', 'ts_nodash': '20211231T030000', 'ts_nodash_with_tz': '20211231T030000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T03:00:00+00:00', 'tsnodash_var': '20211231T030000', 'templates_dict': None}
[2022-01-05 06:32:00,354] {logging_mixin.py:109} INFO - Hello, Current Time:06:32:00 Execution time is 2021-12-31T03:00:00+00:00
[2022-01-05 06:32:00,428] {warnings.py:110} WARNING - /opt/***/dags/load_redshift.py:137: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only
  tweet_data = tweet_data.drop('original_text', 1)

[2022-01-05 06:32:00,641] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 06:32:00,666] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 06:32:14,103] {python.py:175} INFO - Done. Returned value was: None
[2022-01-05 06:32:14,191] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T030000, start_date=20220105T063159, end_date=20220105T063214
[2022-01-05 06:32:14,219] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-01-05 06:32:14,259] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-01-05 07:02:30,912] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [queued]>
[2022-01-05 07:02:30,941] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [queued]>
[2022-01-05 07:02:30,941] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 07:02:30,941] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 07:02:30,941] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 07:02:30,980] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 03:00:00+00:00
[2022-01-05 07:02:30,987] {standard_task_runner.py:52} INFO - Started process 120 to run task
[2022-01-05 07:02:31,011] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T03:00:00+00:00', '--job-id', '323', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmp75ix2zxf', '--error-file', '/tmp/tmp5b8s60c2']
[2022-01-05 07:02:31,012] {standard_task_runner.py:77} INFO - Job 323: Subtask tweet_load
[2022-01-05 07:02:31,230] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [running]> on host e544fdb7c66e
[2022-01-05 07:02:31,432] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T03:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T03:00:00+00:00
[2022-01-05 07:02:31,434] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:02:31,434] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:02:31,435] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:02:31,435] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:02:31,435] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:02:31,435] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:02:31,435] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:02:31,436] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:02:31,436] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:02:31,436] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:02:31,436] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:02:31,437] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:02:31,438] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7fa6a9eda8d0>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 03:00:00+00:00: scheduled__2021-12-31T03:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-31', 'prev_ds_nodash': '20211231', 'prev_execution_date': DateTime(2021, 12, 31, 2, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T03:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T03:00:00+00:00', 'ts_nodash': '20211231T030000', 'ts_nodash_with_tz': '20211231T030000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T03:00:00+00:00', 'tsnodash_var': '20211231T030000', 'templates_dict': None}
[2022-01-05 07:02:31,438] {logging_mixin.py:109} INFO - Hello, Current Time:07:02:31 Execution time is 2021-12-31T03:00:00+00:00
[2022-01-05 07:02:31,465] {warnings.py:110} WARNING - /opt/***/dags/load_redshift.py:137: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only
  tweet_data = tweet_data.drop('original_text', 1)

[2022-01-05 07:02:31,559] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 07:02:31,577] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 07:02:33,837] {python.py:175} INFO - Done. Returned value was: None
[2022-01-05 07:02:33,846] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T030000, start_date=20220105T070230, end_date=20220105T070233
[2022-01-05 07:02:33,871] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-01-05 07:02:33,905] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-01-05 07:04:27,403] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [queued]>
[2022-01-05 07:04:27,417] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [queued]>
[2022-01-05 07:04:27,417] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 07:04:27,417] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 07:04:27,417] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 07:04:27,433] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 03:00:00+00:00
[2022-01-05 07:04:27,442] {standard_task_runner.py:52} INFO - Started process 259 to run task
[2022-01-05 07:04:27,446] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T03:00:00+00:00', '--job-id', '343', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmplu6ptfsz', '--error-file', '/tmp/tmpdyrf3v38']
[2022-01-05 07:04:27,447] {standard_task_runner.py:77} INFO - Job 343: Subtask tweet_load
[2022-01-05 07:04:27,514] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [running]> on host e544fdb7c66e
[2022-01-05 07:04:27,588] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T03:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T03:00:00+00:00
[2022-01-05 07:04:27,590] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:04:27,591] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:04:27,591] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:04:27,591] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:04:27,591] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:04:27,591] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:04:27,591] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:04:27,591] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:04:27,591] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:04:27,592] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:04:27,592] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:04:27,592] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:04:27,592] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7fa6a9eda8d0>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 03:00:00+00:00: scheduled__2021-12-31T03:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-31', 'prev_ds_nodash': '20211231', 'prev_execution_date': DateTime(2021, 12, 31, 2, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T03:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T03:00:00+00:00', 'ts_nodash': '20211231T030000', 'ts_nodash_with_tz': '20211231T030000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T03:00:00+00:00', 'tsnodash_var': '20211231T030000', 'templates_dict': None}
[2022-01-05 07:04:27,592] {logging_mixin.py:109} INFO - Hello, Current Time:07:04:27 Execution time is 2021-12-31T03:00:00+00:00
[2022-01-05 07:04:27,604] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 07:04:27,610] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 07:04:44,103] {python.py:175} INFO - Done. Returned value was: None
[2022-01-05 07:04:44,113] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T030000, start_date=20220105T070427, end_date=20220105T070444
[2022-01-05 07:04:44,151] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-01-05 07:04:44,178] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-01-05 18:45:39,981] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [queued]>
[2022-01-05 18:45:40,023] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [queued]>
[2022-01-05 18:45:40,023] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 18:45:40,028] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 18:45:40,028] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 18:45:40,077] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 03:00:00+00:00
[2022-01-05 18:45:40,085] {standard_task_runner.py:52} INFO - Started process 754 to run task
[2022-01-05 18:45:40,120] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T03:00:00+00:00', '--job-id', '380', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmp_ca6uyiw', '--error-file', '/tmp/tmpsbnimkjd']
[2022-01-05 18:45:40,121] {standard_task_runner.py:77} INFO - Job 380: Subtask tweet_load
[2022-01-05 18:45:40,326] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [running]> on host e544fdb7c66e
[2022-01-05 18:45:40,625] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T03:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T03:00:00+00:00
[2022-01-05 18:45:40,630] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:45:40,630] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:45:40,630] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:45:40,630] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:45:40,630] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:45:40,631] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:45:40,631] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:45:40,631] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:45:40,631] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:45:40,631] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:45:40,631] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:45:40,632] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:45:40,632] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7ffaccd8cb10>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 03:00:00+00:00: scheduled__2021-12-31T03:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-31', 'prev_ds_nodash': '20211231', 'prev_execution_date': DateTime(2021, 12, 31, 2, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T03:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T03:00:00+00:00', 'ts_nodash': '20211231T030000', 'ts_nodash_with_tz': '20211231T030000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T03:00:00+00:00', 'tsnodash_var': '20211231T030000', 'templates_dict': None}
[2022-01-05 18:45:40,632] {logging_mixin.py:109} INFO - Hello, Current Time:18:45:40 Execution time is 2021-12-31T03:00:00+00:00
[2022-01-05 18:45:40,684] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 18:45:40,719] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 18:45:44,535] {python.py:175} INFO - Done. Returned value was: None
[2022-01-05 18:45:44,547] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T030000, start_date=20220105T184539, end_date=20220105T184544
[2022-01-05 18:45:44,594] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-01-05 18:45:44,623] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-01-05 18:45:44,644] {dagrun.py:545} INFO - Marking run <DagRun load_dimensions @ 2021-12-31 03:00:00+00:00: scheduled__2021-12-31T03:00:00+00:00, externally triggered: False> successful
[2022-01-05 18:45:44,644] {dagrun.py:605} INFO - DagRun Finished: dag_id=load_dimensions, execution_date=2021-12-31 03:00:00+00:00, run_id=scheduled__2021-12-31T03:00:00+00:00, run_start_date=2022-01-05 18:45:37.381164+00:00, run_end_date=2022-01-05 18:45:44.644457+00:00, run_duration=7.263293, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2021-12-31 03:00:00+00:00, data_interval_end=2021-12-31 04:00:00+00:00, dag_hash=ea59270a290c9c2a836a4c05215d2937
[2022-01-05 18:46:41,808] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [queued]>
[2022-01-05 18:46:41,874] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [queued]>
[2022-01-05 18:46:41,875] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 18:46:41,875] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 18:46:41,875] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 18:46:41,979] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 03:00:00+00:00
[2022-01-05 18:46:41,996] {standard_task_runner.py:52} INFO - Started process 863 to run task
[2022-01-05 18:46:42,026] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T03:00:00+00:00', '--job-id', '406', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmpfbmm0nz1', '--error-file', '/tmp/tmp7ijgadn0']
[2022-01-05 18:46:42,028] {standard_task_runner.py:77} INFO - Job 406: Subtask tweet_load
[2022-01-05 18:46:42,332] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [running]> on host e544fdb7c66e
[2022-01-05 18:46:42,563] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T03:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T03:00:00+00:00
[2022-01-05 18:46:42,565] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:46:42,565] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:46:42,565] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:46:42,565] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:46:42,566] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:46:42,566] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:46:42,566] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:46:42,566] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:46:42,566] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:46:42,566] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:46:42,567] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:46:42,567] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:46:42,576] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7ffaccd8cb10>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 03:00:00+00:00: scheduled__2021-12-31T03:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-31', 'prev_ds_nodash': '20211231', 'prev_execution_date': DateTime(2021, 12, 31, 2, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T03:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T03:00:00+00:00', 'ts_nodash': '20211231T030000', 'ts_nodash_with_tz': '20211231T030000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T03:00:00+00:00', 'tsnodash_var': '20211231T030000', 'templates_dict': None}
[2022-01-05 18:46:42,577] {logging_mixin.py:109} INFO - Hello, Current Time:18:46:42 Execution time is 2021-12-31T03:00:00+00:00
[2022-01-05 18:46:42,665] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 18:46:42,710] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 18:46:45,056] {python.py:175} INFO - Done. Returned value was: None
[2022-01-05 18:46:45,070] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T030000, start_date=20220105T184641, end_date=20220105T184645
[2022-01-05 18:46:45,124] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-01-05 18:46:45,160] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-01-05 19:23:55,575] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [queued]>
[2022-01-05 19:23:55,671] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [queued]>
[2022-01-05 19:23:55,672] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 19:23:55,672] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 19:23:55,672] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 19:23:55,693] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 03:00:00+00:00
[2022-01-05 19:23:55,701] {standard_task_runner.py:52} INFO - Started process 2674 to run task
[2022-01-05 19:23:55,708] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T03:00:00+00:00', '--job-id', '448', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmpvgywqyxu', '--error-file', '/tmp/tmpl9za22bu']
[2022-01-05 19:23:55,709] {standard_task_runner.py:77} INFO - Job 448: Subtask tweet_load
[2022-01-05 19:23:55,866] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [running]> on host e544fdb7c66e
[2022-01-05 19:23:56,032] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T03:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T03:00:00+00:00
[2022-01-05 19:23:56,034] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:23:56,034] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:23:56,037] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:23:56,037] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:23:56,037] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:23:56,037] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:23:56,038] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:23:56,038] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:23:56,038] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:23:56,038] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:23:56,038] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:23:56,038] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:23:56,039] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7ffaccd8cb10>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 03:00:00+00:00: scheduled__2021-12-31T03:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-31', 'prev_ds_nodash': '20211231', 'prev_execution_date': DateTime(2021, 12, 31, 2, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T03:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T03:00:00+00:00', 'ts_nodash': '20211231T030000', 'ts_nodash_with_tz': '20211231T030000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T03:00:00+00:00', 'tsnodash_var': '20211231T030000', 'templates_dict': None}
[2022-01-05 19:23:56,039] {logging_mixin.py:109} INFO - Hello, Current Time:19:23:56 Execution time is 2021-12-31T03:00:00+00:00
[2022-01-05 19:23:56,070] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 19:23:56,096] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 19:23:58,539] {python.py:175} INFO - Done. Returned value was: None
[2022-01-05 19:23:58,551] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T030000, start_date=20220105T192355, end_date=20220105T192358
[2022-01-05 19:23:58,603] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-01-05 19:23:58,632] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-01-05 19:28:22,554] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [queued]>
[2022-01-05 19:28:22,613] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [queued]>
[2022-01-05 19:28:22,613] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 19:28:22,614] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 19:28:22,614] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 19:28:22,669] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 03:00:00+00:00
[2022-01-05 19:28:22,677] {standard_task_runner.py:52} INFO - Started process 2917 to run task
[2022-01-05 19:28:22,699] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T03:00:00+00:00', '--job-id', '466', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmpza1zj24u', '--error-file', '/tmp/tmp_qzgaa_y']
[2022-01-05 19:28:22,700] {standard_task_runner.py:77} INFO - Job 466: Subtask tweet_load
[2022-01-05 19:28:22,810] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [running]> on host e544fdb7c66e
[2022-01-05 19:28:22,912] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T03:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T03:00:00+00:00
[2022-01-05 19:28:22,914] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:28:22,914] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:28:22,914] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:28:22,914] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:28:22,915] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:28:22,915] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:28:22,915] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:28:22,915] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:28:22,915] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:28:22,915] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:28:22,916] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:28:22,916] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:28:22,916] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7ffaccd8cb10>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 03:00:00+00:00: scheduled__2021-12-31T03:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-31', 'prev_ds_nodash': '20211231', 'prev_execution_date': DateTime(2021, 12, 31, 2, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T03:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T03:00:00+00:00', 'ts_nodash': '20211231T030000', 'ts_nodash_with_tz': '20211231T030000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T03:00:00+00:00', 'tsnodash_var': '20211231T030000', 'templates_dict': None}
[2022-01-05 19:28:22,916] {logging_mixin.py:109} INFO - Hello, Current Time:19:28:22 Execution time is 2021-12-31T03:00:00+00:00
[2022-01-05 19:28:22,948] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 19:28:22,974] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 19:28:26,246] {python.py:175} INFO - Done. Returned value was: None
[2022-01-05 19:28:26,256] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T030000, start_date=20220105T192822, end_date=20220105T192826
[2022-01-05 19:28:26,307] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-01-05 19:28:26,332] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-01-05 19:29:19,326] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [queued]>
[2022-01-05 19:29:19,338] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [queued]>
[2022-01-05 19:29:19,338] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 19:29:19,338] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 19:29:19,338] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 19:29:19,351] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 03:00:00+00:00
[2022-01-05 19:29:19,356] {standard_task_runner.py:52} INFO - Started process 3031 to run task
[2022-01-05 19:29:19,360] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T03:00:00+00:00', '--job-id', '491', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmpbsb2mm1w', '--error-file', '/tmp/tmpwgrm21vh']
[2022-01-05 19:29:19,361] {standard_task_runner.py:77} INFO - Job 491: Subtask tweet_load
[2022-01-05 19:29:19,405] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [running]> on host e544fdb7c66e
[2022-01-05 19:29:19,453] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T03:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T03:00:00+00:00
[2022-01-05 19:29:19,454] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:29:19,454] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:29:19,454] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:29:19,454] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:29:19,455] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:29:19,455] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:29:19,455] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:29:19,455] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:29:19,455] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:29:19,455] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:29:19,455] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:29:19,455] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:29:19,456] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7ffaccd8cb10>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 03:00:00+00:00: scheduled__2021-12-31T03:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-31', 'prev_ds_nodash': '20211231', 'prev_execution_date': DateTime(2021, 12, 31, 2, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T03:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T03:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T03:00:00+00:00', 'ts_nodash': '20211231T030000', 'ts_nodash_with_tz': '20211231T030000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T03:00:00+00:00', 'tsnodash_var': '20211231T030000', 'templates_dict': None}
[2022-01-05 19:29:19,456] {logging_mixin.py:109} INFO - Hello, Current Time:19:29:19 Execution time is 2021-12-31T03:00:00+00:00
[2022-01-05 19:29:19,470] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 19:29:19,477] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 19:29:23,704] {python.py:175} INFO - Done. Returned value was: None
[2022-01-05 19:29:23,714] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T030000, start_date=20220105T192919, end_date=20220105T192923
[2022-01-05 19:29:23,747] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-01-05 19:29:23,778] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
