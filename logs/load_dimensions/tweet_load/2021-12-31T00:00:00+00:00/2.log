[2022-01-03 04:12:46,543] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [queued]>
[2022-01-03 04:12:46,555] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [queued]>
[2022-01-03 04:12:46,556] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-03 04:12:46,556] {taskinstance.py:1239} INFO - Starting attempt 2 of 2
[2022-01-03 04:12:46,556] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-03 04:12:46,574] {taskinstance.py:1259} INFO - Executing <Task(PostgresOperator): tweet_load> on 2021-12-31 00:00:00+00:00
[2022-01-03 04:12:46,580] {standard_task_runner.py:52} INFO - Started process 1151 to run task
[2022-01-03 04:12:46,587] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T00:00:00+00:00', '--job-id', '25', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmpke5hejcb', '--error-file', '/tmp/tmp1v22roc7']
[2022-01-03 04:12:46,589] {standard_task_runner.py:77} INFO - Job 25: Subtask tweet_load
[2022-01-03 04:12:46,677] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [running]> on host 2b1d65872a35
[2022-01-03 04:12:46,761] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T00:00:00+00:00
[2022-01-03 04:12:46,776] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-03 04:14:56,751] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/postgres/operators/postgres.py", line 69, in execute
    self.hook.run(self.sql, self.autocommit, parameters=self.parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/hooks/dbapi.py", line 198, in run
    with closing(self.get_conn()) as conn:
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/postgres/hooks/postgres.py", line 115, in get_conn
    self.conn = psycopg2.connect(**conn_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com" (172.31.45.95), port 5439 failed: Connection timed out
	Is the server running on that host and accepting TCP/IP connections?

[2022-01-03 04:14:56,766] {taskinstance.py:1277} INFO - Marking task as FAILED. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T000000, start_date=20220103T041246, end_date=20220103T041456
[2022-01-03 04:14:56,783] {standard_task_runner.py:92} ERROR - Failed to execute job 25 for task tweet_load
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/postgres/operators/postgres.py", line 69, in execute
    self.hook.run(self.sql, self.autocommit, parameters=self.parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/hooks/dbapi.py", line 198, in run
    with closing(self.get_conn()) as conn:
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/postgres/hooks/postgres.py", line 115, in get_conn
    self.conn = psycopg2.connect(**conn_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com" (172.31.45.95), port 5439 failed: Connection timed out
	Is the server running on that host and accepting TCP/IP connections?

[2022-01-03 04:14:56,821] {local_task_job.py:154} INFO - Task exited with return code 1
[2022-01-03 04:14:56,862] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-01-05 06:37:50,762] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [queued]>
[2022-01-05 06:37:50,776] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [queued]>
[2022-01-05 06:37:50,776] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 06:37:50,776] {taskinstance.py:1239} INFO - Starting attempt 2 of 2
[2022-01-05 06:37:50,776] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 06:37:50,790] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 00:00:00+00:00
[2022-01-05 06:37:50,796] {standard_task_runner.py:52} INFO - Started process 3481 to run task
[2022-01-05 06:37:50,798] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T00:00:00+00:00', '--job-id', '273', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmp_bzr60ha', '--error-file', '/tmp/tmpcdpe0ixy']
[2022-01-05 06:37:50,799] {standard_task_runner.py:77} INFO - Job 273: Subtask tweet_load
[2022-01-05 06:37:50,845] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [running]> on host 2b1d65872a35
[2022-01-05 06:37:50,892] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T00:00:00+00:00
[2022-01-05 06:37:50,893] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:37:50,893] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:37:50,894] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:37:50,894] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:37:50,894] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:37:50,894] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:37:50,894] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:37:50,894] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:37:50,894] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:37:50,894] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:37:50,894] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:37:50,895] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:37:50,895] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7fd8b40b1950>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 00:00:00+00:00: scheduled__2021-12-31T00:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 1, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 0, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 0, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 0, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 1, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-30', 'prev_ds_nodash': '20211230', 'prev_execution_date': DateTime(2021, 12, 30, 23, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T00:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T00:00:00+00:00', 'ts_nodash': '20211231T000000', 'ts_nodash_with_tz': '20211231T000000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T00:00:00+00:00', 'tsnodash_var': '20211231T000000', 'templates_dict': None}
[2022-01-05 06:37:50,895] {logging_mixin.py:109} INFO - Hello, Current Time:06:37:50 Execution time is 2021-12-31T00:00:00+00:00
[2022-01-05 06:37:50,902] {warnings.py:110} WARNING - /opt/***/dags/load_redshift.py:137: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only
  tweet_data = tweet_data.drop('original_text', 1)

[2022-01-05 06:37:50,913] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 06:37:50,919] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 06:38:06,057] {python.py:175} INFO - Done. Returned value was: None
[2022-01-05 06:38:06,079] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T000000, start_date=20220105T063750, end_date=20220105T063806
[2022-01-05 06:38:06,143] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-01-05 06:38:06,188] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-01-05 07:07:03,980] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [queued]>
[2022-01-05 07:07:04,002] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [queued]>
[2022-01-05 07:07:04,003] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 07:07:04,003] {taskinstance.py:1239} INFO - Starting attempt 2 of 2
[2022-01-05 07:07:04,004] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 07:07:04,038] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 00:00:00+00:00
[2022-01-05 07:07:04,050] {standard_task_runner.py:52} INFO - Started process 424 to run task
[2022-01-05 07:07:04,059] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T00:00:00+00:00', '--job-id', '359', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmp_xl1xuwx', '--error-file', '/tmp/tmpykwmhpgv']
[2022-01-05 07:07:04,062] {standard_task_runner.py:77} INFO - Job 359: Subtask tweet_load
[2022-01-05 07:07:04,190] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [running]> on host e544fdb7c66e
[2022-01-05 07:07:04,343] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T00:00:00+00:00
[2022-01-05 07:07:04,345] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:07:04,345] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:07:04,345] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:07:04,345] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:07:04,348] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:07:04,348] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:07:04,349] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:07:04,349] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:07:04,349] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:07:04,349] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:07:04,349] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:07:04,349] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:07:04,350] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7fa6a9eda8d0>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 00:00:00+00:00: scheduled__2021-12-31T00:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 1, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 0, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 0, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 0, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 1, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-30', 'prev_ds_nodash': '20211230', 'prev_execution_date': DateTime(2021, 12, 30, 23, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T00:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T00:00:00+00:00', 'ts_nodash': '20211231T000000', 'ts_nodash_with_tz': '20211231T000000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T00:00:00+00:00', 'tsnodash_var': '20211231T000000', 'templates_dict': None}
[2022-01-05 07:07:04,350] {logging_mixin.py:109} INFO - Hello, Current Time:07:07:04 Execution time is 2021-12-31T00:00:00+00:00
[2022-01-05 07:07:04,389] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 07:07:04,412] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 07:07:07,980] {python.py:175} INFO - Done. Returned value was: None
[2022-01-05 07:07:07,998] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T000000, start_date=20220105T070703, end_date=20220105T070707
[2022-01-05 07:07:08,047] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-01-05 07:07:08,097] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
