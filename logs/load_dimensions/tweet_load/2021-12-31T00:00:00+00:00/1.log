[2022-01-03 04:04:46,454] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [queued]>
[2022-01-03 04:04:46,471] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [queued]>
[2022-01-03 04:04:46,471] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-03 04:04:46,471] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-03 04:04:46,471] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-03 04:04:46,489] {taskinstance.py:1259} INFO - Executing <Task(PostgresOperator): tweet_load> on 2021-12-31 00:00:00+00:00
[2022-01-03 04:04:46,497] {standard_task_runner.py:52} INFO - Started process 796 to run task
[2022-01-03 04:04:46,503] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T00:00:00+00:00', '--job-id', '23', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmpmr5a1808', '--error-file', '/tmp/tmpmn4fvthn']
[2022-01-03 04:04:46,504] {standard_task_runner.py:77} INFO - Job 23: Subtask tweet_load
[2022-01-03 04:04:46,577] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [running]> on host 2b1d65872a35
[2022-01-03 04:04:46,645] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T00:00:00+00:00
[2022-01-03 04:04:46,655] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: dev, Login: awsuser, Password: ***, extra: {}
[2022-01-03 04:06:57,524] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/postgres/operators/postgres.py", line 69, in execute
    self.hook.run(self.sql, self.autocommit, parameters=self.parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/hooks/dbapi.py", line 198, in run
    with closing(self.get_conn()) as conn:
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/postgres/hooks/postgres.py", line 115, in get_conn
    self.conn = psycopg2.connect(**conn_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com" (172.31.45.95), port 5439 failed: Connection timed out
	Is the server running on that host and accepting TCP/IP connections?

[2022-01-03 04:06:57,539] {taskinstance.py:1277} INFO - Marking task as FAILED. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T000000, start_date=20220103T040446, end_date=20220103T040657
[2022-01-03 04:06:57,569] {standard_task_runner.py:92} ERROR - Failed to execute job 23 for task tweet_load
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/postgres/operators/postgres.py", line 69, in execute
    self.hook.run(self.sql, self.autocommit, parameters=self.parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/hooks/dbapi.py", line 198, in run
    with closing(self.get_conn()) as conn:
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/postgres/hooks/postgres.py", line 115, in get_conn
    self.conn = psycopg2.connect(**conn_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com" (172.31.45.95), port 5439 failed: Connection timed out
	Is the server running on that host and accepting TCP/IP connections?

[2022-01-03 04:06:57,592] {local_task_job.py:154} INFO - Task exited with return code 1
[2022-01-03 04:06:57,630] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-01-05 05:18:31,294] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [queued]>
[2022-01-05 05:18:31,337] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [queued]>
[2022-01-05 05:18:31,337] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 05:18:31,338] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 05:18:31,338] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 05:18:31,368] {taskinstance.py:1259} INFO - Executing <Task(PostgresOperator): tweet_load> on 2021-12-31 00:00:00+00:00
[2022-01-05 05:18:31,376] {standard_task_runner.py:52} INFO - Started process 2936 to run task
[2022-01-05 05:18:31,407] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T00:00:00+00:00', '--job-id', '36', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmpk4xr1kca', '--error-file', '/tmp/tmpbojx0wtc']
[2022-01-05 05:18:31,408] {standard_task_runner.py:77} INFO - Job 36: Subtask tweet_load
[2022-01-05 05:18:31,527] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [running]> on host 2b1d65872a35
[2022-01-05 05:18:31,702] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T00:00:00+00:00
[2022-01-05 05:18:31,728] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 05:18:32,287] {dbapi.py:225} INFO - Running statement: select * test, parameters: None
[2022-01-05 05:18:32,401] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/postgres/operators/postgres.py", line 69, in execute
    self.hook.run(self.sql, self.autocommit, parameters=self.parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/hooks/dbapi.py", line 205, in run
    self._run_command(cur, sql_statement, parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/hooks/dbapi.py", line 229, in _run_command
    cur.execute(sql_statement)
psycopg2.errors.SyntaxError: syntax error at or near "test"
LINE 1: select * test
                 ^

[2022-01-05 05:18:32,429] {taskinstance.py:1277} INFO - Marking task as FAILED. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T000000, start_date=20220105T051831, end_date=20220105T051832
[2022-01-05 05:18:32,460] {standard_task_runner.py:92} ERROR - Failed to execute job 36 for task tweet_load
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/postgres/operators/postgres.py", line 69, in execute
    self.hook.run(self.sql, self.autocommit, parameters=self.parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/hooks/dbapi.py", line 205, in run
    self._run_command(cur, sql_statement, parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/hooks/dbapi.py", line 229, in _run_command
    cur.execute(sql_statement)
psycopg2.errors.SyntaxError: syntax error at or near "test"
LINE 1: select * test
                 ^

[2022-01-05 05:18:32,512] {local_task_job.py:154} INFO - Task exited with return code 1
[2022-01-05 05:18:32,577] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-01-05 05:23:12,333] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [queued]>
[2022-01-05 05:23:12,427] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [queued]>
[2022-01-05 05:23:12,427] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 05:23:12,427] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 05:23:12,427] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 05:23:12,509] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 00:00:00+00:00
[2022-01-05 05:23:12,515] {standard_task_runner.py:52} INFO - Started process 3234 to run task
[2022-01-05 05:23:12,534] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T00:00:00+00:00', '--job-id', '68', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmp1lqft9mu', '--error-file', '/tmp/tmplqn3qt7z']
[2022-01-05 05:23:12,559] {standard_task_runner.py:77} INFO - Job 68: Subtask tweet_load
[2022-01-05 05:23:12,784] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [running]> on host 2b1d65872a35
[2022-01-05 05:23:12,999] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T00:00:00+00:00
[2022-01-05 05:23:13,005] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:23:13,006] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:23:13,007] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:23:13,007] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:23:13,008] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:23:13,008] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:23:13,021] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:23:13,021] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:23:13,022] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:23:13,022] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:23:13,022] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:23:13,022] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:23:13,023] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7f88b8fac810>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 00:00:00+00:00: scheduled__2021-12-31T00:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 1, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 0, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 0, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 0, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 1, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-30', 'prev_ds_nodash': '20211230', 'prev_execution_date': DateTime(2021, 12, 30, 23, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T00:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T00:00:00+00:00', 'ts_nodash': '20211231T000000', 'ts_nodash_with_tz': '20211231T000000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T00:00:00+00:00', 'tsnodash_var': '20211231T000000', 'templates_dict': None}
[2022-01-05 05:23:13,023] {logging_mixin.py:109} INFO - Hello, Current Time:05:23:13 Execution time is 2021-12-31T00:00:00+00:00
[2022-01-05 05:23:13,172] {logging_mixin.py:109} INFO -    Unnamed: 0  ...       location
0           0  ...            NaN
1           1  ...            NaN
2           2  ...            NaN
3           3  ...      UofGuelph
4           4  ...            NaN
5           5  ...  Westbrook, ME
6           6  ...            NaN
7           7  ...            NaN
8           8  ...            NaN
9           9  ...   General Roca

[10 rows x 6 columns]
[2022-01-05 05:23:13,295] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 05:23:13,305] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 05:23:13,940] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2336, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 364, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 778, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 495, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 140, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 137, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 309, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 440, in __init__
    self.__connect(first_connect_check=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 656, in __connect
    connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/strategies.py", line 114, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 508, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com" (3.132.179.48), port 5439 failed: FATAL:  password authentication failed for user "awsuser"
connection to server at "tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com" (3.132.179.48), port 5439 failed: FATAL:  password authentication failed for user "awsuser"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 139, in load_tweets
    df.to_sql('test', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1758, in to_sql
    dtype=dtype,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1650, in prep_table
    table.create()
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 856, in create
    if self.exists():
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 840, in exists
    return self.pd_sql.has_table(self.name, self.schema)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1787, in has_table
    self.connectable.dialect.has_table, name, schema or self.meta.schema
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2211, in run_callable
    with self._contextual_connect() as conn:
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2302, in _contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2340, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1584, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2336, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 364, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 778, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 495, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 140, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 137, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 309, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 440, in __init__
    self.__connect(first_connect_check=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 656, in __connect
    connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/strategies.py", line 114, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 508, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com" (3.132.179.48), port 5439 failed: FATAL:  password authentication failed for user "awsuser"
connection to server at "tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com" (3.132.179.48), port 5439 failed: FATAL:  password authentication failed for user "awsuser"

(Background on this error at: http://sqlalche.me/e/13/e3q8)
[2022-01-05 05:23:14,183] {taskinstance.py:1277} INFO - Marking task as FAILED. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T000000, start_date=20220105T052312, end_date=20220105T052314
[2022-01-05 05:23:14,375] {standard_task_runner.py:92} ERROR - Failed to execute job 68 for task tweet_load
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2336, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 364, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 778, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 495, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 140, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 137, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 309, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 440, in __init__
    self.__connect(first_connect_check=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 656, in __connect
    connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/strategies.py", line 114, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 508, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com" (3.132.179.48), port 5439 failed: FATAL:  password authentication failed for user "awsuser"
connection to server at "tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com" (3.132.179.48), port 5439 failed: FATAL:  password authentication failed for user "awsuser"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 139, in load_tweets
    df.to_sql('test', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1758, in to_sql
    dtype=dtype,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1650, in prep_table
    table.create()
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 856, in create
    if self.exists():
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 840, in exists
    return self.pd_sql.has_table(self.name, self.schema)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1787, in has_table
    self.connectable.dialect.has_table, name, schema or self.meta.schema
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2211, in run_callable
    with self._contextual_connect() as conn:
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2302, in _contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2340, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1584, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2336, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 364, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 778, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 495, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 140, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 137, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 309, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 440, in __init__
    self.__connect(first_connect_check=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 656, in __connect
    connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/strategies.py", line 114, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 508, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com" (3.132.179.48), port 5439 failed: FATAL:  password authentication failed for user "awsuser"
connection to server at "tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com" (3.132.179.48), port 5439 failed: FATAL:  password authentication failed for user "awsuser"

(Background on this error at: http://sqlalche.me/e/13/e3q8)
[2022-01-05 05:23:14,409] {local_task_job.py:154} INFO - Task exited with return code 1
[2022-01-05 05:23:14,506] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-01-05 05:35:10,853] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [queued]>
[2022-01-05 05:35:10,885] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [queued]>
[2022-01-05 05:35:10,885] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 05:35:10,887] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 05:35:10,887] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 05:35:10,937] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 00:00:00+00:00
[2022-01-05 05:35:10,951] {standard_task_runner.py:52} INFO - Started process 226 to run task
[2022-01-05 05:35:10,965] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T00:00:00+00:00', '--job-id', '106', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmpceailzwd', '--error-file', '/tmp/tmpm9ysders']
[2022-01-05 05:35:10,966] {standard_task_runner.py:77} INFO - Job 106: Subtask tweet_load
[2022-01-05 05:35:11,125] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [running]> on host 2b1d65872a35
[2022-01-05 05:35:11,267] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T00:00:00+00:00
[2022-01-05 05:35:11,271] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:35:11,272] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:35:11,272] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:35:11,272] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:35:11,272] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:35:11,272] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:35:11,273] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:35:11,273] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:35:11,273] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:35:11,273] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:35:11,273] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:35:11,273] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:35:11,274] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7fd8b40b1950>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 00:00:00+00:00: scheduled__2021-12-31T00:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 1, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 0, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 0, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 0, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 1, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-30', 'prev_ds_nodash': '20211230', 'prev_execution_date': DateTime(2021, 12, 30, 23, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T00:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T00:00:00+00:00', 'ts_nodash': '20211231T000000', 'ts_nodash_with_tz': '20211231T000000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T00:00:00+00:00', 'tsnodash_var': '20211231T000000', 'templates_dict': None}
[2022-01-05 05:35:11,274] {logging_mixin.py:109} INFO - Hello, Current Time:05:35:11 Execution time is 2021-12-31T00:00:00+00:00
[2022-01-05 05:35:11,308] {logging_mixin.py:109} INFO -    Unnamed: 0  ...       location
0           0  ...            NaN
1           1  ...            NaN
2           2  ...            NaN
3           3  ...      UofGuelph
4           4  ...            NaN
5           5  ...  Westbrook, ME
6           6  ...            NaN
7           7  ...            NaN
8           8  ...            NaN
9           9  ...   General Roca

[10 rows x 6 columns]
[2022-01-05 05:35:11,321] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 05:35:11,330] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 05:35:13,492] {python.py:175} INFO - Done. Returned value was: None
[2022-01-05 05:35:13,511] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T000000, start_date=20220105T053510, end_date=20220105T053513
[2022-01-05 05:35:13,554] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-01-05 05:35:13,631] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-01-05 05:49:55,025] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [queued]>
[2022-01-05 05:49:55,057] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [queued]>
[2022-01-05 05:49:55,057] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 05:49:55,057] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 05:49:55,057] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 05:49:55,096] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 00:00:00+00:00
[2022-01-05 05:49:55,110] {standard_task_runner.py:52} INFO - Started process 922 to run task
[2022-01-05 05:49:55,131] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T00:00:00+00:00', '--job-id', '123', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmpfu596ssl', '--error-file', '/tmp/tmp0jux26wj']
[2022-01-05 05:49:55,140] {standard_task_runner.py:77} INFO - Job 123: Subtask tweet_load
[2022-01-05 05:49:55,317] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [running]> on host 2b1d65872a35
[2022-01-05 05:49:55,432] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T00:00:00+00:00
[2022-01-05 05:49:55,434] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:49:55,434] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:49:55,435] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:49:55,435] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:49:55,435] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:49:55,435] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:49:55,435] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:49:55,435] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:49:55,436] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:49:55,438] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:49:55,438] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:49:55,439] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:49:55,439] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7fd8b40b1950>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 00:00:00+00:00: scheduled__2021-12-31T00:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 1, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 0, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 0, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 0, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 1, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-30', 'prev_ds_nodash': '20211230', 'prev_execution_date': DateTime(2021, 12, 30, 23, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T00:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T00:00:00+00:00', 'ts_nodash': '20211231T000000', 'ts_nodash_with_tz': '20211231T000000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T00:00:00+00:00', 'tsnodash_var': '20211231T000000', 'templates_dict': None}
[2022-01-05 05:49:55,439] {logging_mixin.py:109} INFO - Hello, Current Time:05:49:55 Execution time is 2021-12-31T00:00:00+00:00
[2022-01-05 05:49:55,524] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 05:49:55,547] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 05:49:57,052] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
psycopg2.errors.UndefinedColumn: column "unnamed: 0" of relation "tweet" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 133, in load_tweets
    tweet_data.to_sql('tweet', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1770, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1350, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1340, in insert_records
    table.insert(chunksize=chunksize, method=method)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 967, in insert
    exec_insert(conn, keys, chunk_iter)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 882, in _execute_insert
    conn.execute(self.table.insert(), data)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "unnamed: 0" of relation "tweet" does not exist

[SQL: INSERT INTO tweet ("Unnamed: 0", id, author_id, created_at, original_text, location) VALUES (%(Unnamed: 0)s, %(id)s, %(author_id)s, %(created_at)s, %(original_text)s, %(location)s)]
[parameters: ({'Unnamed: 0': 0, 'id': 1476707170444001286, 'author_id': 2729515294, 'created_at': '2021-12-31T00:09:59.000Z', 'original_text': 'The Cleveland Cavaliers are nearing a trade to acquire Los Angeles Lakers guard Rajon Rondo -- and an agreement is expected to be reached as soon as Friday, sources tell ESPN. Rondo would be able to join Cleveland as soon as he clears Covid protocols.', 'location': 'Z 🌎'}, {'Unnamed: 0': 1, 'id': 1476707170028720136, 'author_id': 1365590270, 'created_at': '2021-12-31T00:09:59.000Z', 'original_text': '@RekietaMedia https://t.co/MQLbyvNGdF', 'location': 'Detroit Lakes, MN'}, {'Unnamed: 0': 2, 'id': 1476707170024525830, 'author_id': 18570600, 'created_at': '2021-12-31T00:09:59.000Z', 'original_text': '“I’m here for a good time, not a long time” between Covid and climate change, you’re here for neither', 'location': None}, {'Unnamed: 0': 3, 'id': 1476707170003689475, 'author_id': 814255276161429509, 'created_at': '2021-12-31T00:09:59.000Z', 'original_text': 'Assim nós que nunca apanhamos covid não merecemos nenhum prêmio … nenhuma gala… nada ?\nFaçam um Covid Awards, nós merecemos', 'location': 'Braga, Portugal'}, {'Unnamed: 0': 4, 'id': 1476707169928200200, 'author_id': 3195361197, 'created_at': '2021-12-31T00:09:59.000Z', 'original_text': 'The @CDCgov is reporting 111,008 new confirmed COVID cases in Florida over the last 48 hours. https://t.co/aLPCxMLEGY', 'location': 'Clearwater, FL'}, {'Unnamed: 0': 5, 'id': 1476707169785450500, 'author_id': 2460479600, 'created_at': '2021-12-31T00:09:59.000Z', 'original_text': 'I know more people who suffered adverse SERIOUS side effects from the jabs than from having covid. People have legit reasons to not take the vax, but ... (5 characters truncated) ... Left has been indoctrinated to firmly believe that the rest of us are racist. Even though people of all races refuse the vax. https://t.co/mwQWRIoFw4', 'location': 'San Diego, CA'}, {'Unnamed: 0': 6, 'id': 1476707169672339456, 'author_id': 1154568985125556224, 'created_at': '2021-12-31T00:09:59.000Z', 'original_text': 'Alguien sin covid para hacer alguna?', 'location': None}, {'Unnamed: 0': 7, 'id': 1476707169286467584, 'author_id': 4070570903, 'created_at': '2021-12-31T00:09:59.000Z', 'original_text': 'Con covid reina https://t.co/JVVJMcxsGS', 'location': 'Villa Dolores, Argentina'}, {'Unnamed: 0': 8, 'id': 1476707169164693516, 'author_id': 1456500642462060546, 'created_at': '2021-12-31T00:09:59.000Z', 'original_text': 'The 4 passengers had concealed gold in their rectums and pockets of trousers.\n\n#TamilNadu \n\nhttps://t.co/k6aCeGu8Mc', 'location': None})]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-01-05 05:49:57,101] {taskinstance.py:1277} INFO - Marking task as FAILED. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T000000, start_date=20220105T054955, end_date=20220105T054957
[2022-01-05 05:49:57,139] {standard_task_runner.py:92} ERROR - Failed to execute job 123 for task tweet_load
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
psycopg2.errors.UndefinedColumn: column "unnamed: 0" of relation "tweet" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 133, in load_tweets
    tweet_data.to_sql('tweet', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1770, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1350, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1340, in insert_records
    table.insert(chunksize=chunksize, method=method)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 967, in insert
    exec_insert(conn, keys, chunk_iter)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 882, in _execute_insert
    conn.execute(self.table.insert(), data)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "unnamed: 0" of relation "tweet" does not exist

[SQL: INSERT INTO tweet ("Unnamed: 0", id, author_id, created_at, original_text, location) VALUES (%(Unnamed: 0)s, %(id)s, %(author_id)s, %(created_at)s, %(original_text)s, %(location)s)]
[parameters: ({'Unnamed: 0': 0, 'id': 1476707170444001286, 'author_id': 2729515294, 'created_at': '2021-12-31T00:09:59.000Z', 'original_text': 'The Cleveland Cavaliers are nearing a trade to acquire Los Angeles Lakers guard Rajon Rondo -- and an agreement is expected to be reached as soon as Friday, sources tell ESPN. Rondo would be able to join Cleveland as soon as he clears Covid protocols.', 'location': 'Z 🌎'}, {'Unnamed: 0': 1, 'id': 1476707170028720136, 'author_id': 1365590270, 'created_at': '2021-12-31T00:09:59.000Z', 'original_text': '@RekietaMedia https://t.co/MQLbyvNGdF', 'location': 'Detroit Lakes, MN'}, {'Unnamed: 0': 2, 'id': 1476707170024525830, 'author_id': 18570600, 'created_at': '2021-12-31T00:09:59.000Z', 'original_text': '“I’m here for a good time, not a long time” between Covid and climate change, you’re here for neither', 'location': None}, {'Unnamed: 0': 3, 'id': 1476707170003689475, 'author_id': 814255276161429509, 'created_at': '2021-12-31T00:09:59.000Z', 'original_text': 'Assim nós que nunca apanhamos covid não merecemos nenhum prêmio … nenhuma gala… nada ?\nFaçam um Covid Awards, nós merecemos', 'location': 'Braga, Portugal'}, {'Unnamed: 0': 4, 'id': 1476707169928200200, 'author_id': 3195361197, 'created_at': '2021-12-31T00:09:59.000Z', 'original_text': 'The @CDCgov is reporting 111,008 new confirmed COVID cases in Florida over the last 48 hours. https://t.co/aLPCxMLEGY', 'location': 'Clearwater, FL'}, {'Unnamed: 0': 5, 'id': 1476707169785450500, 'author_id': 2460479600, 'created_at': '2021-12-31T00:09:59.000Z', 'original_text': 'I know more people who suffered adverse SERIOUS side effects from the jabs than from having covid. People have legit reasons to not take the vax, but ... (5 characters truncated) ... Left has been indoctrinated to firmly believe that the rest of us are racist. Even though people of all races refuse the vax. https://t.co/mwQWRIoFw4', 'location': 'San Diego, CA'}, {'Unnamed: 0': 6, 'id': 1476707169672339456, 'author_id': 1154568985125556224, 'created_at': '2021-12-31T00:09:59.000Z', 'original_text': 'Alguien sin covid para hacer alguna?', 'location': None}, {'Unnamed: 0': 7, 'id': 1476707169286467584, 'author_id': 4070570903, 'created_at': '2021-12-31T00:09:59.000Z', 'original_text': 'Con covid reina https://t.co/JVVJMcxsGS', 'location': 'Villa Dolores, Argentina'}, {'Unnamed: 0': 8, 'id': 1476707169164693516, 'author_id': 1456500642462060546, 'created_at': '2021-12-31T00:09:59.000Z', 'original_text': 'The 4 passengers had concealed gold in their rectums and pockets of trousers.\n\n#TamilNadu \n\nhttps://t.co/k6aCeGu8Mc', 'location': None})]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-01-05 05:49:57,179] {local_task_job.py:154} INFO - Task exited with return code 1
[2022-01-05 05:49:57,333] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-01-05 05:51:29,199] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [queued]>
[2022-01-05 05:51:29,219] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [queued]>
[2022-01-05 05:51:29,219] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 05:51:29,219] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 05:51:29,219] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 05:51:29,246] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 00:00:00+00:00
[2022-01-05 05:51:29,254] {standard_task_runner.py:52} INFO - Started process 1047 to run task
[2022-01-05 05:51:29,262] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T00:00:00+00:00', '--job-id', '141', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmp64we1xnd', '--error-file', '/tmp/tmpn_v0_gh5']
[2022-01-05 05:51:29,263] {standard_task_runner.py:77} INFO - Job 141: Subtask tweet_load
[2022-01-05 05:51:29,328] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [running]> on host 2b1d65872a35
[2022-01-05 05:51:29,387] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T00:00:00+00:00
[2022-01-05 05:51:29,389] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:51:29,389] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:51:29,389] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:51:29,389] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:51:29,389] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:51:29,389] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:51:29,390] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:51:29,390] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:51:29,390] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:51:29,390] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:51:29,390] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:51:29,390] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:51:29,391] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7fd8b40b1950>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 00:00:00+00:00: scheduled__2021-12-31T00:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 1, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 0, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 0, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 0, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 1, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-30', 'prev_ds_nodash': '20211230', 'prev_execution_date': DateTime(2021, 12, 30, 23, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T00:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T00:00:00+00:00', 'ts_nodash': '20211231T000000', 'ts_nodash_with_tz': '20211231T000000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T00:00:00+00:00', 'tsnodash_var': '20211231T000000', 'templates_dict': None}
[2022-01-05 05:51:29,391] {logging_mixin.py:109} INFO - Hello, Current Time:05:51:29 Execution time is 2021-12-31T00:00:00+00:00
[2022-01-05 05:51:29,410] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 05:51:29,419] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 05:51:30,891] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
psycopg2.errors.UndefinedColumn: column "original_text" of relation "tweet" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 133, in load_tweets
    tweet_data.to_sql('tweet', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1770, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1350, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1340, in insert_records
    table.insert(chunksize=chunksize, method=method)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 967, in insert
    exec_insert(conn, keys, chunk_iter)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 882, in _execute_insert
    conn.execute(self.table.insert(), data)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "original_text" of relation "tweet" does not exist

[SQL: INSERT INTO tweet (created_at, author_id, id, original_text, location) VALUES (%(created_at)s, %(author_id)s, %(id)s, %(original_text)s, %(location)s)]
[parameters: ({'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 2729515294, 'id': 1476707170444001286, 'original_text': 'The Cleveland Cavaliers are nearing a trade to acquire Los Angeles Lakers guard Rajon Rondo -- and an agreement is expected to be reached as soon as Friday, sources tell ESPN. Rondo would be able to join Cleveland as soon as he clears Covid protocols.', 'location': 'Z 🌎'}, {'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 1365590270, 'id': 1476707170028720136, 'original_text': '@RekietaMedia https://t.co/MQLbyvNGdF', 'location': 'Detroit Lakes, MN'}, {'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 18570600, 'id': 1476707170024525830, 'original_text': '“I’m here for a good time, not a long time” between Covid and climate change, you’re here for neither', 'location': None}, {'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 814255276161429509, 'id': 1476707170003689475, 'original_text': 'Assim nós que nunca apanhamos covid não merecemos nenhum prêmio … nenhuma gala… nada ?\nFaçam um Covid Awards, nós merecemos', 'location': 'Braga, Portugal'}, {'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 3195361197, 'id': 1476707169928200200, 'original_text': 'The @CDCgov is reporting 111,008 new confirmed COVID cases in Florida over the last 48 hours. https://t.co/aLPCxMLEGY', 'location': 'Clearwater, FL'}, {'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 2460479600, 'id': 1476707169785450500, 'original_text': 'I know more people who suffered adverse SERIOUS side effects from the jabs than from having covid. People have legit reasons to not take the vax, but ... (5 characters truncated) ... Left has been indoctrinated to firmly believe that the rest of us are racist. Even though people of all races refuse the vax. https://t.co/mwQWRIoFw4', 'location': 'San Diego, CA'}, {'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 1154568985125556224, 'id': 1476707169672339456, 'original_text': 'Alguien sin covid para hacer alguna?', 'location': None}, {'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 4070570903, 'id': 1476707169286467584, 'original_text': 'Con covid reina https://t.co/JVVJMcxsGS', 'location': 'Villa Dolores, Argentina'}, {'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 1456500642462060546, 'id': 1476707169164693516, 'original_text': 'The 4 passengers had concealed gold in their rectums and pockets of trousers.\n\n#TamilNadu \n\nhttps://t.co/k6aCeGu8Mc', 'location': None})]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-01-05 05:51:30,907] {taskinstance.py:1277} INFO - Marking task as FAILED. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T000000, start_date=20220105T055129, end_date=20220105T055130
[2022-01-05 05:51:30,918] {standard_task_runner.py:92} ERROR - Failed to execute job 141 for task tweet_load
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
psycopg2.errors.UndefinedColumn: column "original_text" of relation "tweet" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 133, in load_tweets
    tweet_data.to_sql('tweet', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1770, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1350, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1340, in insert_records
    table.insert(chunksize=chunksize, method=method)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 967, in insert
    exec_insert(conn, keys, chunk_iter)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 882, in _execute_insert
    conn.execute(self.table.insert(), data)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "original_text" of relation "tweet" does not exist

[SQL: INSERT INTO tweet (created_at, author_id, id, original_text, location) VALUES (%(created_at)s, %(author_id)s, %(id)s, %(original_text)s, %(location)s)]
[parameters: ({'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 2729515294, 'id': 1476707170444001286, 'original_text': 'The Cleveland Cavaliers are nearing a trade to acquire Los Angeles Lakers guard Rajon Rondo -- and an agreement is expected to be reached as soon as Friday, sources tell ESPN. Rondo would be able to join Cleveland as soon as he clears Covid protocols.', 'location': 'Z 🌎'}, {'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 1365590270, 'id': 1476707170028720136, 'original_text': '@RekietaMedia https://t.co/MQLbyvNGdF', 'location': 'Detroit Lakes, MN'}, {'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 18570600, 'id': 1476707170024525830, 'original_text': '“I’m here for a good time, not a long time” between Covid and climate change, you’re here for neither', 'location': None}, {'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 814255276161429509, 'id': 1476707170003689475, 'original_text': 'Assim nós que nunca apanhamos covid não merecemos nenhum prêmio … nenhuma gala… nada ?\nFaçam um Covid Awards, nós merecemos', 'location': 'Braga, Portugal'}, {'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 3195361197, 'id': 1476707169928200200, 'original_text': 'The @CDCgov is reporting 111,008 new confirmed COVID cases in Florida over the last 48 hours. https://t.co/aLPCxMLEGY', 'location': 'Clearwater, FL'}, {'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 2460479600, 'id': 1476707169785450500, 'original_text': 'I know more people who suffered adverse SERIOUS side effects from the jabs than from having covid. People have legit reasons to not take the vax, but ... (5 characters truncated) ... Left has been indoctrinated to firmly believe that the rest of us are racist. Even though people of all races refuse the vax. https://t.co/mwQWRIoFw4', 'location': 'San Diego, CA'}, {'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 1154568985125556224, 'id': 1476707169672339456, 'original_text': 'Alguien sin covid para hacer alguna?', 'location': None}, {'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 4070570903, 'id': 1476707169286467584, 'original_text': 'Con covid reina https://t.co/JVVJMcxsGS', 'location': 'Villa Dolores, Argentina'}, {'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 1456500642462060546, 'id': 1476707169164693516, 'original_text': 'The 4 passengers had concealed gold in their rectums and pockets of trousers.\n\n#TamilNadu \n\nhttps://t.co/k6aCeGu8Mc', 'location': None})]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-01-05 05:51:30,964] {local_task_job.py:154} INFO - Task exited with return code 1
[2022-01-05 05:51:30,994] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-01-05 06:00:46,271] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [queued]>
[2022-01-05 06:00:46,304] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [queued]>
[2022-01-05 06:00:46,304] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 06:00:46,304] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 06:00:46,304] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 06:00:46,334] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 00:00:00+00:00
[2022-01-05 06:00:46,340] {standard_task_runner.py:52} INFO - Started process 1507 to run task
[2022-01-05 06:00:46,348] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T00:00:00+00:00', '--job-id', '159', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmp6whpjm_b', '--error-file', '/tmp/tmpmb88ywgl']
[2022-01-05 06:00:46,349] {standard_task_runner.py:77} INFO - Job 159: Subtask tweet_load
[2022-01-05 06:00:46,475] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [running]> on host 2b1d65872a35
[2022-01-05 06:00:46,650] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T00:00:00+00:00
[2022-01-05 06:00:46,652] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:00:46,652] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:00:46,652] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:00:46,653] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:00:46,653] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:00:46,653] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:00:46,653] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:00:46,653] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:00:46,653] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:00:46,653] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:00:46,654] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:00:46,654] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:00:46,656] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7fd8b40b1950>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 00:00:00+00:00: scheduled__2021-12-31T00:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 1, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 0, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 0, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 0, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 1, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-30', 'prev_ds_nodash': '20211230', 'prev_execution_date': DateTime(2021, 12, 30, 23, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T00:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T00:00:00+00:00', 'ts_nodash': '20211231T000000', 'ts_nodash_with_tz': '20211231T000000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T00:00:00+00:00', 'tsnodash_var': '20211231T000000', 'templates_dict': None}
[2022-01-05 06:00:46,656] {logging_mixin.py:109} INFO - Hello, Current Time:06:00:46 Execution time is 2021-12-31T00:00:00+00:00
[2022-01-05 06:00:46,697] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 06:00:46,710] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 06:00:48,152] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
psycopg2.errors.NumericValueOutOfRange: numeric value "2729515294" out of range for integer


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 133, in load_tweets
    tweet_data.to_sql('tweet', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1770, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1350, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1340, in insert_records
    table.insert(chunksize=chunksize, method=method)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 967, in insert
    exec_insert(conn, keys, chunk_iter)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 882, in _execute_insert
    conn.execute(self.table.insert(), data)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
sqlalchemy.exc.DataError: (psycopg2.errors.NumericValueOutOfRange) numeric value "2729515294" out of range for integer

[SQL: INSERT INTO tweet (id, created_at, author_id, original_text, location) VALUES (%(id)s, %(created_at)s, %(author_id)s, %(original_text)s, %(location)s)]
[parameters: ({'id': 1476707170444001286, 'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 2729515294, 'original_text': 'The Cleveland Cavaliers are nearing a trade to acquire Los Angeles Lakers guard Rajon Rondo -- and an agreement is expected to be reached as soon as Friday, sources tell ESPN. Rondo would be able to join Cleveland as soon as he clears Covid protocols.', 'location': 'Z 🌎'}, {'id': 1476707170028720136, 'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 1365590270, 'original_text': '@RekietaMedia https://t.co/MQLbyvNGdF', 'location': 'Detroit Lakes, MN'}, {'id': 1476707170024525830, 'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 18570600, 'original_text': '“I’m here for a good time, not a long time” between Covid and climate change, you’re here for neither', 'location': None}, {'id': 1476707170003689475, 'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 814255276161429509, 'original_text': 'Assim nós que nunca apanhamos covid não merecemos nenhum prêmio … nenhuma gala… nada ?\nFaçam um Covid Awards, nós merecemos', 'location': 'Braga, Portugal'}, {'id': 1476707169928200200, 'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 3195361197, 'original_text': 'The @CDCgov is reporting 111,008 new confirmed COVID cases in Florida over the last 48 hours. https://t.co/aLPCxMLEGY', 'location': 'Clearwater, FL'}, {'id': 1476707169785450500, 'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 2460479600, 'original_text': 'I know more people who suffered adverse SERIOUS side effects from the jabs than from having covid. People have legit reasons to not take the vax, but ... (5 characters truncated) ... Left has been indoctrinated to firmly believe that the rest of us are racist. Even though people of all races refuse the vax. https://t.co/mwQWRIoFw4', 'location': 'San Diego, CA'}, {'id': 1476707169672339456, 'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 1154568985125556224, 'original_text': 'Alguien sin covid para hacer alguna?', 'location': None}, {'id': 1476707169286467584, 'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 4070570903, 'original_text': 'Con covid reina https://t.co/JVVJMcxsGS', 'location': 'Villa Dolores, Argentina'}, {'id': 1476707169164693516, 'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 1456500642462060546, 'original_text': 'The 4 passengers had concealed gold in their rectums and pockets of trousers.\n\n#TamilNadu \n\nhttps://t.co/k6aCeGu8Mc', 'location': None})]
(Background on this error at: http://sqlalche.me/e/13/9h9h)
[2022-01-05 06:00:48,169] {taskinstance.py:1277} INFO - Marking task as FAILED. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T000000, start_date=20220105T060046, end_date=20220105T060048
[2022-01-05 06:00:48,182] {standard_task_runner.py:92} ERROR - Failed to execute job 159 for task tweet_load
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
psycopg2.errors.NumericValueOutOfRange: numeric value "2729515294" out of range for integer


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 133, in load_tweets
    tweet_data.to_sql('tweet', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1770, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1350, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1340, in insert_records
    table.insert(chunksize=chunksize, method=method)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 967, in insert
    exec_insert(conn, keys, chunk_iter)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 882, in _execute_insert
    conn.execute(self.table.insert(), data)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
sqlalchemy.exc.DataError: (psycopg2.errors.NumericValueOutOfRange) numeric value "2729515294" out of range for integer

[SQL: INSERT INTO tweet (id, created_at, author_id, original_text, location) VALUES (%(id)s, %(created_at)s, %(author_id)s, %(original_text)s, %(location)s)]
[parameters: ({'id': 1476707170444001286, 'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 2729515294, 'original_text': 'The Cleveland Cavaliers are nearing a trade to acquire Los Angeles Lakers guard Rajon Rondo -- and an agreement is expected to be reached as soon as Friday, sources tell ESPN. Rondo would be able to join Cleveland as soon as he clears Covid protocols.', 'location': 'Z 🌎'}, {'id': 1476707170028720136, 'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 1365590270, 'original_text': '@RekietaMedia https://t.co/MQLbyvNGdF', 'location': 'Detroit Lakes, MN'}, {'id': 1476707170024525830, 'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 18570600, 'original_text': '“I’m here for a good time, not a long time” between Covid and climate change, you’re here for neither', 'location': None}, {'id': 1476707170003689475, 'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 814255276161429509, 'original_text': 'Assim nós que nunca apanhamos covid não merecemos nenhum prêmio … nenhuma gala… nada ?\nFaçam um Covid Awards, nós merecemos', 'location': 'Braga, Portugal'}, {'id': 1476707169928200200, 'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 3195361197, 'original_text': 'The @CDCgov is reporting 111,008 new confirmed COVID cases in Florida over the last 48 hours. https://t.co/aLPCxMLEGY', 'location': 'Clearwater, FL'}, {'id': 1476707169785450500, 'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 2460479600, 'original_text': 'I know more people who suffered adverse SERIOUS side effects from the jabs than from having covid. People have legit reasons to not take the vax, but ... (5 characters truncated) ... Left has been indoctrinated to firmly believe that the rest of us are racist. Even though people of all races refuse the vax. https://t.co/mwQWRIoFw4', 'location': 'San Diego, CA'}, {'id': 1476707169672339456, 'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 1154568985125556224, 'original_text': 'Alguien sin covid para hacer alguna?', 'location': None}, {'id': 1476707169286467584, 'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 4070570903, 'original_text': 'Con covid reina https://t.co/JVVJMcxsGS', 'location': 'Villa Dolores, Argentina'}, {'id': 1476707169164693516, 'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 1456500642462060546, 'original_text': 'The 4 passengers had concealed gold in their rectums and pockets of trousers.\n\n#TamilNadu \n\nhttps://t.co/k6aCeGu8Mc', 'location': None})]
(Background on this error at: http://sqlalche.me/e/13/9h9h)
[2022-01-05 06:00:48,226] {local_task_job.py:154} INFO - Task exited with return code 1
[2022-01-05 06:00:48,261] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-01-05 06:01:47,606] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [queued]>
[2022-01-05 06:01:47,618] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [queued]>
[2022-01-05 06:01:47,618] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 06:01:47,618] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 06:01:47,618] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 06:01:47,639] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 00:00:00+00:00
[2022-01-05 06:01:47,649] {standard_task_runner.py:52} INFO - Started process 1593 to run task
[2022-01-05 06:01:47,653] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T00:00:00+00:00', '--job-id', '175', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmpal5aux2h', '--error-file', '/tmp/tmp90umdex4']
[2022-01-05 06:01:47,654] {standard_task_runner.py:77} INFO - Job 175: Subtask tweet_load
[2022-01-05 06:01:47,733] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [running]> on host 2b1d65872a35
[2022-01-05 06:01:47,797] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T00:00:00+00:00
[2022-01-05 06:01:47,799] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:01:47,799] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:01:47,799] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:01:47,800] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:01:47,800] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:01:47,800] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:01:47,800] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:01:47,800] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:01:47,800] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:01:47,801] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:01:47,801] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:01:47,801] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:01:47,801] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7fd8b40b1950>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 00:00:00+00:00: scheduled__2021-12-31T00:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 1, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 0, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 0, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 0, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 1, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-30', 'prev_ds_nodash': '20211230', 'prev_execution_date': DateTime(2021, 12, 30, 23, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T00:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T00:00:00+00:00', 'ts_nodash': '20211231T000000', 'ts_nodash_with_tz': '20211231T000000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T00:00:00+00:00', 'tsnodash_var': '20211231T000000', 'templates_dict': None}
[2022-01-05 06:01:47,801] {logging_mixin.py:109} INFO - Hello, Current Time:06:01:47 Execution time is 2021-12-31T00:00:00+00:00
[2022-01-05 06:01:47,819] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 06:01:47,829] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 06:01:49,340] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
psycopg2.errors.NumericValueOutOfRange: numeric value "2729515294" out of range for integer


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 133, in load_tweets
    tweet_data.to_sql('tweet', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1770, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1350, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1340, in insert_records
    table.insert(chunksize=chunksize, method=method)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 967, in insert
    exec_insert(conn, keys, chunk_iter)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 882, in _execute_insert
    conn.execute(self.table.insert(), data)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
sqlalchemy.exc.DataError: (psycopg2.errors.NumericValueOutOfRange) numeric value "2729515294" out of range for integer

[SQL: INSERT INTO tweet (author_id, created_at, id, original_text, location) VALUES (%(author_id)s, %(created_at)s, %(id)s, %(original_text)s, %(location)s)]
[parameters: ({'author_id': 2729515294, 'created_at': '2021-12-31T00:09:59.000Z', 'id': 1476707170444001286, 'original_text': 'The Cleveland Cavaliers are nearing a trade to acquire Los Angeles Lakers guard Rajon Rondo -- and an agreement is expected to be reached as soon as Friday, sources tell ESPN. Rondo would be able to join Cleveland as soon as he clears Covid protocols.', 'location': 'Z 🌎'}, {'author_id': 1365590270, 'created_at': '2021-12-31T00:09:59.000Z', 'id': 1476707170028720136, 'original_text': '@RekietaMedia https://t.co/MQLbyvNGdF', 'location': 'Detroit Lakes, MN'}, {'author_id': 18570600, 'created_at': '2021-12-31T00:09:59.000Z', 'id': 1476707170024525830, 'original_text': '“I’m here for a good time, not a long time” between Covid and climate change, you’re here for neither', 'location': None}, {'author_id': 814255276161429509, 'created_at': '2021-12-31T00:09:59.000Z', 'id': 1476707170003689475, 'original_text': 'Assim nós que nunca apanhamos covid não merecemos nenhum prêmio … nenhuma gala… nada ?\nFaçam um Covid Awards, nós merecemos', 'location': 'Braga, Portugal'}, {'author_id': 3195361197, 'created_at': '2021-12-31T00:09:59.000Z', 'id': 1476707169928200200, 'original_text': 'The @CDCgov is reporting 111,008 new confirmed COVID cases in Florida over the last 48 hours. https://t.co/aLPCxMLEGY', 'location': 'Clearwater, FL'}, {'author_id': 2460479600, 'created_at': '2021-12-31T00:09:59.000Z', 'id': 1476707169785450500, 'original_text': 'I know more people who suffered adverse SERIOUS side effects from the jabs than from having covid. People have legit reasons to not take the vax, but ... (5 characters truncated) ... Left has been indoctrinated to firmly believe that the rest of us are racist. Even though people of all races refuse the vax. https://t.co/mwQWRIoFw4', 'location': 'San Diego, CA'}, {'author_id': 1154568985125556224, 'created_at': '2021-12-31T00:09:59.000Z', 'id': 1476707169672339456, 'original_text': 'Alguien sin covid para hacer alguna?', 'location': None}, {'author_id': 4070570903, 'created_at': '2021-12-31T00:09:59.000Z', 'id': 1476707169286467584, 'original_text': 'Con covid reina https://t.co/JVVJMcxsGS', 'location': 'Villa Dolores, Argentina'}, {'author_id': 1456500642462060546, 'created_at': '2021-12-31T00:09:59.000Z', 'id': 1476707169164693516, 'original_text': 'The 4 passengers had concealed gold in their rectums and pockets of trousers.\n\n#TamilNadu \n\nhttps://t.co/k6aCeGu8Mc', 'location': None})]
(Background on this error at: http://sqlalche.me/e/13/9h9h)
[2022-01-05 06:01:49,360] {taskinstance.py:1277} INFO - Marking task as FAILED. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T000000, start_date=20220105T060147, end_date=20220105T060149
[2022-01-05 06:01:49,376] {standard_task_runner.py:92} ERROR - Failed to execute job 175 for task tweet_load
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
psycopg2.errors.NumericValueOutOfRange: numeric value "2729515294" out of range for integer


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 133, in load_tweets
    tweet_data.to_sql('tweet', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1770, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1350, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1340, in insert_records
    table.insert(chunksize=chunksize, method=method)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 967, in insert
    exec_insert(conn, keys, chunk_iter)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 882, in _execute_insert
    conn.execute(self.table.insert(), data)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
sqlalchemy.exc.DataError: (psycopg2.errors.NumericValueOutOfRange) numeric value "2729515294" out of range for integer

[SQL: INSERT INTO tweet (author_id, created_at, id, original_text, location) VALUES (%(author_id)s, %(created_at)s, %(id)s, %(original_text)s, %(location)s)]
[parameters: ({'author_id': 2729515294, 'created_at': '2021-12-31T00:09:59.000Z', 'id': 1476707170444001286, 'original_text': 'The Cleveland Cavaliers are nearing a trade to acquire Los Angeles Lakers guard Rajon Rondo -- and an agreement is expected to be reached as soon as Friday, sources tell ESPN. Rondo would be able to join Cleveland as soon as he clears Covid protocols.', 'location': 'Z 🌎'}, {'author_id': 1365590270, 'created_at': '2021-12-31T00:09:59.000Z', 'id': 1476707170028720136, 'original_text': '@RekietaMedia https://t.co/MQLbyvNGdF', 'location': 'Detroit Lakes, MN'}, {'author_id': 18570600, 'created_at': '2021-12-31T00:09:59.000Z', 'id': 1476707170024525830, 'original_text': '“I’m here for a good time, not a long time” between Covid and climate change, you’re here for neither', 'location': None}, {'author_id': 814255276161429509, 'created_at': '2021-12-31T00:09:59.000Z', 'id': 1476707170003689475, 'original_text': 'Assim nós que nunca apanhamos covid não merecemos nenhum prêmio … nenhuma gala… nada ?\nFaçam um Covid Awards, nós merecemos', 'location': 'Braga, Portugal'}, {'author_id': 3195361197, 'created_at': '2021-12-31T00:09:59.000Z', 'id': 1476707169928200200, 'original_text': 'The @CDCgov is reporting 111,008 new confirmed COVID cases in Florida over the last 48 hours. https://t.co/aLPCxMLEGY', 'location': 'Clearwater, FL'}, {'author_id': 2460479600, 'created_at': '2021-12-31T00:09:59.000Z', 'id': 1476707169785450500, 'original_text': 'I know more people who suffered adverse SERIOUS side effects from the jabs than from having covid. People have legit reasons to not take the vax, but ... (5 characters truncated) ... Left has been indoctrinated to firmly believe that the rest of us are racist. Even though people of all races refuse the vax. https://t.co/mwQWRIoFw4', 'location': 'San Diego, CA'}, {'author_id': 1154568985125556224, 'created_at': '2021-12-31T00:09:59.000Z', 'id': 1476707169672339456, 'original_text': 'Alguien sin covid para hacer alguna?', 'location': None}, {'author_id': 4070570903, 'created_at': '2021-12-31T00:09:59.000Z', 'id': 1476707169286467584, 'original_text': 'Con covid reina https://t.co/JVVJMcxsGS', 'location': 'Villa Dolores, Argentina'}, {'author_id': 1456500642462060546, 'created_at': '2021-12-31T00:09:59.000Z', 'id': 1476707169164693516, 'original_text': 'The 4 passengers had concealed gold in their rectums and pockets of trousers.\n\n#TamilNadu \n\nhttps://t.co/k6aCeGu8Mc', 'location': None})]
(Background on this error at: http://sqlalche.me/e/13/9h9h)
[2022-01-05 06:01:49,398] {local_task_job.py:154} INFO - Task exited with return code 1
[2022-01-05 06:01:49,439] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-01-05 06:06:14,466] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [queued]>
[2022-01-05 06:06:14,489] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [queued]>
[2022-01-05 06:06:14,490] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 06:06:14,490] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 06:06:14,490] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 06:06:14,515] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 00:00:00+00:00
[2022-01-05 06:06:14,540] {standard_task_runner.py:52} INFO - Started process 1859 to run task
[2022-01-05 06:06:14,573] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T00:00:00+00:00', '--job-id', '196', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmp2uhgpdab', '--error-file', '/tmp/tmp5if9zrzz']
[2022-01-05 06:06:14,574] {standard_task_runner.py:77} INFO - Job 196: Subtask tweet_load
[2022-01-05 06:06:14,720] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [running]> on host 2b1d65872a35
[2022-01-05 06:06:14,822] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T00:00:00+00:00
[2022-01-05 06:06:14,824] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:06:14,824] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:06:14,824] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:06:14,825] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:06:14,825] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:06:14,825] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:06:14,825] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:06:14,825] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:06:14,825] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:06:14,825] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:06:14,826] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:06:14,826] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:06:14,826] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7fd8b40b1950>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 00:00:00+00:00: scheduled__2021-12-31T00:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 1, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 0, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 0, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 0, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 1, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-30', 'prev_ds_nodash': '20211230', 'prev_execution_date': DateTime(2021, 12, 30, 23, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T00:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T00:00:00+00:00', 'ts_nodash': '20211231T000000', 'ts_nodash_with_tz': '20211231T000000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T00:00:00+00:00', 'tsnodash_var': '20211231T000000', 'templates_dict': None}
[2022-01-05 06:06:14,826] {logging_mixin.py:109} INFO - Hello, Current Time:06:06:14 Execution time is 2021-12-31T00:00:00+00:00
[2022-01-05 06:06:14,893] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 06:06:14,929] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 06:06:16,326] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
psycopg2.errors.StringDataRightTruncation: value too long for type character varying(200)


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 136, in load_tweets
    tweet_data.to_sql('tweet', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1770, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1350, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1340, in insert_records
    table.insert(chunksize=chunksize, method=method)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 967, in insert
    exec_insert(conn, keys, chunk_iter)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 882, in _execute_insert
    conn.execute(self.table.insert(), data)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
sqlalchemy.exc.DataError: (psycopg2.errors.StringDataRightTruncation) value too long for type character varying(200)

[SQL: INSERT INTO tweet (created_at, author_id, id, original_text, location) VALUES (%(created_at)s, %(author_id)s, %(id)s, %(original_text)s, %(location)s)]
[parameters: ({'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 2729515294, 'id': 2729515294, 'original_text': 'The Cleveland Cavaliers are nearing a trade to acquire Los Angeles Lakers guard Rajon Rondo -- and an agreement is expected to be reached as soon as Friday, sources tell ESPN. Rondo would be able to join Cleveland as soon as he clears Covid protocols.', 'location': 'Z 🌎'}, {'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 1365590270, 'id': 1365590270, 'original_text': '@RekietaMedia https://t.co/MQLbyvNGdF', 'location': 'Detroit Lakes, MN'}, {'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 18570600, 'id': 18570600, 'original_text': '“I’m here for a good time, not a long time” between Covid and climate change, you’re here for neither', 'location': None}, {'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 814255276161429509, 'id': 814255276161429509, 'original_text': 'Assim nós que nunca apanhamos covid não merecemos nenhum prêmio … nenhuma gala… nada ?\nFaçam um Covid Awards, nós merecemos', 'location': 'Braga, Portugal'}, {'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 3195361197, 'id': 3195361197, 'original_text': 'The @CDCgov is reporting 111,008 new confirmed COVID cases in Florida over the last 48 hours. https://t.co/aLPCxMLEGY', 'location': 'Clearwater, FL'}, {'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 2460479600, 'id': 2460479600, 'original_text': 'I know more people who suffered adverse SERIOUS side effects from the jabs than from having covid. People have legit reasons to not take the vax, but ... (5 characters truncated) ... Left has been indoctrinated to firmly believe that the rest of us are racist. Even though people of all races refuse the vax. https://t.co/mwQWRIoFw4', 'location': 'San Diego, CA'}, {'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 1154568985125556224, 'id': 1154568985125556224, 'original_text': 'Alguien sin covid para hacer alguna?', 'location': None}, {'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 4070570903, 'id': 4070570903, 'original_text': 'Con covid reina https://t.co/JVVJMcxsGS', 'location': 'Villa Dolores, Argentina'}, {'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 1456500642462060546, 'id': 1456500642462060546, 'original_text': 'The 4 passengers had concealed gold in their rectums and pockets of trousers.\n\n#TamilNadu \n\nhttps://t.co/k6aCeGu8Mc', 'location': None})]
(Background on this error at: http://sqlalche.me/e/13/9h9h)
[2022-01-05 06:06:16,339] {taskinstance.py:1277} INFO - Marking task as FAILED. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T000000, start_date=20220105T060614, end_date=20220105T060616
[2022-01-05 06:06:16,351] {standard_task_runner.py:92} ERROR - Failed to execute job 196 for task tweet_load
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
psycopg2.errors.StringDataRightTruncation: value too long for type character varying(200)


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 136, in load_tweets
    tweet_data.to_sql('tweet', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1770, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1350, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1340, in insert_records
    table.insert(chunksize=chunksize, method=method)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 967, in insert
    exec_insert(conn, keys, chunk_iter)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 882, in _execute_insert
    conn.execute(self.table.insert(), data)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
sqlalchemy.exc.DataError: (psycopg2.errors.StringDataRightTruncation) value too long for type character varying(200)

[SQL: INSERT INTO tweet (created_at, author_id, id, original_text, location) VALUES (%(created_at)s, %(author_id)s, %(id)s, %(original_text)s, %(location)s)]
[parameters: ({'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 2729515294, 'id': 2729515294, 'original_text': 'The Cleveland Cavaliers are nearing a trade to acquire Los Angeles Lakers guard Rajon Rondo -- and an agreement is expected to be reached as soon as Friday, sources tell ESPN. Rondo would be able to join Cleveland as soon as he clears Covid protocols.', 'location': 'Z 🌎'}, {'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 1365590270, 'id': 1365590270, 'original_text': '@RekietaMedia https://t.co/MQLbyvNGdF', 'location': 'Detroit Lakes, MN'}, {'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 18570600, 'id': 18570600, 'original_text': '“I’m here for a good time, not a long time” between Covid and climate change, you’re here for neither', 'location': None}, {'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 814255276161429509, 'id': 814255276161429509, 'original_text': 'Assim nós que nunca apanhamos covid não merecemos nenhum prêmio … nenhuma gala… nada ?\nFaçam um Covid Awards, nós merecemos', 'location': 'Braga, Portugal'}, {'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 3195361197, 'id': 3195361197, 'original_text': 'The @CDCgov is reporting 111,008 new confirmed COVID cases in Florida over the last 48 hours. https://t.co/aLPCxMLEGY', 'location': 'Clearwater, FL'}, {'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 2460479600, 'id': 2460479600, 'original_text': 'I know more people who suffered adverse SERIOUS side effects from the jabs than from having covid. People have legit reasons to not take the vax, but ... (5 characters truncated) ... Left has been indoctrinated to firmly believe that the rest of us are racist. Even though people of all races refuse the vax. https://t.co/mwQWRIoFw4', 'location': 'San Diego, CA'}, {'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 1154568985125556224, 'id': 1154568985125556224, 'original_text': 'Alguien sin covid para hacer alguna?', 'location': None}, {'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 4070570903, 'id': 4070570903, 'original_text': 'Con covid reina https://t.co/JVVJMcxsGS', 'location': 'Villa Dolores, Argentina'}, {'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 1456500642462060546, 'id': 1456500642462060546, 'original_text': 'The 4 passengers had concealed gold in their rectums and pockets of trousers.\n\n#TamilNadu \n\nhttps://t.co/k6aCeGu8Mc', 'location': None})]
(Background on this error at: http://sqlalche.me/e/13/9h9h)
[2022-01-05 06:06:16,377] {local_task_job.py:154} INFO - Task exited with return code 1
[2022-01-05 06:06:16,407] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-01-05 06:09:20,891] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [queued]>
[2022-01-05 06:09:20,934] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [queued]>
[2022-01-05 06:09:20,935] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 06:09:20,935] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 06:09:20,935] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 06:09:20,991] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 00:00:00+00:00
[2022-01-05 06:09:20,999] {standard_task_runner.py:52} INFO - Started process 2043 to run task
[2022-01-05 06:09:21,009] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T00:00:00+00:00', '--job-id', '212', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmprr8tpwij', '--error-file', '/tmp/tmpr1kuvlil']
[2022-01-05 06:09:21,010] {standard_task_runner.py:77} INFO - Job 212: Subtask tweet_load
[2022-01-05 06:09:21,193] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [running]> on host 2b1d65872a35
[2022-01-05 06:09:21,361] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T00:00:00+00:00
[2022-01-05 06:09:21,363] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:09:21,364] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:09:21,364] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:09:21,364] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:09:21,364] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:09:21,364] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:09:21,365] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:09:21,365] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:09:21,365] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:09:21,365] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:09:21,365] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:09:21,365] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:09:21,366] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7fd8b40b1950>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 00:00:00+00:00: scheduled__2021-12-31T00:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 1, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 0, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 0, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 0, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 1, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-30', 'prev_ds_nodash': '20211230', 'prev_execution_date': DateTime(2021, 12, 30, 23, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T00:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T00:00:00+00:00', 'ts_nodash': '20211231T000000', 'ts_nodash_with_tz': '20211231T000000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T00:00:00+00:00', 'tsnodash_var': '20211231T000000', 'templates_dict': None}
[2022-01-05 06:09:21,366] {logging_mixin.py:109} INFO - Hello, Current Time:06:09:21 Execution time is 2021-12-31T00:00:00+00:00
[2022-01-05 06:09:21,413] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 06:09:21,439] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 06:09:23,586] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
psycopg2.errors.StringDataRightTruncation: value too long for type character varying(256)


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 136, in load_tweets
    tweet_data.to_sql('tweet', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1770, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1350, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1340, in insert_records
    table.insert(chunksize=chunksize, method=method)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 967, in insert
    exec_insert(conn, keys, chunk_iter)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 882, in _execute_insert
    conn.execute(self.table.insert(), data)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
sqlalchemy.exc.DataError: (psycopg2.errors.StringDataRightTruncation) value too long for type character varying(256)

[SQL: INSERT INTO tweet (author_id, created_at, id, original_text, location) VALUES (%(author_id)s, %(created_at)s, %(id)s, %(original_text)s, %(location)s)]
[parameters: ({'author_id': 2729515294, 'created_at': '2021-12-31T00:09:59.000Z', 'id': 2729515294, 'original_text': 'The Cleveland Cavaliers are nearing a trade to acquire Los Angeles Lakers guard Rajon Rondo -- and an agreement is expected to be reached as soon as Friday, sources tell ESPN. Rondo would be able to join Cleveland as soon as he clears Covid protocols.', 'location': 'Z 🌎'}, {'author_id': 1365590270, 'created_at': '2021-12-31T00:09:59.000Z', 'id': 1365590270, 'original_text': '@RekietaMedia https://t.co/MQLbyvNGdF', 'location': 'Detroit Lakes, MN'}, {'author_id': 18570600, 'created_at': '2021-12-31T00:09:59.000Z', 'id': 18570600, 'original_text': '“I’m here for a good time, not a long time” between Covid and climate change, you’re here for neither', 'location': None}, {'author_id': 814255276161429509, 'created_at': '2021-12-31T00:09:59.000Z', 'id': 814255276161429509, 'original_text': 'Assim nós que nunca apanhamos covid não merecemos nenhum prêmio … nenhuma gala… nada ?\nFaçam um Covid Awards, nós merecemos', 'location': 'Braga, Portugal'}, {'author_id': 3195361197, 'created_at': '2021-12-31T00:09:59.000Z', 'id': 3195361197, 'original_text': 'The @CDCgov is reporting 111,008 new confirmed COVID cases in Florida over the last 48 hours. https://t.co/aLPCxMLEGY', 'location': 'Clearwater, FL'}, {'author_id': 2460479600, 'created_at': '2021-12-31T00:09:59.000Z', 'id': 2460479600, 'original_text': 'I know more people who suffered adverse SERIOUS side effects from the jabs than from having covid. People have legit reasons to not take the vax, but ... (5 characters truncated) ... Left has been indoctrinated to firmly believe that the rest of us are racist. Even though people of all races refuse the vax. https://t.co/mwQWRIoFw4', 'location': 'San Diego, CA'}, {'author_id': 1154568985125556224, 'created_at': '2021-12-31T00:09:59.000Z', 'id': 1154568985125556224, 'original_text': 'Alguien sin covid para hacer alguna?', 'location': None}, {'author_id': 4070570903, 'created_at': '2021-12-31T00:09:59.000Z', 'id': 4070570903, 'original_text': 'Con covid reina https://t.co/JVVJMcxsGS', 'location': 'Villa Dolores, Argentina'}, {'author_id': 1456500642462060546, 'created_at': '2021-12-31T00:09:59.000Z', 'id': 1456500642462060546, 'original_text': 'The 4 passengers had concealed gold in their rectums and pockets of trousers.\n\n#TamilNadu \n\nhttps://t.co/k6aCeGu8Mc', 'location': None})]
(Background on this error at: http://sqlalche.me/e/13/9h9h)
[2022-01-05 06:09:23,659] {taskinstance.py:1277} INFO - Marking task as FAILED. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T000000, start_date=20220105T060920, end_date=20220105T060923
[2022-01-05 06:09:23,762] {standard_task_runner.py:92} ERROR - Failed to execute job 212 for task tweet_load
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
psycopg2.errors.StringDataRightTruncation: value too long for type character varying(256)


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 136, in load_tweets
    tweet_data.to_sql('tweet', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1770, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1350, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1340, in insert_records
    table.insert(chunksize=chunksize, method=method)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 967, in insert
    exec_insert(conn, keys, chunk_iter)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 882, in _execute_insert
    conn.execute(self.table.insert(), data)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
sqlalchemy.exc.DataError: (psycopg2.errors.StringDataRightTruncation) value too long for type character varying(256)

[SQL: INSERT INTO tweet (author_id, created_at, id, original_text, location) VALUES (%(author_id)s, %(created_at)s, %(id)s, %(original_text)s, %(location)s)]
[parameters: ({'author_id': 2729515294, 'created_at': '2021-12-31T00:09:59.000Z', 'id': 2729515294, 'original_text': 'The Cleveland Cavaliers are nearing a trade to acquire Los Angeles Lakers guard Rajon Rondo -- and an agreement is expected to be reached as soon as Friday, sources tell ESPN. Rondo would be able to join Cleveland as soon as he clears Covid protocols.', 'location': 'Z 🌎'}, {'author_id': 1365590270, 'created_at': '2021-12-31T00:09:59.000Z', 'id': 1365590270, 'original_text': '@RekietaMedia https://t.co/MQLbyvNGdF', 'location': 'Detroit Lakes, MN'}, {'author_id': 18570600, 'created_at': '2021-12-31T00:09:59.000Z', 'id': 18570600, 'original_text': '“I’m here for a good time, not a long time” between Covid and climate change, you’re here for neither', 'location': None}, {'author_id': 814255276161429509, 'created_at': '2021-12-31T00:09:59.000Z', 'id': 814255276161429509, 'original_text': 'Assim nós que nunca apanhamos covid não merecemos nenhum prêmio … nenhuma gala… nada ?\nFaçam um Covid Awards, nós merecemos', 'location': 'Braga, Portugal'}, {'author_id': 3195361197, 'created_at': '2021-12-31T00:09:59.000Z', 'id': 3195361197, 'original_text': 'The @CDCgov is reporting 111,008 new confirmed COVID cases in Florida over the last 48 hours. https://t.co/aLPCxMLEGY', 'location': 'Clearwater, FL'}, {'author_id': 2460479600, 'created_at': '2021-12-31T00:09:59.000Z', 'id': 2460479600, 'original_text': 'I know more people who suffered adverse SERIOUS side effects from the jabs than from having covid. People have legit reasons to not take the vax, but ... (5 characters truncated) ... Left has been indoctrinated to firmly believe that the rest of us are racist. Even though people of all races refuse the vax. https://t.co/mwQWRIoFw4', 'location': 'San Diego, CA'}, {'author_id': 1154568985125556224, 'created_at': '2021-12-31T00:09:59.000Z', 'id': 1154568985125556224, 'original_text': 'Alguien sin covid para hacer alguna?', 'location': None}, {'author_id': 4070570903, 'created_at': '2021-12-31T00:09:59.000Z', 'id': 4070570903, 'original_text': 'Con covid reina https://t.co/JVVJMcxsGS', 'location': 'Villa Dolores, Argentina'}, {'author_id': 1456500642462060546, 'created_at': '2021-12-31T00:09:59.000Z', 'id': 1456500642462060546, 'original_text': 'The 4 passengers had concealed gold in their rectums and pockets of trousers.\n\n#TamilNadu \n\nhttps://t.co/k6aCeGu8Mc', 'location': None})]
(Background on this error at: http://sqlalche.me/e/13/9h9h)
[2022-01-05 06:09:23,786] {local_task_job.py:154} INFO - Task exited with return code 1
[2022-01-05 06:09:23,836] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-01-05 06:25:32,304] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [queued]>
[2022-01-05 06:25:32,350] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [queued]>
[2022-01-05 06:25:32,351] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 06:25:32,351] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 06:25:32,351] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 06:25:32,380] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 00:00:00+00:00
[2022-01-05 06:25:32,394] {standard_task_runner.py:52} INFO - Started process 2819 to run task
[2022-01-05 06:25:32,406] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T00:00:00+00:00', '--job-id', '230', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmpaouyece2', '--error-file', '/tmp/tmp9i_wssop']
[2022-01-05 06:25:32,407] {standard_task_runner.py:77} INFO - Job 230: Subtask tweet_load
[2022-01-05 06:25:32,528] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [running]> on host 2b1d65872a35
[2022-01-05 06:25:32,654] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T00:00:00+00:00
[2022-01-05 06:25:32,656] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:25:32,656] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:25:32,657] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:25:32,657] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:25:32,657] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:25:32,657] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:25:32,657] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:25:32,657] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:25:32,657] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:25:32,658] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:25:32,658] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:25:32,658] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:25:32,658] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7fd8b40b1950>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 00:00:00+00:00: scheduled__2021-12-31T00:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 1, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 0, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 0, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 0, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 1, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-30', 'prev_ds_nodash': '20211230', 'prev_execution_date': DateTime(2021, 12, 30, 23, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T00:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T00:00:00+00:00', 'ts_nodash': '20211231T000000', 'ts_nodash_with_tz': '20211231T000000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T00:00:00+00:00', 'tsnodash_var': '20211231T000000', 'templates_dict': None}
[2022-01-05 06:25:32,658] {logging_mixin.py:109} INFO - Hello, Current Time:06:25:32 Execution time is 2021-12-31T00:00:00+00:00
[2022-01-05 06:25:32,706] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 06:25:32,727] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 06:25:34,636] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
psycopg2.errors.StringDataRightTruncation: value too long for type character varying(256)


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 137, in load_tweets
    tweet_data.to_sql('tweet', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1770, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1350, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1340, in insert_records
    table.insert(chunksize=chunksize, method=method)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 967, in insert
    exec_insert(conn, keys, chunk_iter)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 882, in _execute_insert
    conn.execute(self.table.insert(), data)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
sqlalchemy.exc.DataError: (psycopg2.errors.StringDataRightTruncation) value too long for type character varying(256)

[SQL: INSERT INTO tweet (created_at, author_id, id, original_text, location) VALUES (%(created_at)s, %(author_id)s, %(id)s, %(original_text)s, %(location)s)]
[parameters: ({'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 2729515294, 'id': 2729515294, 'original_text': 'The Cleveland Cavaliers are nearing a trade to acquire Los Angeles Lakers guard Rajon Rondo -- and an agreement is expected to be reached as soon as Friday, sources tell ESPN. Rondo would be able to join Cleveland as soon as he clears Covid protocols.', 'location': 'Z '}, {'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 1365590270, 'id': 1365590270, 'original_text': '@RekietaMedia https://t.co/MQLbyvNGdF', 'location': 'Detroit Lakes, MN'}, {'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 18570600, 'id': 18570600, 'original_text': 'Im here for a good time, not a long time between Covid and climate change, youre here for neither', 'location': None}, {'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 814255276161429509, 'id': 814255276161429509, 'original_text': 'Assim ns que nunca apanhamos covid no merecemos nenhum prmio  nenhuma gala nada ?\nFaam um Covid Awards, ns merecemos', 'location': 'Braga, Portugal'}, {'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 3195361197, 'id': 3195361197, 'original_text': 'The @CDCgov is reporting 111,008 new confirmed COVID cases in Florida over the last 48 hours. https://t.co/aLPCxMLEGY', 'location': 'Clearwater, FL'}, {'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 2460479600, 'id': 2460479600, 'original_text': 'I know more people who suffered adverse SERIOUS side effects from the jabs than from having covid. People have legit reasons to not take the vax, but ... (5 characters truncated) ... Left has been indoctrinated to firmly believe that the rest of us are racist. Even though people of all races refuse the vax. https://t.co/mwQWRIoFw4', 'location': 'San Diego, CA'}, {'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 1154568985125556224, 'id': 1154568985125556224, 'original_text': 'Alguien sin covid para hacer alguna?', 'location': None}, {'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 4070570903, 'id': 4070570903, 'original_text': 'Con covid reina https://t.co/JVVJMcxsGS', 'location': 'Villa Dolores, Argentina'}, {'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 1456500642462060546, 'id': 1456500642462060546, 'original_text': 'The 4 passengers had concealed gold in their rectums and pockets of trousers.\n\n#TamilNadu \n\nhttps://t.co/k6aCeGu8Mc', 'location': None})]
(Background on this error at: http://sqlalche.me/e/13/9h9h)
[2022-01-05 06:25:34,663] {taskinstance.py:1277} INFO - Marking task as FAILED. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T000000, start_date=20220105T062532, end_date=20220105T062534
[2022-01-05 06:25:34,683] {standard_task_runner.py:92} ERROR - Failed to execute job 230 for task tweet_load
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
psycopg2.errors.StringDataRightTruncation: value too long for type character varying(256)


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 137, in load_tweets
    tweet_data.to_sql('tweet', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1770, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1350, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1340, in insert_records
    table.insert(chunksize=chunksize, method=method)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 967, in insert
    exec_insert(conn, keys, chunk_iter)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 882, in _execute_insert
    conn.execute(self.table.insert(), data)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
sqlalchemy.exc.DataError: (psycopg2.errors.StringDataRightTruncation) value too long for type character varying(256)

[SQL: INSERT INTO tweet (created_at, author_id, id, original_text, location) VALUES (%(created_at)s, %(author_id)s, %(id)s, %(original_text)s, %(location)s)]
[parameters: ({'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 2729515294, 'id': 2729515294, 'original_text': 'The Cleveland Cavaliers are nearing a trade to acquire Los Angeles Lakers guard Rajon Rondo -- and an agreement is expected to be reached as soon as Friday, sources tell ESPN. Rondo would be able to join Cleveland as soon as he clears Covid protocols.', 'location': 'Z '}, {'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 1365590270, 'id': 1365590270, 'original_text': '@RekietaMedia https://t.co/MQLbyvNGdF', 'location': 'Detroit Lakes, MN'}, {'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 18570600, 'id': 18570600, 'original_text': 'Im here for a good time, not a long time between Covid and climate change, youre here for neither', 'location': None}, {'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 814255276161429509, 'id': 814255276161429509, 'original_text': 'Assim ns que nunca apanhamos covid no merecemos nenhum prmio  nenhuma gala nada ?\nFaam um Covid Awards, ns merecemos', 'location': 'Braga, Portugal'}, {'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 3195361197, 'id': 3195361197, 'original_text': 'The @CDCgov is reporting 111,008 new confirmed COVID cases in Florida over the last 48 hours. https://t.co/aLPCxMLEGY', 'location': 'Clearwater, FL'}, {'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 2460479600, 'id': 2460479600, 'original_text': 'I know more people who suffered adverse SERIOUS side effects from the jabs than from having covid. People have legit reasons to not take the vax, but ... (5 characters truncated) ... Left has been indoctrinated to firmly believe that the rest of us are racist. Even though people of all races refuse the vax. https://t.co/mwQWRIoFw4', 'location': 'San Diego, CA'}, {'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 1154568985125556224, 'id': 1154568985125556224, 'original_text': 'Alguien sin covid para hacer alguna?', 'location': None}, {'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 4070570903, 'id': 4070570903, 'original_text': 'Con covid reina https://t.co/JVVJMcxsGS', 'location': 'Villa Dolores, Argentina'}, {'created_at': '2021-12-31T00:09:59.000Z', 'author_id': 1456500642462060546, 'id': 1456500642462060546, 'original_text': 'The 4 passengers had concealed gold in their rectums and pockets of trousers.\n\n#TamilNadu \n\nhttps://t.co/k6aCeGu8Mc', 'location': None})]
(Background on this error at: http://sqlalche.me/e/13/9h9h)
[2022-01-05 06:25:34,704] {local_task_job.py:154} INFO - Task exited with return code 1
[2022-01-05 06:25:34,751] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-01-05 06:28:26,954] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [queued]>
[2022-01-05 06:28:26,972] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [queued]>
[2022-01-05 06:28:26,972] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 06:28:26,973] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 06:28:26,973] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 06:28:26,993] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 00:00:00+00:00
[2022-01-05 06:28:26,999] {standard_task_runner.py:52} INFO - Started process 3000 to run task
[2022-01-05 06:28:27,016] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T00:00:00+00:00', '--job-id', '248', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmphhwsyafd', '--error-file', '/tmp/tmps4xg2wy_']
[2022-01-05 06:28:27,017] {standard_task_runner.py:77} INFO - Job 248: Subtask tweet_load
[2022-01-05 06:28:27,156] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [running]> on host 2b1d65872a35
[2022-01-05 06:28:27,263] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T00:00:00+00:00
[2022-01-05 06:28:27,264] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:28:27,265] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:28:27,265] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:28:27,265] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:28:27,265] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:28:27,265] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:28:27,265] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:28:27,266] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:28:27,266] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:28:27,266] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:28:27,266] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:28:27,266] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:28:27,267] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7fd8b40b1950>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 00:00:00+00:00: scheduled__2021-12-31T00:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 1, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 0, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 0, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 0, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 1, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-30', 'prev_ds_nodash': '20211230', 'prev_execution_date': DateTime(2021, 12, 30, 23, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T00:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T00:00:00+00:00', 'ts_nodash': '20211231T000000', 'ts_nodash_with_tz': '20211231T000000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T00:00:00+00:00', 'tsnodash_var': '20211231T000000', 'templates_dict': None}
[2022-01-05 06:28:27,267] {logging_mixin.py:109} INFO - Hello, Current Time:06:28:27 Execution time is 2021-12-31T00:00:00+00:00
[2022-01-05 06:28:27,297] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 06:28:27,312] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 06:28:29,222] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
psycopg2.errors.StringDataRightTruncation: value too long for type character varying(256)


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 139, in load_tweets
    tweet_data.to_sql('tweet', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1770, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1350, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1340, in insert_records
    table.insert(chunksize=chunksize, method=method)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 967, in insert
    exec_insert(conn, keys, chunk_iter)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 882, in _execute_insert
    conn.execute(self.table.insert(), data)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
sqlalchemy.exc.DataError: (psycopg2.errors.StringDataRightTruncation) value too long for type character varying(256)

[SQL: INSERT INTO tweet (author_id, created_at, id, original_text, location) VALUES (%(author_id)s, %(created_at)s, %(id)s, %(original_text)s, %(location)s)]
[parameters: ({'author_id': 2729515294, 'created_at': '2021-12-31T00:09:59.000Z', 'id': 2729515294, 'original_text': 'The Cleveland Cavaliers are nearing a trade to acquire Los Angeles Lakers guard Rajon Rondo -- and an agreement is expected to be reached as soon as Friday, sources tell ESPN. Rondo would be able to join Cleveland as soon as he clears Covid protocols.', 'location': 'Z '}, {'author_id': 1365590270, 'created_at': '2021-12-31T00:09:59.000Z', 'id': 1365590270, 'original_text': '@RekietaMedia https://t.co/MQLbyvNGdF', 'location': 'Detroit Lakes, MN'}, {'author_id': 18570600, 'created_at': '2021-12-31T00:09:59.000Z', 'id': 18570600, 'original_text': 'Im here for a good time, not a long time between Covid and climate change, youre here for neither', 'location': None}, {'author_id': 814255276161429509, 'created_at': '2021-12-31T00:09:59.000Z', 'id': 814255276161429509, 'original_text': 'Assim ns que nunca apanhamos covid no merecemos nenhum prmio  nenhuma gala nada ?\nFaam um Covid Awards, ns merecemos', 'location': 'Braga, Portugal'}, {'author_id': 3195361197, 'created_at': '2021-12-31T00:09:59.000Z', 'id': 3195361197, 'original_text': 'The @CDCgov is reporting 111,008 new confirmed COVID cases in Florida over the last 48 hours. https://t.co/aLPCxMLEGY', 'location': 'Clearwater, FL'}, {'author_id': 2460479600, 'created_at': '2021-12-31T00:09:59.000Z', 'id': 2460479600, 'original_text': 'I know more people who suffered adverse SERIOUS side effects from the jabs than from having covid. People have legit reasons to not take the vax, but ... (5 characters truncated) ... Left has been indoctrinated to firmly believe that the rest of us are racist. Even though people of all races refuse the vax. https://t.co/mwQWRIoFw4', 'location': 'San Diego, CA'}, {'author_id': 1154568985125556224, 'created_at': '2021-12-31T00:09:59.000Z', 'id': 1154568985125556224, 'original_text': 'Alguien sin covid para hacer alguna?', 'location': None}, {'author_id': 4070570903, 'created_at': '2021-12-31T00:09:59.000Z', 'id': 4070570903, 'original_text': 'Con covid reina https://t.co/JVVJMcxsGS', 'location': 'Villa Dolores, Argentina'}, {'author_id': 1456500642462060546, 'created_at': '2021-12-31T00:09:59.000Z', 'id': 1456500642462060546, 'original_text': 'The 4 passengers had concealed gold in their rectums and pockets of trousers.\n\n#TamilNadu \n\nhttps://t.co/k6aCeGu8Mc', 'location': None})]
(Background on this error at: http://sqlalche.me/e/13/9h9h)
[2022-01-05 06:28:29,316] {taskinstance.py:1277} INFO - Marking task as FAILED. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T000000, start_date=20220105T062826, end_date=20220105T062829
[2022-01-05 06:28:29,365] {standard_task_runner.py:92} ERROR - Failed to execute job 248 for task tweet_load
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
psycopg2.errors.StringDataRightTruncation: value too long for type character varying(256)


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 139, in load_tweets
    tweet_data.to_sql('tweet', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1770, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1350, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1340, in insert_records
    table.insert(chunksize=chunksize, method=method)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 967, in insert
    exec_insert(conn, keys, chunk_iter)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 882, in _execute_insert
    conn.execute(self.table.insert(), data)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
sqlalchemy.exc.DataError: (psycopg2.errors.StringDataRightTruncation) value too long for type character varying(256)

[SQL: INSERT INTO tweet (author_id, created_at, id, original_text, location) VALUES (%(author_id)s, %(created_at)s, %(id)s, %(original_text)s, %(location)s)]
[parameters: ({'author_id': 2729515294, 'created_at': '2021-12-31T00:09:59.000Z', 'id': 2729515294, 'original_text': 'The Cleveland Cavaliers are nearing a trade to acquire Los Angeles Lakers guard Rajon Rondo -- and an agreement is expected to be reached as soon as Friday, sources tell ESPN. Rondo would be able to join Cleveland as soon as he clears Covid protocols.', 'location': 'Z '}, {'author_id': 1365590270, 'created_at': '2021-12-31T00:09:59.000Z', 'id': 1365590270, 'original_text': '@RekietaMedia https://t.co/MQLbyvNGdF', 'location': 'Detroit Lakes, MN'}, {'author_id': 18570600, 'created_at': '2021-12-31T00:09:59.000Z', 'id': 18570600, 'original_text': 'Im here for a good time, not a long time between Covid and climate change, youre here for neither', 'location': None}, {'author_id': 814255276161429509, 'created_at': '2021-12-31T00:09:59.000Z', 'id': 814255276161429509, 'original_text': 'Assim ns que nunca apanhamos covid no merecemos nenhum prmio  nenhuma gala nada ?\nFaam um Covid Awards, ns merecemos', 'location': 'Braga, Portugal'}, {'author_id': 3195361197, 'created_at': '2021-12-31T00:09:59.000Z', 'id': 3195361197, 'original_text': 'The @CDCgov is reporting 111,008 new confirmed COVID cases in Florida over the last 48 hours. https://t.co/aLPCxMLEGY', 'location': 'Clearwater, FL'}, {'author_id': 2460479600, 'created_at': '2021-12-31T00:09:59.000Z', 'id': 2460479600, 'original_text': 'I know more people who suffered adverse SERIOUS side effects from the jabs than from having covid. People have legit reasons to not take the vax, but ... (5 characters truncated) ... Left has been indoctrinated to firmly believe that the rest of us are racist. Even though people of all races refuse the vax. https://t.co/mwQWRIoFw4', 'location': 'San Diego, CA'}, {'author_id': 1154568985125556224, 'created_at': '2021-12-31T00:09:59.000Z', 'id': 1154568985125556224, 'original_text': 'Alguien sin covid para hacer alguna?', 'location': None}, {'author_id': 4070570903, 'created_at': '2021-12-31T00:09:59.000Z', 'id': 4070570903, 'original_text': 'Con covid reina https://t.co/JVVJMcxsGS', 'location': 'Villa Dolores, Argentina'}, {'author_id': 1456500642462060546, 'created_at': '2021-12-31T00:09:59.000Z', 'id': 1456500642462060546, 'original_text': 'The 4 passengers had concealed gold in their rectums and pockets of trousers.\n\n#TamilNadu \n\nhttps://t.co/k6aCeGu8Mc', 'location': None})]
(Background on this error at: http://sqlalche.me/e/13/9h9h)
[2022-01-05 06:28:29,408] {local_task_job.py:154} INFO - Task exited with return code 1
[2022-01-05 06:28:29,511] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-01-05 06:31:59,666] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [queued]>
[2022-01-05 06:31:59,695] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [queued]>
[2022-01-05 06:31:59,695] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 06:31:59,695] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 06:31:59,695] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 06:31:59,761] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 00:00:00+00:00
[2022-01-05 06:31:59,778] {standard_task_runner.py:52} INFO - Started process 3214 to run task
[2022-01-05 06:31:59,786] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T00:00:00+00:00', '--job-id', '268', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmpykam798r', '--error-file', '/tmp/tmp4adoavfh']
[2022-01-05 06:31:59,789] {standard_task_runner.py:77} INFO - Job 268: Subtask tweet_load
[2022-01-05 06:32:00,040] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [running]> on host 2b1d65872a35
[2022-01-05 06:32:00,359] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T00:00:00+00:00
[2022-01-05 06:32:00,363] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:32:00,363] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:32:00,363] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:32:00,363] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:32:00,364] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:32:00,364] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:32:00,364] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:32:00,364] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:32:00,364] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:32:00,365] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:32:00,365] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:32:00,365] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:32:00,365] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7fd8b40b1950>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 00:00:00+00:00: scheduled__2021-12-31T00:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 1, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 0, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 0, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 0, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 1, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-30', 'prev_ds_nodash': '20211230', 'prev_execution_date': DateTime(2021, 12, 30, 23, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T00:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T00:00:00+00:00', 'ts_nodash': '20211231T000000', 'ts_nodash_with_tz': '20211231T000000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T00:00:00+00:00', 'tsnodash_var': '20211231T000000', 'templates_dict': None}
[2022-01-05 06:32:00,365] {logging_mixin.py:109} INFO - Hello, Current Time:06:32:00 Execution time is 2021-12-31T00:00:00+00:00
[2022-01-05 06:32:00,427] {warnings.py:110} WARNING - /opt/***/dags/load_redshift.py:137: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only
  tweet_data = tweet_data.drop('original_text', 1)

[2022-01-05 06:32:00,641] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 06:32:00,675] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 06:32:15,820] {python.py:175} INFO - Done. Returned value was: None
[2022-01-05 06:32:15,834] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T000000, start_date=20220105T063159, end_date=20220105T063215
[2022-01-05 06:32:15,867] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-01-05 06:32:15,896] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-01-05 07:02:31,828] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [queued]>
[2022-01-05 07:02:31,874] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [queued]>
[2022-01-05 07:02:31,875] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 07:02:31,875] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 07:02:31,875] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 07:02:31,911] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 00:00:00+00:00
[2022-01-05 07:02:31,919] {standard_task_runner.py:52} INFO - Started process 124 to run task
[2022-01-05 07:02:31,928] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T00:00:00+00:00', '--job-id', '326', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmpule69eef', '--error-file', '/tmp/tmpvx210t5k']
[2022-01-05 07:02:31,929] {standard_task_runner.py:77} INFO - Job 326: Subtask tweet_load
[2022-01-05 07:02:32,044] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [running]> on host e544fdb7c66e
[2022-01-05 07:02:32,133] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T00:00:00+00:00
[2022-01-05 07:02:32,135] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:02:32,135] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:02:32,136] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:02:32,136] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:02:32,136] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:02:32,136] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:02:32,136] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:02:32,136] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:02:32,136] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:02:32,136] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:02:32,137] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:02:32,137] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:02:32,138] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7fa6a9eda8d0>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 00:00:00+00:00: scheduled__2021-12-31T00:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 1, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 0, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 0, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 0, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 1, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-30', 'prev_ds_nodash': '20211230', 'prev_execution_date': DateTime(2021, 12, 30, 23, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T00:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T00:00:00+00:00', 'ts_nodash': '20211231T000000', 'ts_nodash_with_tz': '20211231T000000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T00:00:00+00:00', 'tsnodash_var': '20211231T000000', 'templates_dict': None}
[2022-01-05 07:02:32,142] {logging_mixin.py:109} INFO - Hello, Current Time:07:02:32 Execution time is 2021-12-31T00:00:00+00:00
[2022-01-05 07:02:32,149] {warnings.py:110} WARNING - /opt/***/dags/load_redshift.py:137: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only
  tweet_data = tweet_data.drop('original_text', 1)

[2022-01-05 07:02:32,173] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 07:02:32,192] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 07:02:37,379] {python.py:175} INFO - Done. Returned value was: None
[2022-01-05 07:02:37,391] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T000000, start_date=20220105T070231, end_date=20220105T070237
[2022-01-05 07:02:37,420] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-01-05 07:02:37,450] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-01-05 07:04:27,343] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [queued]>
[2022-01-05 07:04:27,362] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [queued]>
[2022-01-05 07:04:27,363] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 07:04:27,363] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 07:04:27,363] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 07:04:27,378] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 00:00:00+00:00
[2022-01-05 07:04:27,386] {standard_task_runner.py:52} INFO - Started process 256 to run task
[2022-01-05 07:04:27,391] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T00:00:00+00:00', '--job-id', '340', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmpamob0gx5', '--error-file', '/tmp/tmpccn70zxi']
[2022-01-05 07:04:27,391] {standard_task_runner.py:77} INFO - Job 340: Subtask tweet_load
[2022-01-05 07:04:27,461] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [running]> on host e544fdb7c66e
[2022-01-05 07:04:27,536] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T00:00:00+00:00
[2022-01-05 07:04:27,539] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:04:27,539] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:04:27,539] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:04:27,539] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:04:27,539] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:04:27,539] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:04:27,539] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:04:27,540] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:04:27,540] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:04:27,540] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:04:27,540] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:04:27,540] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:04:27,541] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7fa6a9eda8d0>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 00:00:00+00:00: scheduled__2021-12-31T00:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 1, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 0, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 0, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 0, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 1, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-30', 'prev_ds_nodash': '20211230', 'prev_execution_date': DateTime(2021, 12, 30, 23, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T00:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T00:00:00+00:00', 'ts_nodash': '20211231T000000', 'ts_nodash_with_tz': '20211231T000000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T00:00:00+00:00', 'tsnodash_var': '20211231T000000', 'templates_dict': None}
[2022-01-05 07:04:27,541] {logging_mixin.py:109} INFO - Hello, Current Time:07:04:27 Execution time is 2021-12-31T00:00:00+00:00
[2022-01-05 07:04:27,563] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 07:04:27,574] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 07:04:43,176] {python.py:175} INFO - Done. Returned value was: None
[2022-01-05 07:04:43,215] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T000000, start_date=20220105T070427, end_date=20220105T070443
[2022-01-05 07:04:43,243] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-01-05 07:04:43,268] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-01-05 18:45:37,578] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [queued]>
[2022-01-05 18:45:37,648] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [queued]>
[2022-01-05 18:45:37,648] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 18:45:37,649] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 18:45:37,649] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 18:45:37,750] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 00:00:00+00:00
[2022-01-05 18:45:37,760] {standard_task_runner.py:52} INFO - Started process 726 to run task
[2022-01-05 18:45:37,776] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T00:00:00+00:00', '--job-id', '370', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmp8vsj7eh4', '--error-file', '/tmp/tmpqx2erhjs']
[2022-01-05 18:45:37,777] {standard_task_runner.py:77} INFO - Job 370: Subtask tweet_load
[2022-01-05 18:45:37,982] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [running]> on host e544fdb7c66e
[2022-01-05 18:45:38,199] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T00:00:00+00:00
[2022-01-05 18:45:38,201] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:45:38,201] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:45:38,201] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:45:38,202] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:45:38,202] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:45:38,202] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:45:38,202] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:45:38,202] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:45:38,202] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:45:38,203] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:45:38,203] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:45:38,206] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:45:38,207] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7ffaccd8cb10>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 00:00:00+00:00: scheduled__2021-12-31T00:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 1, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 0, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 0, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 0, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 1, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-30', 'prev_ds_nodash': '20211230', 'prev_execution_date': DateTime(2021, 12, 30, 23, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T00:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T00:00:00+00:00', 'ts_nodash': '20211231T000000', 'ts_nodash_with_tz': '20211231T000000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T00:00:00+00:00', 'tsnodash_var': '20211231T000000', 'templates_dict': None}
[2022-01-05 18:45:38,207] {logging_mixin.py:109} INFO - Hello, Current Time:18:45:38 Execution time is 2021-12-31T00:00:00+00:00
[2022-01-05 18:45:38,328] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 18:45:38,368] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 18:45:41,647] {python.py:175} INFO - Done. Returned value was: None
[2022-01-05 18:45:41,677] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T000000, start_date=20220105T184537, end_date=20220105T184541
[2022-01-05 18:45:41,720] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-01-05 18:45:41,783] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-01-05 18:46:38,911] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [queued]>
[2022-01-05 18:46:38,932] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [queued]>
[2022-01-05 18:46:38,932] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 18:46:38,933] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 18:46:38,933] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 18:46:38,970] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 00:00:00+00:00
[2022-01-05 18:46:38,978] {standard_task_runner.py:52} INFO - Started process 824 to run task
[2022-01-05 18:46:38,998] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T00:00:00+00:00', '--job-id', '392', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmpa8bxh8__', '--error-file', '/tmp/tmp_15nt1_7']
[2022-01-05 18:46:38,999] {standard_task_runner.py:77} INFO - Job 392: Subtask tweet_load
[2022-01-05 18:46:39,192] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [running]> on host e544fdb7c66e
[2022-01-05 18:46:39,349] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T00:00:00+00:00
[2022-01-05 18:46:39,351] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:46:39,352] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:46:39,352] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:46:39,352] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:46:39,352] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:46:39,352] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:46:39,353] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:46:39,353] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:46:39,353] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:46:39,353] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:46:39,353] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:46:39,353] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:46:39,354] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7ffaccd8cb10>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 00:00:00+00:00: scheduled__2021-12-31T00:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 1, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 0, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 0, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 0, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 1, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-30', 'prev_ds_nodash': '20211230', 'prev_execution_date': DateTime(2021, 12, 30, 23, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T00:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T00:00:00+00:00', 'ts_nodash': '20211231T000000', 'ts_nodash_with_tz': '20211231T000000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T00:00:00+00:00', 'tsnodash_var': '20211231T000000', 'templates_dict': None}
[2022-01-05 18:46:39,354] {logging_mixin.py:109} INFO - Hello, Current Time:18:46:39 Execution time is 2021-12-31T00:00:00+00:00
[2022-01-05 18:46:39,400] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 18:46:39,450] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 18:46:41,615] {python.py:175} INFO - Done. Returned value was: None
[2022-01-05 18:46:41,660] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T000000, start_date=20220105T184638, end_date=20220105T184641
[2022-01-05 18:46:41,789] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-01-05 18:46:41,888] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-01-05 19:23:52,746] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [queued]>
[2022-01-05 19:23:52,788] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [queued]>
[2022-01-05 19:23:52,789] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 19:23:52,789] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 19:23:52,789] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 19:23:52,810] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 00:00:00+00:00
[2022-01-05 19:23:52,822] {standard_task_runner.py:52} INFO - Started process 2649 to run task
[2022-01-05 19:23:52,831] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T00:00:00+00:00', '--job-id', '441', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmps1g_unq2', '--error-file', '/tmp/tmpexvmeq2e']
[2022-01-05 19:23:52,832] {standard_task_runner.py:77} INFO - Job 441: Subtask tweet_load
[2022-01-05 19:23:53,031] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [running]> on host e544fdb7c66e
[2022-01-05 19:23:53,205] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T00:00:00+00:00
[2022-01-05 19:23:53,209] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:23:53,210] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:23:53,210] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:23:53,210] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:23:53,210] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:23:53,210] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:23:53,210] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:23:53,211] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:23:53,211] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:23:53,211] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:23:53,211] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:23:53,211] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:23:53,212] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7ffaccd8cb10>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 00:00:00+00:00: scheduled__2021-12-31T00:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 1, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 0, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 0, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 0, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 1, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-30', 'prev_ds_nodash': '20211230', 'prev_execution_date': DateTime(2021, 12, 30, 23, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T00:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T00:00:00+00:00', 'ts_nodash': '20211231T000000', 'ts_nodash_with_tz': '20211231T000000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T00:00:00+00:00', 'tsnodash_var': '20211231T000000', 'templates_dict': None}
[2022-01-05 19:23:53,212] {logging_mixin.py:109} INFO - Hello, Current Time:19:23:53 Execution time is 2021-12-31T00:00:00+00:00
[2022-01-05 19:23:53,244] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 19:23:53,264] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 19:23:55,578] {python.py:175} INFO - Done. Returned value was: None
[2022-01-05 19:23:55,607] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T000000, start_date=20220105T192352, end_date=20220105T192355
[2022-01-05 19:23:55,721] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-01-05 19:23:55,817] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-01-05 19:28:20,934] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [queued]>
[2022-01-05 19:28:20,963] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [queued]>
[2022-01-05 19:28:20,964] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 19:28:20,964] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 19:28:20,964] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 19:28:20,990] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 00:00:00+00:00
[2022-01-05 19:28:20,998] {standard_task_runner.py:52} INFO - Started process 2895 to run task
[2022-01-05 19:28:21,005] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T00:00:00+00:00', '--job-id', '459', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmpgefk7gru', '--error-file', '/tmp/tmpfd9y6c3w']
[2022-01-05 19:28:21,006] {standard_task_runner.py:77} INFO - Job 459: Subtask tweet_load
[2022-01-05 19:28:21,162] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [running]> on host e544fdb7c66e
[2022-01-05 19:28:21,284] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T00:00:00+00:00
[2022-01-05 19:28:21,285] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:28:21,286] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:28:21,286] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:28:21,286] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:28:21,286] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:28:21,287] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:28:21,287] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:28:21,287] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:28:21,287] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:28:21,287] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:28:21,287] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:28:21,287] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:28:21,288] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7ffaccd8cb10>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 00:00:00+00:00: scheduled__2021-12-31T00:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 1, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 0, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 0, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 0, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 1, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-30', 'prev_ds_nodash': '20211230', 'prev_execution_date': DateTime(2021, 12, 30, 23, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T00:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T00:00:00+00:00', 'ts_nodash': '20211231T000000', 'ts_nodash_with_tz': '20211231T000000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T00:00:00+00:00', 'tsnodash_var': '20211231T000000', 'templates_dict': None}
[2022-01-05 19:28:21,288] {logging_mixin.py:109} INFO - Hello, Current Time:19:28:21 Execution time is 2021-12-31T00:00:00+00:00
[2022-01-05 19:28:21,311] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 19:28:21,324] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 19:28:23,550] {python.py:175} INFO - Done. Returned value was: None
[2022-01-05 19:28:23,588] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T000000, start_date=20220105T192820, end_date=20220105T192823
[2022-01-05 19:28:23,649] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-01-05 19:28:23,808] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-01-05 19:29:18,228] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [queued]>
[2022-01-05 19:29:18,247] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [queued]>
[2022-01-05 19:29:18,247] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 19:29:18,247] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 19:29:18,248] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 19:29:18,268] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 00:00:00+00:00
[2022-01-05 19:29:18,275] {standard_task_runner.py:52} INFO - Started process 3021 to run task
[2022-01-05 19:29:18,285] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T00:00:00+00:00', '--job-id', '487', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmpz1bez3uc', '--error-file', '/tmp/tmpw21am56i']
[2022-01-05 19:29:18,286] {standard_task_runner.py:77} INFO - Job 487: Subtask tweet_load
[2022-01-05 19:29:18,374] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [running]> on host e544fdb7c66e
[2022-01-05 19:29:18,458] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T00:00:00+00:00
[2022-01-05 19:29:18,460] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:29:18,460] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:29:18,461] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:29:18,461] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:29:18,461] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:29:18,461] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:29:18,461] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:29:18,461] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:29:18,462] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:29:18,462] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:29:18,462] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:29:18,462] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:29:18,463] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7ffaccd8cb10>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 00:00:00+00:00: scheduled__2021-12-31T00:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 1, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 0, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 0, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 0, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 1, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-30', 'prev_ds_nodash': '20211230', 'prev_execution_date': DateTime(2021, 12, 30, 23, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T00:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T00:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T00:00:00+00:00', 'ts_nodash': '20211231T000000', 'ts_nodash_with_tz': '20211231T000000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T00:00:00+00:00', 'tsnodash_var': '20211231T000000', 'templates_dict': None}
[2022-01-05 19:29:18,463] {logging_mixin.py:109} INFO - Hello, Current Time:19:29:18 Execution time is 2021-12-31T00:00:00+00:00
[2022-01-05 19:29:18,490] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 19:29:18,502] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 19:29:20,668] {python.py:175} INFO - Done. Returned value was: None
[2022-01-05 19:29:20,684] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T000000, start_date=20220105T192918, end_date=20220105T192920
[2022-01-05 19:29:20,712] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-01-05 19:29:20,751] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
