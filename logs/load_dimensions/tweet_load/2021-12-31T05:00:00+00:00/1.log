[2022-01-03 04:04:46,394] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [queued]>
[2022-01-03 04:04:46,411] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [queued]>
[2022-01-03 04:04:46,411] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-03 04:04:46,411] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-03 04:04:46,411] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-03 04:04:46,427] {taskinstance.py:1259} INFO - Executing <Task(PostgresOperator): tweet_load> on 2021-12-31 05:00:00+00:00
[2022-01-03 04:04:46,434] {standard_task_runner.py:52} INFO - Started process 793 to run task
[2022-01-03 04:04:46,438] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T05:00:00+00:00', '--job-id', '19', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmpgy65fnui', '--error-file', '/tmp/tmpqcx080fb']
[2022-01-03 04:04:46,439] {standard_task_runner.py:77} INFO - Job 19: Subtask tweet_load
[2022-01-03 04:04:46,507] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [running]> on host 2b1d65872a35
[2022-01-03 04:04:46,581] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T05:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T05:00:00+00:00
[2022-01-03 04:04:46,595] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: dev, Login: awsuser, Password: ***, extra: {}
[2022-01-03 04:06:57,519] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/postgres/operators/postgres.py", line 69, in execute
    self.hook.run(self.sql, self.autocommit, parameters=self.parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/hooks/dbapi.py", line 198, in run
    with closing(self.get_conn()) as conn:
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/postgres/hooks/postgres.py", line 115, in get_conn
    self.conn = psycopg2.connect(**conn_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com" (172.31.45.95), port 5439 failed: Connection timed out
	Is the server running on that host and accepting TCP/IP connections?

[2022-01-03 04:06:57,538] {taskinstance.py:1277} INFO - Marking task as FAILED. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T050000, start_date=20220103T040446, end_date=20220103T040657
[2022-01-03 04:06:57,560] {standard_task_runner.py:92} ERROR - Failed to execute job 19 for task tweet_load
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/postgres/operators/postgres.py", line 69, in execute
    self.hook.run(self.sql, self.autocommit, parameters=self.parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/hooks/dbapi.py", line 198, in run
    with closing(self.get_conn()) as conn:
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/postgres/hooks/postgres.py", line 115, in get_conn
    self.conn = psycopg2.connect(**conn_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com" (172.31.45.95), port 5439 failed: Connection timed out
	Is the server running on that host and accepting TCP/IP connections?

[2022-01-03 04:06:57,602] {local_task_job.py:154} INFO - Task exited with return code 1
[2022-01-03 04:06:57,649] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-01-05 05:18:33,714] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [queued]>
[2022-01-05 05:18:33,730] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [queued]>
[2022-01-05 05:18:33,730] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 05:18:33,730] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 05:18:33,730] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 05:18:33,787] {taskinstance.py:1259} INFO - Executing <Task(PostgresOperator): tweet_load> on 2021-12-31 05:00:00+00:00
[2022-01-05 05:18:33,828] {standard_task_runner.py:52} INFO - Started process 2951 to run task
[2022-01-05 05:18:33,849] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T05:00:00+00:00', '--job-id', '43', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmpvzz48bxf', '--error-file', '/tmp/tmpxlv8zb5o']
[2022-01-05 05:18:33,850] {standard_task_runner.py:77} INFO - Job 43: Subtask tweet_load
[2022-01-05 05:18:34,076] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [running]> on host 2b1d65872a35
[2022-01-05 05:18:34,147] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T05:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T05:00:00+00:00
[2022-01-05 05:18:34,161] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 05:18:34,579] {dbapi.py:225} INFO - Running statement: select * test, parameters: None
[2022-01-05 05:18:34,701] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/postgres/operators/postgres.py", line 69, in execute
    self.hook.run(self.sql, self.autocommit, parameters=self.parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/hooks/dbapi.py", line 205, in run
    self._run_command(cur, sql_statement, parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/hooks/dbapi.py", line 229, in _run_command
    cur.execute(sql_statement)
psycopg2.errors.SyntaxError: syntax error at or near "test"
LINE 1: select * test
                 ^

[2022-01-05 05:18:34,730] {taskinstance.py:1277} INFO - Marking task as FAILED. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T050000, start_date=20220105T051833, end_date=20220105T051834
[2022-01-05 05:18:34,773] {standard_task_runner.py:92} ERROR - Failed to execute job 43 for task tweet_load
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/postgres/operators/postgres.py", line 69, in execute
    self.hook.run(self.sql, self.autocommit, parameters=self.parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/hooks/dbapi.py", line 205, in run
    self._run_command(cur, sql_statement, parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/hooks/dbapi.py", line 229, in _run_command
    cur.execute(sql_statement)
psycopg2.errors.SyntaxError: syntax error at or near "test"
LINE 1: select * test
                 ^

[2022-01-05 05:18:34,816] {local_task_job.py:154} INFO - Task exited with return code 1
[2022-01-05 05:18:34,905] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-01-05 05:23:15,979] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [queued]>
[2022-01-05 05:23:16,006] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [queued]>
[2022-01-05 05:23:16,007] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 05:23:16,007] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 05:23:16,007] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 05:23:16,032] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 05:00:00+00:00
[2022-01-05 05:23:16,040] {standard_task_runner.py:52} INFO - Started process 3247 to run task
[2022-01-05 05:23:16,050] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T05:00:00+00:00', '--job-id', '73', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmp9by2y2w5', '--error-file', '/tmp/tmp7cp4s_g4']
[2022-01-05 05:23:16,054] {standard_task_runner.py:77} INFO - Job 73: Subtask tweet_load
[2022-01-05 05:23:16,266] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [running]> on host 2b1d65872a35
[2022-01-05 05:23:16,460] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T05:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T05:00:00+00:00
[2022-01-05 05:23:16,461] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:23:16,462] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:23:16,462] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:23:16,462] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:23:16,462] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:23:16,462] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:23:16,463] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:23:16,463] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:23:16,463] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:23:16,463] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:23:16,463] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:23:16,464] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:23:16,464] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7f88b8fac810>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 05:00:00+00:00: scheduled__2021-12-31T05:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 6, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 6, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-31', 'prev_ds_nodash': '20211231', 'prev_execution_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T05:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T05:00:00+00:00', 'ts_nodash': '20211231T050000', 'ts_nodash_with_tz': '20211231T050000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T05:00:00+00:00', 'tsnodash_var': '20211231T050000', 'templates_dict': None}
[2022-01-05 05:23:16,465] {logging_mixin.py:109} INFO - Hello, Current Time:05:23:16 Execution time is 2021-12-31T05:00:00+00:00
[2022-01-05 05:23:16,497] {logging_mixin.py:109} INFO -    Unnamed: 0  ...       location
0           0  ...            NaN
1           1  ...            NaN
2           2  ...            NaN
3           3  ...      UofGuelph
4           4  ...            NaN
5           5  ...  Westbrook, ME
6           6  ...            NaN
7           7  ...            NaN
8           8  ...            NaN
9           9  ...   General Roca

[10 rows x 6 columns]
[2022-01-05 05:23:16,512] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 05:23:16,527] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 05:23:17,067] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2336, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 364, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 778, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 495, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 140, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 137, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 309, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 440, in __init__
    self.__connect(first_connect_check=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 656, in __connect
    connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/strategies.py", line 114, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 508, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com" (3.132.179.48), port 5439 failed: FATAL:  password authentication failed for user "awsuser"
connection to server at "tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com" (3.132.179.48), port 5439 failed: FATAL:  password authentication failed for user "awsuser"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 139, in load_tweets
    df.to_sql('test', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1758, in to_sql
    dtype=dtype,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1650, in prep_table
    table.create()
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 856, in create
    if self.exists():
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 840, in exists
    return self.pd_sql.has_table(self.name, self.schema)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1787, in has_table
    self.connectable.dialect.has_table, name, schema or self.meta.schema
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2211, in run_callable
    with self._contextual_connect() as conn:
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2302, in _contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2340, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1584, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2336, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 364, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 778, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 495, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 140, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 137, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 309, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 440, in __init__
    self.__connect(first_connect_check=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 656, in __connect
    connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/strategies.py", line 114, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 508, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com" (3.132.179.48), port 5439 failed: FATAL:  password authentication failed for user "awsuser"
connection to server at "tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com" (3.132.179.48), port 5439 failed: FATAL:  password authentication failed for user "awsuser"

(Background on this error at: http://sqlalche.me/e/13/e3q8)
[2022-01-05 05:23:17,114] {taskinstance.py:1277} INFO - Marking task as FAILED. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T050000, start_date=20220105T052315, end_date=20220105T052317
[2022-01-05 05:23:17,144] {standard_task_runner.py:92} ERROR - Failed to execute job 73 for task tweet_load
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2336, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 364, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 778, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 495, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 140, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 137, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 309, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 440, in __init__
    self.__connect(first_connect_check=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 656, in __connect
    connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/strategies.py", line 114, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 508, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com" (3.132.179.48), port 5439 failed: FATAL:  password authentication failed for user "awsuser"
connection to server at "tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com" (3.132.179.48), port 5439 failed: FATAL:  password authentication failed for user "awsuser"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 139, in load_tweets
    df.to_sql('test', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1758, in to_sql
    dtype=dtype,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1650, in prep_table
    table.create()
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 856, in create
    if self.exists():
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 840, in exists
    return self.pd_sql.has_table(self.name, self.schema)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1787, in has_table
    self.connectable.dialect.has_table, name, schema or self.meta.schema
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2211, in run_callable
    with self._contextual_connect() as conn:
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2302, in _contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2340, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1584, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2336, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 364, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 778, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 495, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 140, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 137, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 309, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 440, in __init__
    self.__connect(first_connect_check=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 656, in __connect
    connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/strategies.py", line 114, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 508, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com" (3.132.179.48), port 5439 failed: FATAL:  password authentication failed for user "awsuser"
connection to server at "tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com" (3.132.179.48), port 5439 failed: FATAL:  password authentication failed for user "awsuser"

(Background on this error at: http://sqlalche.me/e/13/e3q8)
[2022-01-05 05:23:17,176] {local_task_job.py:154} INFO - Task exited with return code 1
[2022-01-05 05:23:17,239] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-01-05 05:35:11,367] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [queued]>
[2022-01-05 05:35:11,381] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [queued]>
[2022-01-05 05:35:11,381] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 05:35:11,381] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 05:35:11,381] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 05:35:11,395] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 05:00:00+00:00
[2022-01-05 05:35:11,400] {standard_task_runner.py:52} INFO - Started process 228 to run task
[2022-01-05 05:35:11,403] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T05:00:00+00:00', '--job-id', '108', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmppxxhsn0c', '--error-file', '/tmp/tmp5y_v9tjj']
[2022-01-05 05:35:11,404] {standard_task_runner.py:77} INFO - Job 108: Subtask tweet_load
[2022-01-05 05:35:11,455] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [running]> on host 2b1d65872a35
[2022-01-05 05:35:11,513] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T05:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T05:00:00+00:00
[2022-01-05 05:35:11,514] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:35:11,514] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:35:11,514] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:35:11,514] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:35:11,514] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:35:11,515] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:35:11,515] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:35:11,515] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:35:11,515] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:35:11,515] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:35:11,515] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:35:11,515] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:35:11,516] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7fd8b40b1950>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 05:00:00+00:00: scheduled__2021-12-31T05:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 6, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 6, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-31', 'prev_ds_nodash': '20211231', 'prev_execution_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T05:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T05:00:00+00:00', 'ts_nodash': '20211231T050000', 'ts_nodash_with_tz': '20211231T050000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T05:00:00+00:00', 'tsnodash_var': '20211231T050000', 'templates_dict': None}
[2022-01-05 05:35:11,516] {logging_mixin.py:109} INFO - Hello, Current Time:05:35:11 Execution time is 2021-12-31T05:00:00+00:00
[2022-01-05 05:35:11,532] {logging_mixin.py:109} INFO -    Unnamed: 0  ...       location
0           0  ...            NaN
1           1  ...            NaN
2           2  ...            NaN
3           3  ...      UofGuelph
4           4  ...            NaN
5           5  ...  Westbrook, ME
6           6  ...            NaN
7           7  ...            NaN
8           8  ...            NaN
9           9  ...   General Roca

[10 rows x 6 columns]
[2022-01-05 05:35:11,542] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 05:35:11,549] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 05:35:13,800] {python.py:175} INFO - Done. Returned value was: None
[2022-01-05 05:35:13,819] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T050000, start_date=20220105T053511, end_date=20220105T053513
[2022-01-05 05:35:13,863] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-01-05 05:35:13,915] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-01-05 05:49:55,258] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [queued]>
[2022-01-05 05:49:55,296] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [queued]>
[2022-01-05 05:49:55,296] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 05:49:55,296] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 05:49:55,296] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 05:49:55,322] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 05:00:00+00:00
[2022-01-05 05:49:55,340] {standard_task_runner.py:52} INFO - Started process 925 to run task
[2022-01-05 05:49:55,351] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T05:00:00+00:00', '--job-id', '127', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmpzqo9xsur', '--error-file', '/tmp/tmpng8o2cxh']
[2022-01-05 05:49:55,353] {standard_task_runner.py:77} INFO - Job 127: Subtask tweet_load
[2022-01-05 05:49:55,466] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [running]> on host 2b1d65872a35
[2022-01-05 05:49:55,589] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T05:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T05:00:00+00:00
[2022-01-05 05:49:55,591] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:49:55,591] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:49:55,591] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:49:55,592] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:49:55,592] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:49:55,592] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:49:55,592] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:49:55,592] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:49:55,593] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:49:55,593] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:49:55,593] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:49:55,593] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:49:55,593] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7fd8b40b1950>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 05:00:00+00:00: scheduled__2021-12-31T05:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 6, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 6, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-31', 'prev_ds_nodash': '20211231', 'prev_execution_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T05:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T05:00:00+00:00', 'ts_nodash': '20211231T050000', 'ts_nodash_with_tz': '20211231T050000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T05:00:00+00:00', 'tsnodash_var': '20211231T050000', 'templates_dict': None}
[2022-01-05 05:49:55,594] {logging_mixin.py:109} INFO - Hello, Current Time:05:49:55 Execution time is 2021-12-31T05:00:00+00:00
[2022-01-05 05:49:55,615] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 05:49:55,627] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 05:49:57,021] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
psycopg2.errors.UndefinedColumn: column "unnamed: 0" of relation "tweet" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 133, in load_tweets
    tweet_data.to_sql('tweet', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1770, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1350, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1340, in insert_records
    table.insert(chunksize=chunksize, method=method)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 967, in insert
    exec_insert(conn, keys, chunk_iter)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 882, in _execute_insert
    conn.execute(self.table.insert(), data)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "unnamed: 0" of relation "tweet" does not exist

[SQL: INSERT INTO tweet ("Unnamed: 0", author_id, created_at, id, original_text, location) VALUES (%(Unnamed: 0)s, %(author_id)s, %(created_at)s, %(id)s, %(original_text)s, %(location)s)]
[parameters: ({'Unnamed: 0': 0, 'author_id': 4687651890, 'created_at': '2021-12-31T05:09:59.000Z', 'id': 1476782667920121858, 'original_text': 'plata, covid, y suerte en el amor nunca tuve', 'location': 'Rio Tercero'}, {'Unnamed: 0': 1, 'author_id': 1001136081994174464, 'created_at': '2021-12-31T05:09:59.000Z', 'id': 1476782667291111429, 'original_text': '“I’m here for a good time, not a long time” between Covid and climate change, you’re here for neither', 'location': 'ur moms house'}, {'Unnamed: 0': 2, 'author_id': 1043168694963200001, 'created_at': '2021-12-31T05:09:59.000Z', 'id': 1476782666972344334, 'original_text': 'quebec will really let someone positive for covid work but not someone wearing a hijab lol', 'location': 'Japan'}, {'Unnamed: 0': 3, 'author_id': 1257280909, 'created_at': '2021-12-31T05:09:59.000Z', 'id': 1476782666783596545, 'original_text': 'Totalmente de acuerdo con empezar a pedir el certificado de vacunación para ir a lugares públicos. Poner en riesgo a otros por ser antivacunas no es justo. Eso no es perder la libertad. Perder la libertad es terminar internado o muerto por un par de egoístas.', 'location': None}, {'Unnamed: 0': 4, 'author_id': 1109237518501859328, 'created_at': '2021-12-31T05:09:59.000Z', 'id': 1476782666188038146, 'original_text': 'En conclusión, TODOS tienen covid pero unos dicen que es gripa y los otros ya se hicieron la prueba.', 'location': None}, {'Unnamed: 0': 5, 'author_id': 995076839390547979, 'created_at': '2021-12-31T05:09:59.000Z', 'id': 1476782665248485395, 'original_text': 'UFRJ ainda exigirá comprovação vacinal contra covid-19 para acesso a espaços da Universidade.\nhttps://t.co/I6GvkbPOEk\n\n#ufrj #vacina #covid19 https://t.co/Dd79rutNDn', 'location': 'Saquarema, Brasil'}, {'Unnamed: 0': 6, 'author_id': 704555058654883840, 'created_at': '2021-12-31T05:09:59.000Z', 'id': 1476782665047035904, 'original_text': 'If everyone who has been grateful for NHS staff over the last two years followed and retweeted, we would reach a million in no time.\n\nIt will only take a few seconds, and your support would really mean a lot to a huge number of people who continue to fight Covid-19. https://t.co/q3UHkk82Rc', 'location': 'Austral, Sydney'}, {'Unnamed: 0': 7, 'author_id': 1122014915735089152, 'created_at': '2021-12-31T05:09:59.000Z', 'id': 1476782664908611585, 'original_text': 'COVID-19 vaccine mandates “have to be repealed” as the vaccines are “still in research” and “people cannot be mandated to participate in research,” says\xa0@P_McCulloughMD \nhttps://t.co/ReBmW1uNfm', 'location': None}, {'Unnamed: 0': 8, 'author_id': 1378566968253513729, 'created_at': '2021-12-31T05:09:59.000Z', 'id': 1476782664447373330, 'original_text': 'The latest VAERS covid vaccine ‘adverse event’ reports stats have been published. When we consider that maybe 1% of all reports make it to the list, you can add two zero’s onto each number, making for uncomfortable reading... https://t.co/MxpH1eKo2t', 'location': 'NH'}, {'Unnamed: 0': 9, 'author_id': 1190492803366838272, 'created_at': '2021-12-31T05:09:59.000Z', 'id': 1476782664275447810, 'original_text': 'Polémico festejo de Fin de Año en la Afip: 160 contagiados con Covid. LN+', 'location': 'Ciudad Autónoma de Buenos Aire'})]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-01-05 05:49:57,050] {taskinstance.py:1277} INFO - Marking task as FAILED. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T050000, start_date=20220105T054955, end_date=20220105T054957
[2022-01-05 05:49:57,086] {standard_task_runner.py:92} ERROR - Failed to execute job 127 for task tweet_load
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
psycopg2.errors.UndefinedColumn: column "unnamed: 0" of relation "tweet" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 133, in load_tweets
    tweet_data.to_sql('tweet', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1770, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1350, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1340, in insert_records
    table.insert(chunksize=chunksize, method=method)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 967, in insert
    exec_insert(conn, keys, chunk_iter)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 882, in _execute_insert
    conn.execute(self.table.insert(), data)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "unnamed: 0" of relation "tweet" does not exist

[SQL: INSERT INTO tweet ("Unnamed: 0", author_id, created_at, id, original_text, location) VALUES (%(Unnamed: 0)s, %(author_id)s, %(created_at)s, %(id)s, %(original_text)s, %(location)s)]
[parameters: ({'Unnamed: 0': 0, 'author_id': 4687651890, 'created_at': '2021-12-31T05:09:59.000Z', 'id': 1476782667920121858, 'original_text': 'plata, covid, y suerte en el amor nunca tuve', 'location': 'Rio Tercero'}, {'Unnamed: 0': 1, 'author_id': 1001136081994174464, 'created_at': '2021-12-31T05:09:59.000Z', 'id': 1476782667291111429, 'original_text': '“I’m here for a good time, not a long time” between Covid and climate change, you’re here for neither', 'location': 'ur moms house'}, {'Unnamed: 0': 2, 'author_id': 1043168694963200001, 'created_at': '2021-12-31T05:09:59.000Z', 'id': 1476782666972344334, 'original_text': 'quebec will really let someone positive for covid work but not someone wearing a hijab lol', 'location': 'Japan'}, {'Unnamed: 0': 3, 'author_id': 1257280909, 'created_at': '2021-12-31T05:09:59.000Z', 'id': 1476782666783596545, 'original_text': 'Totalmente de acuerdo con empezar a pedir el certificado de vacunación para ir a lugares públicos. Poner en riesgo a otros por ser antivacunas no es justo. Eso no es perder la libertad. Perder la libertad es terminar internado o muerto por un par de egoístas.', 'location': None}, {'Unnamed: 0': 4, 'author_id': 1109237518501859328, 'created_at': '2021-12-31T05:09:59.000Z', 'id': 1476782666188038146, 'original_text': 'En conclusión, TODOS tienen covid pero unos dicen que es gripa y los otros ya se hicieron la prueba.', 'location': None}, {'Unnamed: 0': 5, 'author_id': 995076839390547979, 'created_at': '2021-12-31T05:09:59.000Z', 'id': 1476782665248485395, 'original_text': 'UFRJ ainda exigirá comprovação vacinal contra covid-19 para acesso a espaços da Universidade.\nhttps://t.co/I6GvkbPOEk\n\n#ufrj #vacina #covid19 https://t.co/Dd79rutNDn', 'location': 'Saquarema, Brasil'}, {'Unnamed: 0': 6, 'author_id': 704555058654883840, 'created_at': '2021-12-31T05:09:59.000Z', 'id': 1476782665047035904, 'original_text': 'If everyone who has been grateful for NHS staff over the last two years followed and retweeted, we would reach a million in no time.\n\nIt will only take a few seconds, and your support would really mean a lot to a huge number of people who continue to fight Covid-19. https://t.co/q3UHkk82Rc', 'location': 'Austral, Sydney'}, {'Unnamed: 0': 7, 'author_id': 1122014915735089152, 'created_at': '2021-12-31T05:09:59.000Z', 'id': 1476782664908611585, 'original_text': 'COVID-19 vaccine mandates “have to be repealed” as the vaccines are “still in research” and “people cannot be mandated to participate in research,” says\xa0@P_McCulloughMD \nhttps://t.co/ReBmW1uNfm', 'location': None}, {'Unnamed: 0': 8, 'author_id': 1378566968253513729, 'created_at': '2021-12-31T05:09:59.000Z', 'id': 1476782664447373330, 'original_text': 'The latest VAERS covid vaccine ‘adverse event’ reports stats have been published. When we consider that maybe 1% of all reports make it to the list, you can add two zero’s onto each number, making for uncomfortable reading... https://t.co/MxpH1eKo2t', 'location': 'NH'}, {'Unnamed: 0': 9, 'author_id': 1190492803366838272, 'created_at': '2021-12-31T05:09:59.000Z', 'id': 1476782664275447810, 'original_text': 'Polémico festejo de Fin de Año en la Afip: 160 contagiados con Covid. LN+', 'location': 'Ciudad Autónoma de Buenos Aire'})]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-01-05 05:49:57,144] {local_task_job.py:154} INFO - Task exited with return code 1
[2022-01-05 05:49:57,338] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-01-05 05:51:30,374] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [queued]>
[2022-01-05 05:51:30,384] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [queued]>
[2022-01-05 05:51:30,384] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 05:51:30,384] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 05:51:30,384] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 05:51:30,396] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 05:00:00+00:00
[2022-01-05 05:51:30,401] {standard_task_runner.py:52} INFO - Started process 1055 to run task
[2022-01-05 05:51:30,404] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T05:00:00+00:00', '--job-id', '145', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmpx7vjjjmd', '--error-file', '/tmp/tmpfypbiwtn']
[2022-01-05 05:51:30,405] {standard_task_runner.py:77} INFO - Job 145: Subtask tweet_load
[2022-01-05 05:51:30,461] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [running]> on host 2b1d65872a35
[2022-01-05 05:51:30,519] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T05:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T05:00:00+00:00
[2022-01-05 05:51:30,521] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:51:30,521] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:51:30,521] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:51:30,521] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:51:30,521] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:51:30,522] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:51:30,522] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:51:30,522] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:51:30,522] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:51:30,522] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:51:30,522] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:51:30,522] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:51:30,523] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7fd8b40b1950>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 05:00:00+00:00: scheduled__2021-12-31T05:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 6, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 6, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-31', 'prev_ds_nodash': '20211231', 'prev_execution_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T05:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T05:00:00+00:00', 'ts_nodash': '20211231T050000', 'ts_nodash_with_tz': '20211231T050000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T05:00:00+00:00', 'tsnodash_var': '20211231T050000', 'templates_dict': None}
[2022-01-05 05:51:30,523] {logging_mixin.py:109} INFO - Hello, Current Time:05:51:30 Execution time is 2021-12-31T05:00:00+00:00
[2022-01-05 05:51:30,537] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 05:51:30,544] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 05:51:31,895] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
psycopg2.errors.UndefinedColumn: column "original_text" of relation "tweet" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 133, in load_tweets
    tweet_data.to_sql('tweet', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1770, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1350, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1340, in insert_records
    table.insert(chunksize=chunksize, method=method)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 967, in insert
    exec_insert(conn, keys, chunk_iter)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 882, in _execute_insert
    conn.execute(self.table.insert(), data)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "original_text" of relation "tweet" does not exist

[SQL: INSERT INTO tweet (created_at, author_id, id, original_text, location) VALUES (%(created_at)s, %(author_id)s, %(id)s, %(original_text)s, %(location)s)]
[parameters: ({'created_at': '2021-12-31T05:09:59.000Z', 'author_id': 4687651890, 'id': 1476782667920121858, 'original_text': 'plata, covid, y suerte en el amor nunca tuve', 'location': 'Rio Tercero'}, {'created_at': '2021-12-31T05:09:59.000Z', 'author_id': 1001136081994174464, 'id': 1476782667291111429, 'original_text': '“I’m here for a good time, not a long time” between Covid and climate change, you’re here for neither', 'location': 'ur moms house'}, {'created_at': '2021-12-31T05:09:59.000Z', 'author_id': 1043168694963200001, 'id': 1476782666972344334, 'original_text': 'quebec will really let someone positive for covid work but not someone wearing a hijab lol', 'location': 'Japan'}, {'created_at': '2021-12-31T05:09:59.000Z', 'author_id': 1257280909, 'id': 1476782666783596545, 'original_text': 'Totalmente de acuerdo con empezar a pedir el certificado de vacunación para ir a lugares públicos. Poner en riesgo a otros por ser antivacunas no es justo. Eso no es perder la libertad. Perder la libertad es terminar internado o muerto por un par de egoístas.', 'location': None}, {'created_at': '2021-12-31T05:09:59.000Z', 'author_id': 1109237518501859328, 'id': 1476782666188038146, 'original_text': 'En conclusión, TODOS tienen covid pero unos dicen que es gripa y los otros ya se hicieron la prueba.', 'location': None}, {'created_at': '2021-12-31T05:09:59.000Z', 'author_id': 995076839390547979, 'id': 1476782665248485395, 'original_text': 'UFRJ ainda exigirá comprovação vacinal contra covid-19 para acesso a espaços da Universidade.\nhttps://t.co/I6GvkbPOEk\n\n#ufrj #vacina #covid19 https://t.co/Dd79rutNDn', 'location': 'Saquarema, Brasil'}, {'created_at': '2021-12-31T05:09:59.000Z', 'author_id': 704555058654883840, 'id': 1476782665047035904, 'original_text': 'If everyone who has been grateful for NHS staff over the last two years followed and retweeted, we would reach a million in no time.\n\nIt will only take a few seconds, and your support would really mean a lot to a huge number of people who continue to fight Covid-19. https://t.co/q3UHkk82Rc', 'location': 'Austral, Sydney'}, {'created_at': '2021-12-31T05:09:59.000Z', 'author_id': 1122014915735089152, 'id': 1476782664908611585, 'original_text': 'COVID-19 vaccine mandates “have to be repealed” as the vaccines are “still in research” and “people cannot be mandated to participate in research,” says\xa0@P_McCulloughMD \nhttps://t.co/ReBmW1uNfm', 'location': None}, {'created_at': '2021-12-31T05:09:59.000Z', 'author_id': 1378566968253513729, 'id': 1476782664447373330, 'original_text': 'The latest VAERS covid vaccine ‘adverse event’ reports stats have been published. When we consider that maybe 1% of all reports make it to the list, you can add two zero’s onto each number, making for uncomfortable reading... https://t.co/MxpH1eKo2t', 'location': 'NH'}, {'created_at': '2021-12-31T05:09:59.000Z', 'author_id': 1190492803366838272, 'id': 1476782664275447810, 'original_text': 'Polémico festejo de Fin de Año en la Afip: 160 contagiados con Covid. LN+', 'location': 'Ciudad Autónoma de Buenos Aire'})]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-01-05 05:51:31,909] {taskinstance.py:1277} INFO - Marking task as FAILED. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T050000, start_date=20220105T055130, end_date=20220105T055131
[2022-01-05 05:51:31,924] {standard_task_runner.py:92} ERROR - Failed to execute job 145 for task tweet_load
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
psycopg2.errors.UndefinedColumn: column "original_text" of relation "tweet" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 133, in load_tweets
    tweet_data.to_sql('tweet', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1770, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1350, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1340, in insert_records
    table.insert(chunksize=chunksize, method=method)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 967, in insert
    exec_insert(conn, keys, chunk_iter)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 882, in _execute_insert
    conn.execute(self.table.insert(), data)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "original_text" of relation "tweet" does not exist

[SQL: INSERT INTO tweet (created_at, author_id, id, original_text, location) VALUES (%(created_at)s, %(author_id)s, %(id)s, %(original_text)s, %(location)s)]
[parameters: ({'created_at': '2021-12-31T05:09:59.000Z', 'author_id': 4687651890, 'id': 1476782667920121858, 'original_text': 'plata, covid, y suerte en el amor nunca tuve', 'location': 'Rio Tercero'}, {'created_at': '2021-12-31T05:09:59.000Z', 'author_id': 1001136081994174464, 'id': 1476782667291111429, 'original_text': '“I’m here for a good time, not a long time” between Covid and climate change, you’re here for neither', 'location': 'ur moms house'}, {'created_at': '2021-12-31T05:09:59.000Z', 'author_id': 1043168694963200001, 'id': 1476782666972344334, 'original_text': 'quebec will really let someone positive for covid work but not someone wearing a hijab lol', 'location': 'Japan'}, {'created_at': '2021-12-31T05:09:59.000Z', 'author_id': 1257280909, 'id': 1476782666783596545, 'original_text': 'Totalmente de acuerdo con empezar a pedir el certificado de vacunación para ir a lugares públicos. Poner en riesgo a otros por ser antivacunas no es justo. Eso no es perder la libertad. Perder la libertad es terminar internado o muerto por un par de egoístas.', 'location': None}, {'created_at': '2021-12-31T05:09:59.000Z', 'author_id': 1109237518501859328, 'id': 1476782666188038146, 'original_text': 'En conclusión, TODOS tienen covid pero unos dicen que es gripa y los otros ya se hicieron la prueba.', 'location': None}, {'created_at': '2021-12-31T05:09:59.000Z', 'author_id': 995076839390547979, 'id': 1476782665248485395, 'original_text': 'UFRJ ainda exigirá comprovação vacinal contra covid-19 para acesso a espaços da Universidade.\nhttps://t.co/I6GvkbPOEk\n\n#ufrj #vacina #covid19 https://t.co/Dd79rutNDn', 'location': 'Saquarema, Brasil'}, {'created_at': '2021-12-31T05:09:59.000Z', 'author_id': 704555058654883840, 'id': 1476782665047035904, 'original_text': 'If everyone who has been grateful for NHS staff over the last two years followed and retweeted, we would reach a million in no time.\n\nIt will only take a few seconds, and your support would really mean a lot to a huge number of people who continue to fight Covid-19. https://t.co/q3UHkk82Rc', 'location': 'Austral, Sydney'}, {'created_at': '2021-12-31T05:09:59.000Z', 'author_id': 1122014915735089152, 'id': 1476782664908611585, 'original_text': 'COVID-19 vaccine mandates “have to be repealed” as the vaccines are “still in research” and “people cannot be mandated to participate in research,” says\xa0@P_McCulloughMD \nhttps://t.co/ReBmW1uNfm', 'location': None}, {'created_at': '2021-12-31T05:09:59.000Z', 'author_id': 1378566968253513729, 'id': 1476782664447373330, 'original_text': 'The latest VAERS covid vaccine ‘adverse event’ reports stats have been published. When we consider that maybe 1% of all reports make it to the list, you can add two zero’s onto each number, making for uncomfortable reading... https://t.co/MxpH1eKo2t', 'location': 'NH'}, {'created_at': '2021-12-31T05:09:59.000Z', 'author_id': 1190492803366838272, 'id': 1476782664275447810, 'original_text': 'Polémico festejo de Fin de Año en la Afip: 160 contagiados con Covid. LN+', 'location': 'Ciudad Autónoma de Buenos Aire'})]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-01-05 05:51:31,947] {local_task_job.py:154} INFO - Task exited with return code 1
[2022-01-05 05:51:31,979] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-01-05 06:00:47,879] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [queued]>
[2022-01-05 06:00:47,893] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [queued]>
[2022-01-05 06:00:47,893] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 06:00:47,893] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 06:00:47,894] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 06:00:47,907] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 05:00:00+00:00
[2022-01-05 06:00:47,913] {standard_task_runner.py:52} INFO - Started process 1515 to run task
[2022-01-05 06:00:47,917] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T05:00:00+00:00', '--job-id', '163', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmp5o0o1371', '--error-file', '/tmp/tmp0gmotn4w']
[2022-01-05 06:00:47,918] {standard_task_runner.py:77} INFO - Job 163: Subtask tweet_load
[2022-01-05 06:00:47,963] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [running]> on host 2b1d65872a35
[2022-01-05 06:00:48,005] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T05:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T05:00:00+00:00
[2022-01-05 06:00:48,007] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:00:48,007] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:00:48,007] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:00:48,007] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:00:48,007] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:00:48,007] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:00:48,007] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:00:48,007] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:00:48,007] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:00:48,008] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:00:48,008] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:00:48,008] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:00:48,008] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7fd8b40b1950>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 05:00:00+00:00: scheduled__2021-12-31T05:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 6, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 6, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-31', 'prev_ds_nodash': '20211231', 'prev_execution_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T05:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T05:00:00+00:00', 'ts_nodash': '20211231T050000', 'ts_nodash_with_tz': '20211231T050000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T05:00:00+00:00', 'tsnodash_var': '20211231T050000', 'templates_dict': None}
[2022-01-05 06:00:48,008] {logging_mixin.py:109} INFO - Hello, Current Time:06:00:48 Execution time is 2021-12-31T05:00:00+00:00
[2022-01-05 06:00:48,021] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 06:00:48,034] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 06:00:49,460] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
psycopg2.errors.NumericValueOutOfRange: numeric value "4687651890" out of range for integer


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 133, in load_tweets
    tweet_data.to_sql('tweet', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1770, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1350, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1340, in insert_records
    table.insert(chunksize=chunksize, method=method)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 967, in insert
    exec_insert(conn, keys, chunk_iter)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 882, in _execute_insert
    conn.execute(self.table.insert(), data)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
sqlalchemy.exc.DataError: (psycopg2.errors.NumericValueOutOfRange) numeric value "4687651890" out of range for integer

[SQL: INSERT INTO tweet (author_id, id, created_at, original_text, location) VALUES (%(author_id)s, %(id)s, %(created_at)s, %(original_text)s, %(location)s)]
[parameters: ({'author_id': 4687651890, 'id': 1476782667920121858, 'created_at': '2021-12-31T05:09:59.000Z', 'original_text': 'plata, covid, y suerte en el amor nunca tuve', 'location': 'Rio Tercero'}, {'author_id': 1001136081994174464, 'id': 1476782667291111429, 'created_at': '2021-12-31T05:09:59.000Z', 'original_text': '“I’m here for a good time, not a long time” between Covid and climate change, you’re here for neither', 'location': 'ur moms house'}, {'author_id': 1043168694963200001, 'id': 1476782666972344334, 'created_at': '2021-12-31T05:09:59.000Z', 'original_text': 'quebec will really let someone positive for covid work but not someone wearing a hijab lol', 'location': 'Japan'}, {'author_id': 1257280909, 'id': 1476782666783596545, 'created_at': '2021-12-31T05:09:59.000Z', 'original_text': 'Totalmente de acuerdo con empezar a pedir el certificado de vacunación para ir a lugares públicos. Poner en riesgo a otros por ser antivacunas no es justo. Eso no es perder la libertad. Perder la libertad es terminar internado o muerto por un par de egoístas.', 'location': None}, {'author_id': 1109237518501859328, 'id': 1476782666188038146, 'created_at': '2021-12-31T05:09:59.000Z', 'original_text': 'En conclusión, TODOS tienen covid pero unos dicen que es gripa y los otros ya se hicieron la prueba.', 'location': None}, {'author_id': 995076839390547979, 'id': 1476782665248485395, 'created_at': '2021-12-31T05:09:59.000Z', 'original_text': 'UFRJ ainda exigirá comprovação vacinal contra covid-19 para acesso a espaços da Universidade.\nhttps://t.co/I6GvkbPOEk\n\n#ufrj #vacina #covid19 https://t.co/Dd79rutNDn', 'location': 'Saquarema, Brasil'}, {'author_id': 704555058654883840, 'id': 1476782665047035904, 'created_at': '2021-12-31T05:09:59.000Z', 'original_text': 'If everyone who has been grateful for NHS staff over the last two years followed and retweeted, we would reach a million in no time.\n\nIt will only take a few seconds, and your support would really mean a lot to a huge number of people who continue to fight Covid-19. https://t.co/q3UHkk82Rc', 'location': 'Austral, Sydney'}, {'author_id': 1122014915735089152, 'id': 1476782664908611585, 'created_at': '2021-12-31T05:09:59.000Z', 'original_text': 'COVID-19 vaccine mandates “have to be repealed” as the vaccines are “still in research” and “people cannot be mandated to participate in research,” says\xa0@P_McCulloughMD \nhttps://t.co/ReBmW1uNfm', 'location': None}, {'author_id': 1378566968253513729, 'id': 1476782664447373330, 'created_at': '2021-12-31T05:09:59.000Z', 'original_text': 'The latest VAERS covid vaccine ‘adverse event’ reports stats have been published. When we consider that maybe 1% of all reports make it to the list, you can add two zero’s onto each number, making for uncomfortable reading... https://t.co/MxpH1eKo2t', 'location': 'NH'}, {'author_id': 1190492803366838272, 'id': 1476782664275447810, 'created_at': '2021-12-31T05:09:59.000Z', 'original_text': 'Polémico festejo de Fin de Año en la Afip: 160 contagiados con Covid. LN+', 'location': 'Ciudad Autónoma de Buenos Aire'})]
(Background on this error at: http://sqlalche.me/e/13/9h9h)
[2022-01-05 06:00:49,474] {taskinstance.py:1277} INFO - Marking task as FAILED. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T050000, start_date=20220105T060047, end_date=20220105T060049
[2022-01-05 06:00:49,486] {standard_task_runner.py:92} ERROR - Failed to execute job 163 for task tweet_load
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
psycopg2.errors.NumericValueOutOfRange: numeric value "4687651890" out of range for integer


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 133, in load_tweets
    tweet_data.to_sql('tweet', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1770, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1350, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1340, in insert_records
    table.insert(chunksize=chunksize, method=method)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 967, in insert
    exec_insert(conn, keys, chunk_iter)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 882, in _execute_insert
    conn.execute(self.table.insert(), data)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
sqlalchemy.exc.DataError: (psycopg2.errors.NumericValueOutOfRange) numeric value "4687651890" out of range for integer

[SQL: INSERT INTO tweet (author_id, id, created_at, original_text, location) VALUES (%(author_id)s, %(id)s, %(created_at)s, %(original_text)s, %(location)s)]
[parameters: ({'author_id': 4687651890, 'id': 1476782667920121858, 'created_at': '2021-12-31T05:09:59.000Z', 'original_text': 'plata, covid, y suerte en el amor nunca tuve', 'location': 'Rio Tercero'}, {'author_id': 1001136081994174464, 'id': 1476782667291111429, 'created_at': '2021-12-31T05:09:59.000Z', 'original_text': '“I’m here for a good time, not a long time” between Covid and climate change, you’re here for neither', 'location': 'ur moms house'}, {'author_id': 1043168694963200001, 'id': 1476782666972344334, 'created_at': '2021-12-31T05:09:59.000Z', 'original_text': 'quebec will really let someone positive for covid work but not someone wearing a hijab lol', 'location': 'Japan'}, {'author_id': 1257280909, 'id': 1476782666783596545, 'created_at': '2021-12-31T05:09:59.000Z', 'original_text': 'Totalmente de acuerdo con empezar a pedir el certificado de vacunación para ir a lugares públicos. Poner en riesgo a otros por ser antivacunas no es justo. Eso no es perder la libertad. Perder la libertad es terminar internado o muerto por un par de egoístas.', 'location': None}, {'author_id': 1109237518501859328, 'id': 1476782666188038146, 'created_at': '2021-12-31T05:09:59.000Z', 'original_text': 'En conclusión, TODOS tienen covid pero unos dicen que es gripa y los otros ya se hicieron la prueba.', 'location': None}, {'author_id': 995076839390547979, 'id': 1476782665248485395, 'created_at': '2021-12-31T05:09:59.000Z', 'original_text': 'UFRJ ainda exigirá comprovação vacinal contra covid-19 para acesso a espaços da Universidade.\nhttps://t.co/I6GvkbPOEk\n\n#ufrj #vacina #covid19 https://t.co/Dd79rutNDn', 'location': 'Saquarema, Brasil'}, {'author_id': 704555058654883840, 'id': 1476782665047035904, 'created_at': '2021-12-31T05:09:59.000Z', 'original_text': 'If everyone who has been grateful for NHS staff over the last two years followed and retweeted, we would reach a million in no time.\n\nIt will only take a few seconds, and your support would really mean a lot to a huge number of people who continue to fight Covid-19. https://t.co/q3UHkk82Rc', 'location': 'Austral, Sydney'}, {'author_id': 1122014915735089152, 'id': 1476782664908611585, 'created_at': '2021-12-31T05:09:59.000Z', 'original_text': 'COVID-19 vaccine mandates “have to be repealed” as the vaccines are “still in research” and “people cannot be mandated to participate in research,” says\xa0@P_McCulloughMD \nhttps://t.co/ReBmW1uNfm', 'location': None}, {'author_id': 1378566968253513729, 'id': 1476782664447373330, 'created_at': '2021-12-31T05:09:59.000Z', 'original_text': 'The latest VAERS covid vaccine ‘adverse event’ reports stats have been published. When we consider that maybe 1% of all reports make it to the list, you can add two zero’s onto each number, making for uncomfortable reading... https://t.co/MxpH1eKo2t', 'location': 'NH'}, {'author_id': 1190492803366838272, 'id': 1476782664275447810, 'created_at': '2021-12-31T05:09:59.000Z', 'original_text': 'Polémico festejo de Fin de Año en la Afip: 160 contagiados con Covid. LN+', 'location': 'Ciudad Autónoma de Buenos Aire'})]
(Background on this error at: http://sqlalche.me/e/13/9h9h)
[2022-01-05 06:00:49,493] {local_task_job.py:154} INFO - Task exited with return code 1
[2022-01-05 06:00:49,527] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-01-05 06:01:49,659] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [queued]>
[2022-01-05 06:01:49,673] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [queued]>
[2022-01-05 06:01:49,674] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 06:01:49,674] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 06:01:49,674] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 06:01:49,689] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 05:00:00+00:00
[2022-01-05 06:01:49,696] {standard_task_runner.py:52} INFO - Started process 1618 to run task
[2022-01-05 06:01:49,700] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T05:00:00+00:00', '--job-id', '181', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmp_bu9bn9q', '--error-file', '/tmp/tmpfxwhkaa4']
[2022-01-05 06:01:49,701] {standard_task_runner.py:77} INFO - Job 181: Subtask tweet_load
[2022-01-05 06:01:49,754] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [running]> on host 2b1d65872a35
[2022-01-05 06:01:49,805] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T05:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T05:00:00+00:00
[2022-01-05 06:01:49,806] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:01:49,806] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:01:49,807] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:01:49,807] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:01:49,807] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:01:49,807] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:01:49,807] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:01:49,807] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:01:49,807] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:01:49,808] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:01:49,808] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:01:49,808] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:01:49,808] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7fd8b40b1950>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 05:00:00+00:00: scheduled__2021-12-31T05:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 6, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 6, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-31', 'prev_ds_nodash': '20211231', 'prev_execution_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T05:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T05:00:00+00:00', 'ts_nodash': '20211231T050000', 'ts_nodash_with_tz': '20211231T050000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T05:00:00+00:00', 'tsnodash_var': '20211231T050000', 'templates_dict': None}
[2022-01-05 06:01:49,808] {logging_mixin.py:109} INFO - Hello, Current Time:06:01:49 Execution time is 2021-12-31T05:00:00+00:00
[2022-01-05 06:01:49,823] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 06:01:49,830] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 06:01:51,272] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
psycopg2.errors.NumericValueOutOfRange: numeric value "4687651890" out of range for integer


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 133, in load_tweets
    tweet_data.to_sql('tweet', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1770, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1350, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1340, in insert_records
    table.insert(chunksize=chunksize, method=method)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 967, in insert
    exec_insert(conn, keys, chunk_iter)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 882, in _execute_insert
    conn.execute(self.table.insert(), data)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
sqlalchemy.exc.DataError: (psycopg2.errors.NumericValueOutOfRange) numeric value "4687651890" out of range for integer

[SQL: INSERT INTO tweet (created_at, id, author_id, original_text, location) VALUES (%(created_at)s, %(id)s, %(author_id)s, %(original_text)s, %(location)s)]
[parameters: ({'created_at': '2021-12-31T05:09:59.000Z', 'id': 1476782667920121858, 'author_id': 4687651890, 'original_text': 'plata, covid, y suerte en el amor nunca tuve', 'location': 'Rio Tercero'}, {'created_at': '2021-12-31T05:09:59.000Z', 'id': 1476782667291111429, 'author_id': 1001136081994174464, 'original_text': '“I’m here for a good time, not a long time” between Covid and climate change, you’re here for neither', 'location': 'ur moms house'}, {'created_at': '2021-12-31T05:09:59.000Z', 'id': 1476782666972344334, 'author_id': 1043168694963200001, 'original_text': 'quebec will really let someone positive for covid work but not someone wearing a hijab lol', 'location': 'Japan'}, {'created_at': '2021-12-31T05:09:59.000Z', 'id': 1476782666783596545, 'author_id': 1257280909, 'original_text': 'Totalmente de acuerdo con empezar a pedir el certificado de vacunación para ir a lugares públicos. Poner en riesgo a otros por ser antivacunas no es justo. Eso no es perder la libertad. Perder la libertad es terminar internado o muerto por un par de egoístas.', 'location': None}, {'created_at': '2021-12-31T05:09:59.000Z', 'id': 1476782666188038146, 'author_id': 1109237518501859328, 'original_text': 'En conclusión, TODOS tienen covid pero unos dicen que es gripa y los otros ya se hicieron la prueba.', 'location': None}, {'created_at': '2021-12-31T05:09:59.000Z', 'id': 1476782665248485395, 'author_id': 995076839390547979, 'original_text': 'UFRJ ainda exigirá comprovação vacinal contra covid-19 para acesso a espaços da Universidade.\nhttps://t.co/I6GvkbPOEk\n\n#ufrj #vacina #covid19 https://t.co/Dd79rutNDn', 'location': 'Saquarema, Brasil'}, {'created_at': '2021-12-31T05:09:59.000Z', 'id': 1476782665047035904, 'author_id': 704555058654883840, 'original_text': 'If everyone who has been grateful for NHS staff over the last two years followed and retweeted, we would reach a million in no time.\n\nIt will only take a few seconds, and your support would really mean a lot to a huge number of people who continue to fight Covid-19. https://t.co/q3UHkk82Rc', 'location': 'Austral, Sydney'}, {'created_at': '2021-12-31T05:09:59.000Z', 'id': 1476782664908611585, 'author_id': 1122014915735089152, 'original_text': 'COVID-19 vaccine mandates “have to be repealed” as the vaccines are “still in research” and “people cannot be mandated to participate in research,” says\xa0@P_McCulloughMD \nhttps://t.co/ReBmW1uNfm', 'location': None}, {'created_at': '2021-12-31T05:09:59.000Z', 'id': 1476782664447373330, 'author_id': 1378566968253513729, 'original_text': 'The latest VAERS covid vaccine ‘adverse event’ reports stats have been published. When we consider that maybe 1% of all reports make it to the list, you can add two zero’s onto each number, making for uncomfortable reading... https://t.co/MxpH1eKo2t', 'location': 'NH'}, {'created_at': '2021-12-31T05:09:59.000Z', 'id': 1476782664275447810, 'author_id': 1190492803366838272, 'original_text': 'Polémico festejo de Fin de Año en la Afip: 160 contagiados con Covid. LN+', 'location': 'Ciudad Autónoma de Buenos Aire'})]
(Background on this error at: http://sqlalche.me/e/13/9h9h)
[2022-01-05 06:01:51,307] {taskinstance.py:1277} INFO - Marking task as FAILED. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T050000, start_date=20220105T060149, end_date=20220105T060151
[2022-01-05 06:01:51,333] {standard_task_runner.py:92} ERROR - Failed to execute job 181 for task tweet_load
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
psycopg2.errors.NumericValueOutOfRange: numeric value "4687651890" out of range for integer


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 133, in load_tweets
    tweet_data.to_sql('tweet', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1770, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1350, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1340, in insert_records
    table.insert(chunksize=chunksize, method=method)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 967, in insert
    exec_insert(conn, keys, chunk_iter)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 882, in _execute_insert
    conn.execute(self.table.insert(), data)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
sqlalchemy.exc.DataError: (psycopg2.errors.NumericValueOutOfRange) numeric value "4687651890" out of range for integer

[SQL: INSERT INTO tweet (created_at, id, author_id, original_text, location) VALUES (%(created_at)s, %(id)s, %(author_id)s, %(original_text)s, %(location)s)]
[parameters: ({'created_at': '2021-12-31T05:09:59.000Z', 'id': 1476782667920121858, 'author_id': 4687651890, 'original_text': 'plata, covid, y suerte en el amor nunca tuve', 'location': 'Rio Tercero'}, {'created_at': '2021-12-31T05:09:59.000Z', 'id': 1476782667291111429, 'author_id': 1001136081994174464, 'original_text': '“I’m here for a good time, not a long time” between Covid and climate change, you’re here for neither', 'location': 'ur moms house'}, {'created_at': '2021-12-31T05:09:59.000Z', 'id': 1476782666972344334, 'author_id': 1043168694963200001, 'original_text': 'quebec will really let someone positive for covid work but not someone wearing a hijab lol', 'location': 'Japan'}, {'created_at': '2021-12-31T05:09:59.000Z', 'id': 1476782666783596545, 'author_id': 1257280909, 'original_text': 'Totalmente de acuerdo con empezar a pedir el certificado de vacunación para ir a lugares públicos. Poner en riesgo a otros por ser antivacunas no es justo. Eso no es perder la libertad. Perder la libertad es terminar internado o muerto por un par de egoístas.', 'location': None}, {'created_at': '2021-12-31T05:09:59.000Z', 'id': 1476782666188038146, 'author_id': 1109237518501859328, 'original_text': 'En conclusión, TODOS tienen covid pero unos dicen que es gripa y los otros ya se hicieron la prueba.', 'location': None}, {'created_at': '2021-12-31T05:09:59.000Z', 'id': 1476782665248485395, 'author_id': 995076839390547979, 'original_text': 'UFRJ ainda exigirá comprovação vacinal contra covid-19 para acesso a espaços da Universidade.\nhttps://t.co/I6GvkbPOEk\n\n#ufrj #vacina #covid19 https://t.co/Dd79rutNDn', 'location': 'Saquarema, Brasil'}, {'created_at': '2021-12-31T05:09:59.000Z', 'id': 1476782665047035904, 'author_id': 704555058654883840, 'original_text': 'If everyone who has been grateful for NHS staff over the last two years followed and retweeted, we would reach a million in no time.\n\nIt will only take a few seconds, and your support would really mean a lot to a huge number of people who continue to fight Covid-19. https://t.co/q3UHkk82Rc', 'location': 'Austral, Sydney'}, {'created_at': '2021-12-31T05:09:59.000Z', 'id': 1476782664908611585, 'author_id': 1122014915735089152, 'original_text': 'COVID-19 vaccine mandates “have to be repealed” as the vaccines are “still in research” and “people cannot be mandated to participate in research,” says\xa0@P_McCulloughMD \nhttps://t.co/ReBmW1uNfm', 'location': None}, {'created_at': '2021-12-31T05:09:59.000Z', 'id': 1476782664447373330, 'author_id': 1378566968253513729, 'original_text': 'The latest VAERS covid vaccine ‘adverse event’ reports stats have been published. When we consider that maybe 1% of all reports make it to the list, you can add two zero’s onto each number, making for uncomfortable reading... https://t.co/MxpH1eKo2t', 'location': 'NH'}, {'created_at': '2021-12-31T05:09:59.000Z', 'id': 1476782664275447810, 'author_id': 1190492803366838272, 'original_text': 'Polémico festejo de Fin de Año en la Afip: 160 contagiados con Covid. LN+', 'location': 'Ciudad Autónoma de Buenos Aire'})]
(Background on this error at: http://sqlalche.me/e/13/9h9h)
[2022-01-05 06:01:51,363] {local_task_job.py:154} INFO - Task exited with return code 1
[2022-01-05 06:01:51,431] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-01-05 06:06:15,926] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [queued]>
[2022-01-05 06:06:15,937] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [queued]>
[2022-01-05 06:06:15,937] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 06:06:15,937] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 06:06:15,937] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 06:06:15,949] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 05:00:00+00:00
[2022-01-05 06:06:15,954] {standard_task_runner.py:52} INFO - Started process 1866 to run task
[2022-01-05 06:06:15,957] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T05:00:00+00:00', '--job-id', '200', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmp0_u3p45f', '--error-file', '/tmp/tmpm5ij3c4s']
[2022-01-05 06:06:15,958] {standard_task_runner.py:77} INFO - Job 200: Subtask tweet_load
[2022-01-05 06:06:16,005] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [running]> on host 2b1d65872a35
[2022-01-05 06:06:16,053] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T05:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T05:00:00+00:00
[2022-01-05 06:06:16,055] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:06:16,055] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:06:16,055] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:06:16,055] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:06:16,055] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:06:16,055] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:06:16,055] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:06:16,055] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:06:16,056] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:06:16,056] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:06:16,056] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:06:16,056] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:06:16,056] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7fd8b40b1950>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 05:00:00+00:00: scheduled__2021-12-31T05:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 6, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 6, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-31', 'prev_ds_nodash': '20211231', 'prev_execution_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T05:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T05:00:00+00:00', 'ts_nodash': '20211231T050000', 'ts_nodash_with_tz': '20211231T050000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T05:00:00+00:00', 'tsnodash_var': '20211231T050000', 'templates_dict': None}
[2022-01-05 06:06:16,056] {logging_mixin.py:109} INFO - Hello, Current Time:06:06:16 Execution time is 2021-12-31T05:00:00+00:00
[2022-01-05 06:06:16,073] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 06:06:16,080] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 06:06:27,309] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
psycopg2.errors.StringDataRightTruncation: value too long for type character varying(200)


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 136, in load_tweets
    tweet_data.to_sql('tweet', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1770, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1350, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1340, in insert_records
    table.insert(chunksize=chunksize, method=method)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 967, in insert
    exec_insert(conn, keys, chunk_iter)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 882, in _execute_insert
    conn.execute(self.table.insert(), data)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
sqlalchemy.exc.DataError: (psycopg2.errors.StringDataRightTruncation) value too long for type character varying(200)

[SQL: INSERT INTO tweet (author_id, created_at, id, original_text, location) VALUES (%(author_id)s, %(created_at)s, %(id)s, %(original_text)s, %(location)s)]
[parameters: ({'author_id': 4687651890, 'created_at': '2021-12-31T05:09:59.000Z', 'id': 4687651890, 'original_text': 'plata, covid, y suerte en el amor nunca tuve', 'location': 'Rio Tercero'}, {'author_id': 1001136081994174464, 'created_at': '2021-12-31T05:09:59.000Z', 'id': 1001136081994174464, 'original_text': '“I’m here for a good time, not a long time” between Covid and climate change, you’re here for neither', 'location': 'ur moms house'}, {'author_id': 1043168694963200001, 'created_at': '2021-12-31T05:09:59.000Z', 'id': 1043168694963200001, 'original_text': 'quebec will really let someone positive for covid work but not someone wearing a hijab lol', 'location': 'Japan'}, {'author_id': 1257280909, 'created_at': '2021-12-31T05:09:59.000Z', 'id': 1257280909, 'original_text': 'Totalmente de acuerdo con empezar a pedir el certificado de vacunación para ir a lugares públicos. Poner en riesgo a otros por ser antivacunas no es justo. Eso no es perder la libertad. Perder la libertad es terminar internado o muerto por un par de egoístas.', 'location': None}, {'author_id': 1109237518501859328, 'created_at': '2021-12-31T05:09:59.000Z', 'id': 1109237518501859328, 'original_text': 'En conclusión, TODOS tienen covid pero unos dicen que es gripa y los otros ya se hicieron la prueba.', 'location': None}, {'author_id': 995076839390547979, 'created_at': '2021-12-31T05:09:59.000Z', 'id': 995076839390547979, 'original_text': 'UFRJ ainda exigirá comprovação vacinal contra covid-19 para acesso a espaços da Universidade.\nhttps://t.co/I6GvkbPOEk\n\n#ufrj #vacina #covid19 https://t.co/Dd79rutNDn', 'location': 'Saquarema, Brasil'}, {'author_id': 704555058654883840, 'created_at': '2021-12-31T05:09:59.000Z', 'id': 704555058654883840, 'original_text': 'If everyone who has been grateful for NHS staff over the last two years followed and retweeted, we would reach a million in no time.\n\nIt will only take a few seconds, and your support would really mean a lot to a huge number of people who continue to fight Covid-19. https://t.co/q3UHkk82Rc', 'location': 'Austral, Sydney'}, {'author_id': 1122014915735089152, 'created_at': '2021-12-31T05:09:59.000Z', 'id': 1122014915735089152, 'original_text': 'COVID-19 vaccine mandates “have to be repealed” as the vaccines are “still in research” and “people cannot be mandated to participate in research,” says\xa0@P_McCulloughMD \nhttps://t.co/ReBmW1uNfm', 'location': None}, {'author_id': 1378566968253513729, 'created_at': '2021-12-31T05:09:59.000Z', 'id': 1378566968253513729, 'original_text': 'The latest VAERS covid vaccine ‘adverse event’ reports stats have been published. When we consider that maybe 1% of all reports make it to the list, you can add two zero’s onto each number, making for uncomfortable reading... https://t.co/MxpH1eKo2t', 'location': 'NH'}, {'author_id': 1190492803366838272, 'created_at': '2021-12-31T05:09:59.000Z', 'id': 1190492803366838272, 'original_text': 'Polémico festejo de Fin de Año en la Afip: 160 contagiados con Covid. LN+', 'location': 'Ciudad Autónoma de Buenos Aire'})]
(Background on this error at: http://sqlalche.me/e/13/9h9h)
[2022-01-05 06:06:27,327] {taskinstance.py:1277} INFO - Marking task as FAILED. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T050000, start_date=20220105T060615, end_date=20220105T060627
[2022-01-05 06:06:27,342] {standard_task_runner.py:92} ERROR - Failed to execute job 200 for task tweet_load
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
psycopg2.errors.StringDataRightTruncation: value too long for type character varying(200)


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 136, in load_tweets
    tweet_data.to_sql('tweet', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1770, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1350, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1340, in insert_records
    table.insert(chunksize=chunksize, method=method)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 967, in insert
    exec_insert(conn, keys, chunk_iter)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 882, in _execute_insert
    conn.execute(self.table.insert(), data)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
sqlalchemy.exc.DataError: (psycopg2.errors.StringDataRightTruncation) value too long for type character varying(200)

[SQL: INSERT INTO tweet (author_id, created_at, id, original_text, location) VALUES (%(author_id)s, %(created_at)s, %(id)s, %(original_text)s, %(location)s)]
[parameters: ({'author_id': 4687651890, 'created_at': '2021-12-31T05:09:59.000Z', 'id': 4687651890, 'original_text': 'plata, covid, y suerte en el amor nunca tuve', 'location': 'Rio Tercero'}, {'author_id': 1001136081994174464, 'created_at': '2021-12-31T05:09:59.000Z', 'id': 1001136081994174464, 'original_text': '“I’m here for a good time, not a long time” between Covid and climate change, you’re here for neither', 'location': 'ur moms house'}, {'author_id': 1043168694963200001, 'created_at': '2021-12-31T05:09:59.000Z', 'id': 1043168694963200001, 'original_text': 'quebec will really let someone positive for covid work but not someone wearing a hijab lol', 'location': 'Japan'}, {'author_id': 1257280909, 'created_at': '2021-12-31T05:09:59.000Z', 'id': 1257280909, 'original_text': 'Totalmente de acuerdo con empezar a pedir el certificado de vacunación para ir a lugares públicos. Poner en riesgo a otros por ser antivacunas no es justo. Eso no es perder la libertad. Perder la libertad es terminar internado o muerto por un par de egoístas.', 'location': None}, {'author_id': 1109237518501859328, 'created_at': '2021-12-31T05:09:59.000Z', 'id': 1109237518501859328, 'original_text': 'En conclusión, TODOS tienen covid pero unos dicen que es gripa y los otros ya se hicieron la prueba.', 'location': None}, {'author_id': 995076839390547979, 'created_at': '2021-12-31T05:09:59.000Z', 'id': 995076839390547979, 'original_text': 'UFRJ ainda exigirá comprovação vacinal contra covid-19 para acesso a espaços da Universidade.\nhttps://t.co/I6GvkbPOEk\n\n#ufrj #vacina #covid19 https://t.co/Dd79rutNDn', 'location': 'Saquarema, Brasil'}, {'author_id': 704555058654883840, 'created_at': '2021-12-31T05:09:59.000Z', 'id': 704555058654883840, 'original_text': 'If everyone who has been grateful for NHS staff over the last two years followed and retweeted, we would reach a million in no time.\n\nIt will only take a few seconds, and your support would really mean a lot to a huge number of people who continue to fight Covid-19. https://t.co/q3UHkk82Rc', 'location': 'Austral, Sydney'}, {'author_id': 1122014915735089152, 'created_at': '2021-12-31T05:09:59.000Z', 'id': 1122014915735089152, 'original_text': 'COVID-19 vaccine mandates “have to be repealed” as the vaccines are “still in research” and “people cannot be mandated to participate in research,” says\xa0@P_McCulloughMD \nhttps://t.co/ReBmW1uNfm', 'location': None}, {'author_id': 1378566968253513729, 'created_at': '2021-12-31T05:09:59.000Z', 'id': 1378566968253513729, 'original_text': 'The latest VAERS covid vaccine ‘adverse event’ reports stats have been published. When we consider that maybe 1% of all reports make it to the list, you can add two zero’s onto each number, making for uncomfortable reading... https://t.co/MxpH1eKo2t', 'location': 'NH'}, {'author_id': 1190492803366838272, 'created_at': '2021-12-31T05:09:59.000Z', 'id': 1190492803366838272, 'original_text': 'Polémico festejo de Fin de Año en la Afip: 160 contagiados con Covid. LN+', 'location': 'Ciudad Autónoma de Buenos Aire'})]
(Background on this error at: http://sqlalche.me/e/13/9h9h)
[2022-01-05 06:06:27,367] {local_task_job.py:154} INFO - Task exited with return code 1
[2022-01-05 06:06:27,396] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-01-05 06:09:24,144] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [queued]>
[2022-01-05 06:09:24,170] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [queued]>
[2022-01-05 06:09:24,170] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 06:09:24,170] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 06:09:24,170] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 06:09:24,187] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 05:00:00+00:00
[2022-01-05 06:09:24,193] {standard_task_runner.py:52} INFO - Started process 2064 to run task
[2022-01-05 06:09:24,195] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T05:00:00+00:00', '--job-id', '218', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmpzdzvm8np', '--error-file', '/tmp/tmpxqzmerd5']
[2022-01-05 06:09:24,196] {standard_task_runner.py:77} INFO - Job 218: Subtask tweet_load
[2022-01-05 06:09:24,246] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [running]> on host 2b1d65872a35
[2022-01-05 06:09:24,305] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T05:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T05:00:00+00:00
[2022-01-05 06:09:24,307] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:09:24,307] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:09:24,307] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:09:24,307] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:09:24,307] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:09:24,308] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:09:24,308] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:09:24,308] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:09:24,308] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:09:24,308] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:09:24,308] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:09:24,308] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:09:24,309] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7fd8b40b1950>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 05:00:00+00:00: scheduled__2021-12-31T05:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 6, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 6, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-31', 'prev_ds_nodash': '20211231', 'prev_execution_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T05:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T05:00:00+00:00', 'ts_nodash': '20211231T050000', 'ts_nodash_with_tz': '20211231T050000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T05:00:00+00:00', 'tsnodash_var': '20211231T050000', 'templates_dict': None}
[2022-01-05 06:09:24,309] {logging_mixin.py:109} INFO - Hello, Current Time:06:09:24 Execution time is 2021-12-31T05:00:00+00:00
[2022-01-05 06:09:24,324] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 06:09:24,333] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 06:09:25,975] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
psycopg2.errors.StringDataRightTruncation: value too long for type character varying(256)


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 136, in load_tweets
    tweet_data.to_sql('tweet', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1770, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1350, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1340, in insert_records
    table.insert(chunksize=chunksize, method=method)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 967, in insert
    exec_insert(conn, keys, chunk_iter)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 882, in _execute_insert
    conn.execute(self.table.insert(), data)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
sqlalchemy.exc.DataError: (psycopg2.errors.StringDataRightTruncation) value too long for type character varying(256)

[SQL: INSERT INTO tweet (created_at, author_id, id, original_text, location) VALUES (%(created_at)s, %(author_id)s, %(id)s, %(original_text)s, %(location)s)]
[parameters: ({'created_at': '2021-12-31T05:09:59.000Z', 'author_id': 4687651890, 'id': 4687651890, 'original_text': 'plata, covid, y suerte en el amor nunca tuve', 'location': 'Rio Tercero'}, {'created_at': '2021-12-31T05:09:59.000Z', 'author_id': 1001136081994174464, 'id': 1001136081994174464, 'original_text': '“I’m here for a good time, not a long time” between Covid and climate change, you’re here for neither', 'location': 'ur moms house'}, {'created_at': '2021-12-31T05:09:59.000Z', 'author_id': 1043168694963200001, 'id': 1043168694963200001, 'original_text': 'quebec will really let someone positive for covid work but not someone wearing a hijab lol', 'location': 'Japan'}, {'created_at': '2021-12-31T05:09:59.000Z', 'author_id': 1257280909, 'id': 1257280909, 'original_text': 'Totalmente de acuerdo con empezar a pedir el certificado de vacunación para ir a lugares públicos. Poner en riesgo a otros por ser antivacunas no es justo. Eso no es perder la libertad. Perder la libertad es terminar internado o muerto por un par de egoístas.', 'location': None}, {'created_at': '2021-12-31T05:09:59.000Z', 'author_id': 1109237518501859328, 'id': 1109237518501859328, 'original_text': 'En conclusión, TODOS tienen covid pero unos dicen que es gripa y los otros ya se hicieron la prueba.', 'location': None}, {'created_at': '2021-12-31T05:09:59.000Z', 'author_id': 995076839390547979, 'id': 995076839390547979, 'original_text': 'UFRJ ainda exigirá comprovação vacinal contra covid-19 para acesso a espaços da Universidade.\nhttps://t.co/I6GvkbPOEk\n\n#ufrj #vacina #covid19 https://t.co/Dd79rutNDn', 'location': 'Saquarema, Brasil'}, {'created_at': '2021-12-31T05:09:59.000Z', 'author_id': 704555058654883840, 'id': 704555058654883840, 'original_text': 'If everyone who has been grateful for NHS staff over the last two years followed and retweeted, we would reach a million in no time.\n\nIt will only take a few seconds, and your support would really mean a lot to a huge number of people who continue to fight Covid-19. https://t.co/q3UHkk82Rc', 'location': 'Austral, Sydney'}, {'created_at': '2021-12-31T05:09:59.000Z', 'author_id': 1122014915735089152, 'id': 1122014915735089152, 'original_text': 'COVID-19 vaccine mandates “have to be repealed” as the vaccines are “still in research” and “people cannot be mandated to participate in research,” says\xa0@P_McCulloughMD \nhttps://t.co/ReBmW1uNfm', 'location': None}, {'created_at': '2021-12-31T05:09:59.000Z', 'author_id': 1378566968253513729, 'id': 1378566968253513729, 'original_text': 'The latest VAERS covid vaccine ‘adverse event’ reports stats have been published. When we consider that maybe 1% of all reports make it to the list, you can add two zero’s onto each number, making for uncomfortable reading... https://t.co/MxpH1eKo2t', 'location': 'NH'}, {'created_at': '2021-12-31T05:09:59.000Z', 'author_id': 1190492803366838272, 'id': 1190492803366838272, 'original_text': 'Polémico festejo de Fin de Año en la Afip: 160 contagiados con Covid. LN+', 'location': 'Ciudad Autónoma de Buenos Aire'})]
(Background on this error at: http://sqlalche.me/e/13/9h9h)
[2022-01-05 06:09:25,994] {taskinstance.py:1277} INFO - Marking task as FAILED. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T050000, start_date=20220105T060924, end_date=20220105T060925
[2022-01-05 06:09:26,015] {standard_task_runner.py:92} ERROR - Failed to execute job 218 for task tweet_load
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
psycopg2.errors.StringDataRightTruncation: value too long for type character varying(256)


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 136, in load_tweets
    tweet_data.to_sql('tweet', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1770, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1350, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1340, in insert_records
    table.insert(chunksize=chunksize, method=method)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 967, in insert
    exec_insert(conn, keys, chunk_iter)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 882, in _execute_insert
    conn.execute(self.table.insert(), data)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
sqlalchemy.exc.DataError: (psycopg2.errors.StringDataRightTruncation) value too long for type character varying(256)

[SQL: INSERT INTO tweet (created_at, author_id, id, original_text, location) VALUES (%(created_at)s, %(author_id)s, %(id)s, %(original_text)s, %(location)s)]
[parameters: ({'created_at': '2021-12-31T05:09:59.000Z', 'author_id': 4687651890, 'id': 4687651890, 'original_text': 'plata, covid, y suerte en el amor nunca tuve', 'location': 'Rio Tercero'}, {'created_at': '2021-12-31T05:09:59.000Z', 'author_id': 1001136081994174464, 'id': 1001136081994174464, 'original_text': '“I’m here for a good time, not a long time” between Covid and climate change, you’re here for neither', 'location': 'ur moms house'}, {'created_at': '2021-12-31T05:09:59.000Z', 'author_id': 1043168694963200001, 'id': 1043168694963200001, 'original_text': 'quebec will really let someone positive for covid work but not someone wearing a hijab lol', 'location': 'Japan'}, {'created_at': '2021-12-31T05:09:59.000Z', 'author_id': 1257280909, 'id': 1257280909, 'original_text': 'Totalmente de acuerdo con empezar a pedir el certificado de vacunación para ir a lugares públicos. Poner en riesgo a otros por ser antivacunas no es justo. Eso no es perder la libertad. Perder la libertad es terminar internado o muerto por un par de egoístas.', 'location': None}, {'created_at': '2021-12-31T05:09:59.000Z', 'author_id': 1109237518501859328, 'id': 1109237518501859328, 'original_text': 'En conclusión, TODOS tienen covid pero unos dicen que es gripa y los otros ya se hicieron la prueba.', 'location': None}, {'created_at': '2021-12-31T05:09:59.000Z', 'author_id': 995076839390547979, 'id': 995076839390547979, 'original_text': 'UFRJ ainda exigirá comprovação vacinal contra covid-19 para acesso a espaços da Universidade.\nhttps://t.co/I6GvkbPOEk\n\n#ufrj #vacina #covid19 https://t.co/Dd79rutNDn', 'location': 'Saquarema, Brasil'}, {'created_at': '2021-12-31T05:09:59.000Z', 'author_id': 704555058654883840, 'id': 704555058654883840, 'original_text': 'If everyone who has been grateful for NHS staff over the last two years followed and retweeted, we would reach a million in no time.\n\nIt will only take a few seconds, and your support would really mean a lot to a huge number of people who continue to fight Covid-19. https://t.co/q3UHkk82Rc', 'location': 'Austral, Sydney'}, {'created_at': '2021-12-31T05:09:59.000Z', 'author_id': 1122014915735089152, 'id': 1122014915735089152, 'original_text': 'COVID-19 vaccine mandates “have to be repealed” as the vaccines are “still in research” and “people cannot be mandated to participate in research,” says\xa0@P_McCulloughMD \nhttps://t.co/ReBmW1uNfm', 'location': None}, {'created_at': '2021-12-31T05:09:59.000Z', 'author_id': 1378566968253513729, 'id': 1378566968253513729, 'original_text': 'The latest VAERS covid vaccine ‘adverse event’ reports stats have been published. When we consider that maybe 1% of all reports make it to the list, you can add two zero’s onto each number, making for uncomfortable reading... https://t.co/MxpH1eKo2t', 'location': 'NH'}, {'created_at': '2021-12-31T05:09:59.000Z', 'author_id': 1190492803366838272, 'id': 1190492803366838272, 'original_text': 'Polémico festejo de Fin de Año en la Afip: 160 contagiados con Covid. LN+', 'location': 'Ciudad Autónoma de Buenos Aire'})]
(Background on this error at: http://sqlalche.me/e/13/9h9h)
[2022-01-05 06:09:26,057] {local_task_job.py:154} INFO - Task exited with return code 1
[2022-01-05 06:09:26,094] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-01-05 06:25:35,297] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [queued]>
[2022-01-05 06:25:35,308] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [queued]>
[2022-01-05 06:25:35,308] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 06:25:35,308] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 06:25:35,308] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 06:25:35,320] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 05:00:00+00:00
[2022-01-05 06:25:35,327] {standard_task_runner.py:52} INFO - Started process 2831 to run task
[2022-01-05 06:25:35,330] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T05:00:00+00:00', '--job-id', '236', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmpnpt7g6t5', '--error-file', '/tmp/tmp_0tcao9g']
[2022-01-05 06:25:35,331] {standard_task_runner.py:77} INFO - Job 236: Subtask tweet_load
[2022-01-05 06:25:35,386] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [running]> on host 2b1d65872a35
[2022-01-05 06:25:35,444] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T05:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T05:00:00+00:00
[2022-01-05 06:25:35,446] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:25:35,446] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:25:35,446] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:25:35,446] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:25:35,446] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:25:35,446] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:25:35,446] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:25:35,446] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:25:35,446] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:25:35,447] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:25:35,447] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:25:35,447] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:25:35,447] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7fd8b40b1950>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 05:00:00+00:00: scheduled__2021-12-31T05:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 6, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 6, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-31', 'prev_ds_nodash': '20211231', 'prev_execution_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T05:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T05:00:00+00:00', 'ts_nodash': '20211231T050000', 'ts_nodash_with_tz': '20211231T050000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T05:00:00+00:00', 'tsnodash_var': '20211231T050000', 'templates_dict': None}
[2022-01-05 06:25:35,447] {logging_mixin.py:109} INFO - Hello, Current Time:06:25:35 Execution time is 2021-12-31T05:00:00+00:00
[2022-01-05 06:25:35,459] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 06:25:35,466] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 06:25:37,624] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
psycopg2.errors.StringDataRightTruncation: value too long for type character varying(256)


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 137, in load_tweets
    tweet_data.to_sql('tweet', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1770, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1350, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1340, in insert_records
    table.insert(chunksize=chunksize, method=method)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 967, in insert
    exec_insert(conn, keys, chunk_iter)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 882, in _execute_insert
    conn.execute(self.table.insert(), data)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
sqlalchemy.exc.DataError: (psycopg2.errors.StringDataRightTruncation) value too long for type character varying(256)

[SQL: INSERT INTO tweet (author_id, id, created_at, original_text, location) VALUES (%(author_id)s, %(id)s, %(created_at)s, %(original_text)s, %(location)s)]
[parameters: ({'author_id': 4687651890, 'id': 4687651890, 'created_at': '2021-12-31T05:09:59.000Z', 'original_text': 'plata, covid, y suerte en el amor nunca tuve', 'location': 'Rio Tercero'}, {'author_id': 1001136081994174464, 'id': 1001136081994174464, 'created_at': '2021-12-31T05:09:59.000Z', 'original_text': 'Im here for a good time, not a long time between Covid and climate change, youre here for neither', 'location': 'ur moms house'}, {'author_id': 1043168694963200001, 'id': 1043168694963200001, 'created_at': '2021-12-31T05:09:59.000Z', 'original_text': 'quebec will really let someone positive for covid work but not someone wearing a hijab lol', 'location': 'Japan'}, {'author_id': 1257280909, 'id': 1257280909, 'created_at': '2021-12-31T05:09:59.000Z', 'original_text': 'Totalmente de acuerdo con empezar a pedir el certificado de vacunacin para ir a lugares pblicos. Poner en riesgo a otros por ser antivacunas no es justo. Eso no es perder la libertad. Perder la libertad es terminar internado o muerto por un par de egostas.', 'location': None}, {'author_id': 1109237518501859328, 'id': 1109237518501859328, 'created_at': '2021-12-31T05:09:59.000Z', 'original_text': 'En conclusin, TODOS tienen covid pero unos dicen que es gripa y los otros ya se hicieron la prueba.', 'location': None}, {'author_id': 995076839390547979, 'id': 995076839390547979, 'created_at': '2021-12-31T05:09:59.000Z', 'original_text': 'UFRJ ainda exigir comprovao vacinal contra covid-19 para acesso a espaos da Universidade.\nhttps://t.co/I6GvkbPOEk\n\n#ufrj #vacina #covid19 https://t.co/Dd79rutNDn', 'location': 'Saquarema, Brasil'}, {'author_id': 704555058654883840, 'id': 704555058654883840, 'created_at': '2021-12-31T05:09:59.000Z', 'original_text': 'If everyone who has been grateful for NHS staff over the last two years followed and retweeted, we would reach a million in no time.\n\nIt will only take a few seconds, and your support would really mean a lot to a huge number of people who continue to fight Covid-19. https://t.co/q3UHkk82Rc', 'location': 'Austral, Sydney'}, {'author_id': 1122014915735089152, 'id': 1122014915735089152, 'created_at': '2021-12-31T05:09:59.000Z', 'original_text': 'COVID-19 vaccine mandates have to be repealed as the vaccines are still in research and people cannot be mandated to participate in research, says@P_McCulloughMD \nhttps://t.co/ReBmW1uNfm', 'location': None}, {'author_id': 1378566968253513729, 'id': 1378566968253513729, 'created_at': '2021-12-31T05:09:59.000Z', 'original_text': 'The latest VAERS covid vaccine adverse event reports stats have been published. When we consider that maybe 1% of all reports make it to the list, you can add two zeros onto each number, making for uncomfortable reading... https://t.co/MxpH1eKo2t', 'location': 'NH'}, {'author_id': 1190492803366838272, 'id': 1190492803366838272, 'created_at': '2021-12-31T05:09:59.000Z', 'original_text': 'Polmico festejo de Fin de Ao en la Afip: 160 contagiados con Covid. LN+', 'location': 'Ciudad Autnoma de Buenos Aire'})]
(Background on this error at: http://sqlalche.me/e/13/9h9h)
[2022-01-05 06:25:37,650] {taskinstance.py:1277} INFO - Marking task as FAILED. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T050000, start_date=20220105T062535, end_date=20220105T062537
[2022-01-05 06:25:37,662] {standard_task_runner.py:92} ERROR - Failed to execute job 236 for task tweet_load
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
psycopg2.errors.StringDataRightTruncation: value too long for type character varying(256)


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 137, in load_tweets
    tweet_data.to_sql('tweet', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1770, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1350, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1340, in insert_records
    table.insert(chunksize=chunksize, method=method)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 967, in insert
    exec_insert(conn, keys, chunk_iter)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 882, in _execute_insert
    conn.execute(self.table.insert(), data)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
sqlalchemy.exc.DataError: (psycopg2.errors.StringDataRightTruncation) value too long for type character varying(256)

[SQL: INSERT INTO tweet (author_id, id, created_at, original_text, location) VALUES (%(author_id)s, %(id)s, %(created_at)s, %(original_text)s, %(location)s)]
[parameters: ({'author_id': 4687651890, 'id': 4687651890, 'created_at': '2021-12-31T05:09:59.000Z', 'original_text': 'plata, covid, y suerte en el amor nunca tuve', 'location': 'Rio Tercero'}, {'author_id': 1001136081994174464, 'id': 1001136081994174464, 'created_at': '2021-12-31T05:09:59.000Z', 'original_text': 'Im here for a good time, not a long time between Covid and climate change, youre here for neither', 'location': 'ur moms house'}, {'author_id': 1043168694963200001, 'id': 1043168694963200001, 'created_at': '2021-12-31T05:09:59.000Z', 'original_text': 'quebec will really let someone positive for covid work but not someone wearing a hijab lol', 'location': 'Japan'}, {'author_id': 1257280909, 'id': 1257280909, 'created_at': '2021-12-31T05:09:59.000Z', 'original_text': 'Totalmente de acuerdo con empezar a pedir el certificado de vacunacin para ir a lugares pblicos. Poner en riesgo a otros por ser antivacunas no es justo. Eso no es perder la libertad. Perder la libertad es terminar internado o muerto por un par de egostas.', 'location': None}, {'author_id': 1109237518501859328, 'id': 1109237518501859328, 'created_at': '2021-12-31T05:09:59.000Z', 'original_text': 'En conclusin, TODOS tienen covid pero unos dicen que es gripa y los otros ya se hicieron la prueba.', 'location': None}, {'author_id': 995076839390547979, 'id': 995076839390547979, 'created_at': '2021-12-31T05:09:59.000Z', 'original_text': 'UFRJ ainda exigir comprovao vacinal contra covid-19 para acesso a espaos da Universidade.\nhttps://t.co/I6GvkbPOEk\n\n#ufrj #vacina #covid19 https://t.co/Dd79rutNDn', 'location': 'Saquarema, Brasil'}, {'author_id': 704555058654883840, 'id': 704555058654883840, 'created_at': '2021-12-31T05:09:59.000Z', 'original_text': 'If everyone who has been grateful for NHS staff over the last two years followed and retweeted, we would reach a million in no time.\n\nIt will only take a few seconds, and your support would really mean a lot to a huge number of people who continue to fight Covid-19. https://t.co/q3UHkk82Rc', 'location': 'Austral, Sydney'}, {'author_id': 1122014915735089152, 'id': 1122014915735089152, 'created_at': '2021-12-31T05:09:59.000Z', 'original_text': 'COVID-19 vaccine mandates have to be repealed as the vaccines are still in research and people cannot be mandated to participate in research, says@P_McCulloughMD \nhttps://t.co/ReBmW1uNfm', 'location': None}, {'author_id': 1378566968253513729, 'id': 1378566968253513729, 'created_at': '2021-12-31T05:09:59.000Z', 'original_text': 'The latest VAERS covid vaccine adverse event reports stats have been published. When we consider that maybe 1% of all reports make it to the list, you can add two zeros onto each number, making for uncomfortable reading... https://t.co/MxpH1eKo2t', 'location': 'NH'}, {'author_id': 1190492803366838272, 'id': 1190492803366838272, 'created_at': '2021-12-31T05:09:59.000Z', 'original_text': 'Polmico festejo de Fin de Ao en la Afip: 160 contagiados con Covid. LN+', 'location': 'Ciudad Autnoma de Buenos Aire'})]
(Background on this error at: http://sqlalche.me/e/13/9h9h)
[2022-01-05 06:25:37,670] {local_task_job.py:154} INFO - Task exited with return code 1
[2022-01-05 06:25:37,703] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-01-05 06:28:29,596] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [queued]>
[2022-01-05 06:28:29,622] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [queued]>
[2022-01-05 06:28:29,622] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 06:28:29,623] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 06:28:29,623] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 06:28:29,644] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 05:00:00+00:00
[2022-01-05 06:28:29,650] {standard_task_runner.py:52} INFO - Started process 3011 to run task
[2022-01-05 06:28:29,658] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T05:00:00+00:00', '--job-id', '254', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmp1c66_xqt', '--error-file', '/tmp/tmp0zfpm61c']
[2022-01-05 06:28:29,661] {standard_task_runner.py:77} INFO - Job 254: Subtask tweet_load
[2022-01-05 06:28:29,735] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [running]> on host 2b1d65872a35
[2022-01-05 06:28:29,815] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T05:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T05:00:00+00:00
[2022-01-05 06:28:29,817] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:28:29,817] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:28:29,817] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:28:29,817] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:28:29,817] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:28:29,817] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:28:29,817] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:28:29,817] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:28:29,818] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:28:29,818] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:28:29,818] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:28:29,818] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:28:29,818] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7fd8b40b1950>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 05:00:00+00:00: scheduled__2021-12-31T05:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 6, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 6, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-31', 'prev_ds_nodash': '20211231', 'prev_execution_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T05:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T05:00:00+00:00', 'ts_nodash': '20211231T050000', 'ts_nodash_with_tz': '20211231T050000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T05:00:00+00:00', 'tsnodash_var': '20211231T050000', 'templates_dict': None}
[2022-01-05 06:28:29,818] {logging_mixin.py:109} INFO - Hello, Current Time:06:28:29 Execution time is 2021-12-31T05:00:00+00:00
[2022-01-05 06:28:29,839] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 06:28:29,860] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 06:28:31,807] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
psycopg2.errors.StringDataRightTruncation: value too long for type character varying(256)


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 139, in load_tweets
    tweet_data.to_sql('tweet', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1770, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1350, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1340, in insert_records
    table.insert(chunksize=chunksize, method=method)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 967, in insert
    exec_insert(conn, keys, chunk_iter)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 882, in _execute_insert
    conn.execute(self.table.insert(), data)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
sqlalchemy.exc.DataError: (psycopg2.errors.StringDataRightTruncation) value too long for type character varying(256)

[SQL: INSERT INTO tweet (author_id, created_at, id, original_text, location) VALUES (%(author_id)s, %(created_at)s, %(id)s, %(original_text)s, %(location)s)]
[parameters: ({'author_id': 4687651890, 'created_at': '2021-12-31T05:09:59.000Z', 'id': 4687651890, 'original_text': 'plata, covid, y suerte en el amor nunca tuve', 'location': 'Rio Tercero'}, {'author_id': 1001136081994174464, 'created_at': '2021-12-31T05:09:59.000Z', 'id': 1001136081994174464, 'original_text': 'Im here for a good time, not a long time between Covid and climate change, youre here for neither', 'location': 'ur moms house'}, {'author_id': 1043168694963200001, 'created_at': '2021-12-31T05:09:59.000Z', 'id': 1043168694963200001, 'original_text': 'quebec will really let someone positive for covid work but not someone wearing a hijab lol', 'location': 'Japan'}, {'author_id': 1257280909, 'created_at': '2021-12-31T05:09:59.000Z', 'id': 1257280909, 'original_text': 'Totalmente de acuerdo con empezar a pedir el certificado de vacunacin para ir a lugares pblicos. Poner en riesgo a otros por ser antivacunas no es justo. Eso no es perder la libertad. Perder la libertad es terminar internado o muerto por un par de egostas.', 'location': None}, {'author_id': 1109237518501859328, 'created_at': '2021-12-31T05:09:59.000Z', 'id': 1109237518501859328, 'original_text': 'En conclusin, TODOS tienen covid pero unos dicen que es gripa y los otros ya se hicieron la prueba.', 'location': None}, {'author_id': 995076839390547979, 'created_at': '2021-12-31T05:09:59.000Z', 'id': 995076839390547979, 'original_text': 'UFRJ ainda exigir comprovao vacinal contra covid-19 para acesso a espaos da Universidade.\nhttps://t.co/I6GvkbPOEk\n\n#ufrj #vacina #covid19 https://t.co/Dd79rutNDn', 'location': 'Saquarema, Brasil'}, {'author_id': 704555058654883840, 'created_at': '2021-12-31T05:09:59.000Z', 'id': 704555058654883840, 'original_text': 'If everyone who has been grateful for NHS staff over the last two years followed and retweeted, we would reach a million in no time.\n\nIt will only take a few seconds, and your support would really mean a lot to a huge number of people who continue to fight Covid-19. https://t.co/q3UHkk82Rc', 'location': 'Austral, Sydney'}, {'author_id': 1122014915735089152, 'created_at': '2021-12-31T05:09:59.000Z', 'id': 1122014915735089152, 'original_text': 'COVID-19 vaccine mandates have to be repealed as the vaccines are still in research and people cannot be mandated to participate in research, says@P_McCulloughMD \nhttps://t.co/ReBmW1uNfm', 'location': None}, {'author_id': 1378566968253513729, 'created_at': '2021-12-31T05:09:59.000Z', 'id': 1378566968253513729, 'original_text': 'The latest VAERS covid vaccine adverse event reports stats have been published. When we consider that maybe 1% of all reports make it to the list, you can add two zeros onto each number, making for uncomfortable reading... https://t.co/MxpH1eKo2t', 'location': 'NH'}, {'author_id': 1190492803366838272, 'created_at': '2021-12-31T05:09:59.000Z', 'id': 1190492803366838272, 'original_text': 'Polmico festejo de Fin de Ao en la Afip: 160 contagiados con Covid. LN+', 'location': 'Ciudad Autnoma de Buenos Aire'})]
(Background on this error at: http://sqlalche.me/e/13/9h9h)
[2022-01-05 06:28:31,826] {taskinstance.py:1277} INFO - Marking task as FAILED. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T050000, start_date=20220105T062829, end_date=20220105T062831
[2022-01-05 06:28:31,842] {standard_task_runner.py:92} ERROR - Failed to execute job 254 for task tweet_load
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
psycopg2.errors.StringDataRightTruncation: value too long for type character varying(256)


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 139, in load_tweets
    tweet_data.to_sql('tweet', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1770, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1350, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1340, in insert_records
    table.insert(chunksize=chunksize, method=method)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 967, in insert
    exec_insert(conn, keys, chunk_iter)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 882, in _execute_insert
    conn.execute(self.table.insert(), data)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
sqlalchemy.exc.DataError: (psycopg2.errors.StringDataRightTruncation) value too long for type character varying(256)

[SQL: INSERT INTO tweet (author_id, created_at, id, original_text, location) VALUES (%(author_id)s, %(created_at)s, %(id)s, %(original_text)s, %(location)s)]
[parameters: ({'author_id': 4687651890, 'created_at': '2021-12-31T05:09:59.000Z', 'id': 4687651890, 'original_text': 'plata, covid, y suerte en el amor nunca tuve', 'location': 'Rio Tercero'}, {'author_id': 1001136081994174464, 'created_at': '2021-12-31T05:09:59.000Z', 'id': 1001136081994174464, 'original_text': 'Im here for a good time, not a long time between Covid and climate change, youre here for neither', 'location': 'ur moms house'}, {'author_id': 1043168694963200001, 'created_at': '2021-12-31T05:09:59.000Z', 'id': 1043168694963200001, 'original_text': 'quebec will really let someone positive for covid work but not someone wearing a hijab lol', 'location': 'Japan'}, {'author_id': 1257280909, 'created_at': '2021-12-31T05:09:59.000Z', 'id': 1257280909, 'original_text': 'Totalmente de acuerdo con empezar a pedir el certificado de vacunacin para ir a lugares pblicos. Poner en riesgo a otros por ser antivacunas no es justo. Eso no es perder la libertad. Perder la libertad es terminar internado o muerto por un par de egostas.', 'location': None}, {'author_id': 1109237518501859328, 'created_at': '2021-12-31T05:09:59.000Z', 'id': 1109237518501859328, 'original_text': 'En conclusin, TODOS tienen covid pero unos dicen que es gripa y los otros ya se hicieron la prueba.', 'location': None}, {'author_id': 995076839390547979, 'created_at': '2021-12-31T05:09:59.000Z', 'id': 995076839390547979, 'original_text': 'UFRJ ainda exigir comprovao vacinal contra covid-19 para acesso a espaos da Universidade.\nhttps://t.co/I6GvkbPOEk\n\n#ufrj #vacina #covid19 https://t.co/Dd79rutNDn', 'location': 'Saquarema, Brasil'}, {'author_id': 704555058654883840, 'created_at': '2021-12-31T05:09:59.000Z', 'id': 704555058654883840, 'original_text': 'If everyone who has been grateful for NHS staff over the last two years followed and retweeted, we would reach a million in no time.\n\nIt will only take a few seconds, and your support would really mean a lot to a huge number of people who continue to fight Covid-19. https://t.co/q3UHkk82Rc', 'location': 'Austral, Sydney'}, {'author_id': 1122014915735089152, 'created_at': '2021-12-31T05:09:59.000Z', 'id': 1122014915735089152, 'original_text': 'COVID-19 vaccine mandates have to be repealed as the vaccines are still in research and people cannot be mandated to participate in research, says@P_McCulloughMD \nhttps://t.co/ReBmW1uNfm', 'location': None}, {'author_id': 1378566968253513729, 'created_at': '2021-12-31T05:09:59.000Z', 'id': 1378566968253513729, 'original_text': 'The latest VAERS covid vaccine adverse event reports stats have been published. When we consider that maybe 1% of all reports make it to the list, you can add two zeros onto each number, making for uncomfortable reading... https://t.co/MxpH1eKo2t', 'location': 'NH'}, {'author_id': 1190492803366838272, 'created_at': '2021-12-31T05:09:59.000Z', 'id': 1190492803366838272, 'original_text': 'Polmico festejo de Fin de Ao en la Afip: 160 contagiados con Covid. LN+', 'location': 'Ciudad Autnoma de Buenos Aire'})]
(Background on this error at: http://sqlalche.me/e/13/9h9h)
[2022-01-05 06:28:31,886] {local_task_job.py:154} INFO - Task exited with return code 1
[2022-01-05 06:28:31,921] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-01-05 06:32:02,612] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [queued]>
[2022-01-05 06:32:02,630] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [queued]>
[2022-01-05 06:32:02,630] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 06:32:02,630] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 06:32:02,630] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 06:32:02,649] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 05:00:00+00:00
[2022-01-05 06:32:02,657] {standard_task_runner.py:52} INFO - Started process 3228 to run task
[2022-01-05 06:32:02,665] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T05:00:00+00:00', '--job-id', '272', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmpk82etvs9', '--error-file', '/tmp/tmpzq8din1w']
[2022-01-05 06:32:02,666] {standard_task_runner.py:77} INFO - Job 272: Subtask tweet_load
[2022-01-05 06:32:02,823] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [running]> on host 2b1d65872a35
[2022-01-05 06:32:02,955] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T05:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T05:00:00+00:00
[2022-01-05 06:32:02,956] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:32:02,957] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:32:02,957] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:32:02,957] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:32:02,957] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:32:02,957] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:32:02,957] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:32:02,957] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:32:02,957] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:32:02,958] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:32:02,958] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:32:02,958] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:32:02,958] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7fd8b40b1950>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 05:00:00+00:00: scheduled__2021-12-31T05:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 6, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 6, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-31', 'prev_ds_nodash': '20211231', 'prev_execution_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T05:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T05:00:00+00:00', 'ts_nodash': '20211231T050000', 'ts_nodash_with_tz': '20211231T050000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T05:00:00+00:00', 'tsnodash_var': '20211231T050000', 'templates_dict': None}
[2022-01-05 06:32:02,958] {logging_mixin.py:109} INFO - Hello, Current Time:06:32:02 Execution time is 2021-12-31T05:00:00+00:00
[2022-01-05 06:32:02,972] {warnings.py:110} WARNING - /opt/***/dags/load_redshift.py:137: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only
  tweet_data = tweet_data.drop('original_text', 1)

[2022-01-05 06:32:03,003] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 06:32:03,026] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 06:32:18,691] {python.py:175} INFO - Done. Returned value was: None
[2022-01-05 06:32:18,701] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T050000, start_date=20220105T063202, end_date=20220105T063218
[2022-01-05 06:32:18,718] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-01-05 06:32:18,745] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-01-05 07:02:31,472] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [queued]>
[2022-01-05 07:02:31,541] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [queued]>
[2022-01-05 07:02:31,541] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 07:02:31,542] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 07:02:31,542] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 07:02:31,599] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 05:00:00+00:00
[2022-01-05 07:02:31,620] {standard_task_runner.py:52} INFO - Started process 123 to run task
[2022-01-05 07:02:31,632] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T05:00:00+00:00', '--job-id', '325', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmpw3kkw1ut', '--error-file', '/tmp/tmpsgr4y9j2']
[2022-01-05 07:02:31,634] {standard_task_runner.py:77} INFO - Job 325: Subtask tweet_load
[2022-01-05 07:02:31,824] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [running]> on host e544fdb7c66e
[2022-01-05 07:02:31,945] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T05:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T05:00:00+00:00
[2022-01-05 07:02:31,947] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:02:31,948] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:02:31,948] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:02:31,948] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:02:31,948] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:02:31,948] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:02:31,949] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:02:31,949] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:02:31,949] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:02:31,949] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:02:31,949] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:02:31,949] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:02:31,950] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7fa6a9eda8d0>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 05:00:00+00:00: scheduled__2021-12-31T05:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 6, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 6, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-31', 'prev_ds_nodash': '20211231', 'prev_execution_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T05:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T05:00:00+00:00', 'ts_nodash': '20211231T050000', 'ts_nodash_with_tz': '20211231T050000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T05:00:00+00:00', 'tsnodash_var': '20211231T050000', 'templates_dict': None}
[2022-01-05 07:02:31,950] {logging_mixin.py:109} INFO - Hello, Current Time:07:02:31 Execution time is 2021-12-31T05:00:00+00:00
[2022-01-05 07:02:31,963] {warnings.py:110} WARNING - /opt/***/dags/load_redshift.py:137: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only
  tweet_data = tweet_data.drop('original_text', 1)

[2022-01-05 07:02:31,991] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 07:02:32,011] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 07:02:36,568] {python.py:175} INFO - Done. Returned value was: None
[2022-01-05 07:02:36,581] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T050000, start_date=20220105T070231, end_date=20220105T070236
[2022-01-05 07:02:36,615] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-01-05 07:02:36,653] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-01-05 07:04:28,717] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [queued]>
[2022-01-05 07:04:28,727] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [queued]>
[2022-01-05 07:04:28,727] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 07:04:28,727] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 07:04:28,727] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 07:04:28,738] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 05:00:00+00:00
[2022-01-05 07:04:28,744] {standard_task_runner.py:52} INFO - Started process 264 to run task
[2022-01-05 07:04:28,747] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T05:00:00+00:00', '--job-id', '344', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmp0urwa2oo', '--error-file', '/tmp/tmpafhx8dyh']
[2022-01-05 07:04:28,747] {standard_task_runner.py:77} INFO - Job 344: Subtask tweet_load
[2022-01-05 07:04:28,794] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [running]> on host e544fdb7c66e
[2022-01-05 07:04:28,842] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T05:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T05:00:00+00:00
[2022-01-05 07:04:28,843] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:04:28,843] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:04:28,843] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:04:28,844] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:04:28,844] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:04:28,844] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:04:28,844] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:04:28,844] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:04:28,844] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:04:28,844] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:04:28,845] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:04:28,845] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:04:28,845] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7fa6a9eda8d0>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 05:00:00+00:00: scheduled__2021-12-31T05:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 6, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 6, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-31', 'prev_ds_nodash': '20211231', 'prev_execution_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T05:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T05:00:00+00:00', 'ts_nodash': '20211231T050000', 'ts_nodash_with_tz': '20211231T050000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T05:00:00+00:00', 'tsnodash_var': '20211231T050000', 'templates_dict': None}
[2022-01-05 07:04:28,845] {logging_mixin.py:109} INFO - Hello, Current Time:07:04:28 Execution time is 2021-12-31T05:00:00+00:00
[2022-01-05 07:04:28,860] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 07:04:28,866] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 07:04:45,917] {python.py:175} INFO - Done. Returned value was: None
[2022-01-05 07:04:45,934] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T050000, start_date=20220105T070428, end_date=20220105T070445
[2022-01-05 07:04:45,976] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-01-05 07:04:45,997] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-01-05 18:45:41,775] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [queued]>
[2022-01-05 18:45:41,799] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [queued]>
[2022-01-05 18:45:41,799] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 18:45:41,799] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 18:45:41,799] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 18:45:41,817] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 05:00:00+00:00
[2022-01-05 18:45:41,837] {standard_task_runner.py:52} INFO - Started process 769 to run task
[2022-01-05 18:45:41,843] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T05:00:00+00:00', '--job-id', '390', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmp6lsmwtd3', '--error-file', '/tmp/tmpns6bdg0x']
[2022-01-05 18:45:41,844] {standard_task_runner.py:77} INFO - Job 390: Subtask tweet_load
[2022-01-05 18:45:41,950] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [running]> on host e544fdb7c66e
[2022-01-05 18:45:42,080] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T05:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T05:00:00+00:00
[2022-01-05 18:45:42,085] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:45:42,085] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:45:42,085] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:45:42,085] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:45:42,086] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:45:42,086] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:45:42,086] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:45:42,086] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:45:42,086] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:45:42,086] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:45:42,086] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:45:42,087] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:45:42,087] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7ffaccd8cb10>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 05:00:00+00:00: scheduled__2021-12-31T05:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 6, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 6, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-31', 'prev_ds_nodash': '20211231', 'prev_execution_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T05:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T05:00:00+00:00', 'ts_nodash': '20211231T050000', 'ts_nodash_with_tz': '20211231T050000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T05:00:00+00:00', 'tsnodash_var': '20211231T050000', 'templates_dict': None}
[2022-01-05 18:45:42,087] {logging_mixin.py:109} INFO - Hello, Current Time:18:45:42 Execution time is 2021-12-31T05:00:00+00:00
[2022-01-05 18:45:42,124] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 18:45:42,145] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 18:45:46,288] {python.py:175} INFO - Done. Returned value was: None
[2022-01-05 18:45:46,307] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T050000, start_date=20220105T184541, end_date=20220105T184546
[2022-01-05 18:45:46,344] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-01-05 18:45:46,399] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-01-05 18:45:46,481] {dagrun.py:545} INFO - Marking run <DagRun load_dimensions @ 2021-12-31 05:00:00+00:00: scheduled__2021-12-31T05:00:00+00:00, externally triggered: False> successful
[2022-01-05 18:45:46,482] {dagrun.py:605} INFO - DagRun Finished: dag_id=load_dimensions, execution_date=2021-12-31 05:00:00+00:00, run_id=scheduled__2021-12-31T05:00:00+00:00, run_start_date=2022-01-05 18:45:38.836455+00:00, run_end_date=2022-01-05 18:45:46.481912+00:00, run_duration=7.645457, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2021-12-31 05:00:00+00:00, data_interval_end=2021-12-31 06:00:00+00:00, dag_hash=ea59270a290c9c2a836a4c05215d2937
[2022-01-05 18:46:44,703] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [queued]>
[2022-01-05 18:46:44,732] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [queued]>
[2022-01-05 18:46:44,732] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 18:46:44,732] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 18:46:44,732] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 18:46:44,780] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 05:00:00+00:00
[2022-01-05 18:46:44,787] {standard_task_runner.py:52} INFO - Started process 888 to run task
[2022-01-05 18:46:44,795] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T05:00:00+00:00', '--job-id', '415', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmpht1zlboy', '--error-file', '/tmp/tmp6v_7u2qy']
[2022-01-05 18:46:44,796] {standard_task_runner.py:77} INFO - Job 415: Subtask tweet_load
[2022-01-05 18:46:44,896] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [running]> on host e544fdb7c66e
[2022-01-05 18:46:44,974] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T05:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T05:00:00+00:00
[2022-01-05 18:46:44,976] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:46:44,976] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:46:44,976] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:46:44,976] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:46:44,977] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:46:44,977] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:46:44,977] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:46:44,977] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:46:44,977] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:46:44,977] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:46:44,977] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:46:44,977] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:46:44,978] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7ffaccd8cb10>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 05:00:00+00:00: scheduled__2021-12-31T05:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 6, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 6, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': DateTime(2021, 12, 31, 2, 0, 0, tzinfo=Timezone('UTC')), 'prev_data_interval_end_success': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'prev_ds': '2021-12-31', 'prev_ds_nodash': '20211231', 'prev_execution_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': DateTime(2021, 12, 31, 2, 0, 0, tzinfo=Timezone('UTC')), 'prev_start_date_success': DateTime(2022, 1, 5, 18, 46, 38, 770355, tzinfo=Timezone('UTC')), 'run_id': 'scheduled__2021-12-31T05:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T05:00:00+00:00', 'ts_nodash': '20211231T050000', 'ts_nodash_with_tz': '20211231T050000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T05:00:00+00:00', 'tsnodash_var': '20211231T050000', 'templates_dict': None}
[2022-01-05 18:46:44,978] {logging_mixin.py:109} INFO - Hello, Current Time:18:46:44 Execution time is 2021-12-31T05:00:00+00:00
[2022-01-05 18:46:44,997] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 18:46:45,007] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 18:46:47,746] {python.py:175} INFO - Done. Returned value was: None
[2022-01-05 18:46:47,757] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T050000, start_date=20220105T184644, end_date=20220105T184647
[2022-01-05 18:46:47,787] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-01-05 18:46:47,815] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-01-05 19:23:56,898] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [queued]>
[2022-01-05 19:23:56,912] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [queued]>
[2022-01-05 19:23:56,912] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 19:23:56,912] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 19:23:56,912] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 19:23:56,929] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 05:00:00+00:00
[2022-01-05 19:23:56,935] {standard_task_runner.py:52} INFO - Started process 2685 to run task
[2022-01-05 19:23:56,944] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T05:00:00+00:00', '--job-id', '454', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmpb5uytv2l', '--error-file', '/tmp/tmptkc_vmc6']
[2022-01-05 19:23:56,945] {standard_task_runner.py:77} INFO - Job 454: Subtask tweet_load
[2022-01-05 19:23:57,023] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [running]> on host e544fdb7c66e
[2022-01-05 19:23:57,087] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T05:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T05:00:00+00:00
[2022-01-05 19:23:57,089] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:23:57,089] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:23:57,089] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:23:57,089] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:23:57,089] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:23:57,090] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:23:57,090] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:23:57,090] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:23:57,090] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:23:57,090] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:23:57,090] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:23:57,090] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:23:57,090] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7ffaccd8cb10>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 05:00:00+00:00: scheduled__2021-12-31T05:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 6, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 6, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-31', 'prev_ds_nodash': '20211231', 'prev_execution_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T05:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T05:00:00+00:00', 'ts_nodash': '20211231T050000', 'ts_nodash_with_tz': '20211231T050000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T05:00:00+00:00', 'tsnodash_var': '20211231T050000', 'templates_dict': None}
[2022-01-05 19:23:57,091] {logging_mixin.py:109} INFO - Hello, Current Time:19:23:57 Execution time is 2021-12-31T05:00:00+00:00
[2022-01-05 19:23:57,109] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 19:23:57,119] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 19:24:00,295] {python.py:175} INFO - Done. Returned value was: None
[2022-01-05 19:24:00,304] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T050000, start_date=20220105T192356, end_date=20220105T192400
[2022-01-05 19:24:00,327] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-01-05 19:24:00,352] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-01-05 19:28:24,278] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [queued]>
[2022-01-05 19:28:24,294] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [queued]>
[2022-01-05 19:28:24,294] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 19:28:24,294] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 19:28:24,294] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 19:28:24,309] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 05:00:00+00:00
[2022-01-05 19:28:24,315] {standard_task_runner.py:52} INFO - Started process 2939 to run task
[2022-01-05 19:28:24,318] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T05:00:00+00:00', '--job-id', '473', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmpw76fwkhs', '--error-file', '/tmp/tmpcux1b_xa']
[2022-01-05 19:28:24,319] {standard_task_runner.py:77} INFO - Job 473: Subtask tweet_load
[2022-01-05 19:28:24,417] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [running]> on host e544fdb7c66e
[2022-01-05 19:28:24,560] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T05:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T05:00:00+00:00
[2022-01-05 19:28:24,562] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:28:24,562] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:28:24,563] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:28:24,563] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:28:24,567] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:28:24,567] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:28:24,568] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:28:24,568] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:28:24,569] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:28:24,569] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:28:24,570] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:28:24,570] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:28:24,571] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7ffaccd8cb10>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 05:00:00+00:00: scheduled__2021-12-31T05:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 6, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 6, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': DateTime(2021, 12, 31, 0, 0, 0, tzinfo=Timezone('UTC')), 'prev_data_interval_end_success': DateTime(2021, 12, 31, 1, 0, 0, tzinfo=Timezone('UTC')), 'prev_ds': '2021-12-31', 'prev_ds_nodash': '20211231', 'prev_execution_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': DateTime(2021, 12, 31, 0, 0, 0, tzinfo=Timezone('UTC')), 'prev_start_date_success': DateTime(2022, 1, 5, 19, 28, 20, 55248, tzinfo=Timezone('UTC')), 'run_id': 'scheduled__2021-12-31T05:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T05:00:00+00:00', 'ts_nodash': '20211231T050000', 'ts_nodash_with_tz': '20211231T050000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T05:00:00+00:00', 'tsnodash_var': '20211231T050000', 'templates_dict': None}
[2022-01-05 19:28:24,572] {logging_mixin.py:109} INFO - Hello, Current Time:19:28:24 Execution time is 2021-12-31T05:00:00+00:00
[2022-01-05 19:28:24,629] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 19:28:24,654] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 19:28:28,073] {python.py:175} INFO - Done. Returned value was: None
[2022-01-05 19:28:28,090] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T050000, start_date=20220105T192824, end_date=20220105T192828
[2022-01-05 19:28:28,115] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-01-05 19:28:28,144] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-01-05 19:29:20,873] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [queued]>
[2022-01-05 19:29:20,883] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [queued]>
[2022-01-05 19:29:20,883] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 19:29:20,883] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 19:29:20,883] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 19:29:20,894] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 05:00:00+00:00
[2022-01-05 19:29:20,899] {standard_task_runner.py:52} INFO - Started process 3035 to run task
[2022-01-05 19:29:20,902] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T05:00:00+00:00', '--job-id', '493', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmpsdwyg74s', '--error-file', '/tmp/tmp92h8e0ab']
[2022-01-05 19:29:20,903] {standard_task_runner.py:77} INFO - Job 493: Subtask tweet_load
[2022-01-05 19:29:20,944] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [running]> on host e544fdb7c66e
[2022-01-05 19:29:20,982] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T05:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T05:00:00+00:00
[2022-01-05 19:29:20,983] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:29:20,983] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:29:20,983] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:29:20,983] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:29:20,983] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:29:20,983] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:29:20,983] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:29:20,984] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:29:20,984] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:29:20,984] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:29:20,984] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:29:20,984] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:29:20,984] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7ffaccd8cb10>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 05:00:00+00:00: scheduled__2021-12-31T05:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 6, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 6, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-31', 'prev_ds_nodash': '20211231', 'prev_execution_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T05:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T05:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T05:00:00+00:00', 'ts_nodash': '20211231T050000', 'ts_nodash_with_tz': '20211231T050000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T05:00:00+00:00', 'tsnodash_var': '20211231T050000', 'templates_dict': None}
[2022-01-05 19:29:20,984] {logging_mixin.py:109} INFO - Hello, Current Time:19:29:20 Execution time is 2021-12-31T05:00:00+00:00
[2022-01-05 19:29:20,994] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 19:29:21,000] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 19:29:25,470] {python.py:175} INFO - Done. Returned value was: None
[2022-01-05 19:29:25,488] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T050000, start_date=20220105T192920, end_date=20220105T192925
[2022-01-05 19:29:25,531] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-01-05 19:29:25,570] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
