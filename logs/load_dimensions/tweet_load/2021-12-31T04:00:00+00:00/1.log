[2022-01-03 04:04:46,558] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [queued]>
[2022-01-03 04:04:46,574] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [queued]>
[2022-01-03 04:04:46,574] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-03 04:04:46,575] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-03 04:04:46,575] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-03 04:04:46,593] {taskinstance.py:1259} INFO - Executing <Task(PostgresOperator): tweet_load> on 2021-12-31 04:00:00+00:00
[2022-01-03 04:04:46,602] {standard_task_runner.py:52} INFO - Started process 798 to run task
[2022-01-03 04:04:46,607] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T04:00:00+00:00', '--job-id', '20', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmpd25hebf9', '--error-file', '/tmp/tmp696may5a']
[2022-01-03 04:04:46,607] {standard_task_runner.py:77} INFO - Job 20: Subtask tweet_load
[2022-01-03 04:04:46,662] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [running]> on host 2b1d65872a35
[2022-01-03 04:04:46,701] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T04:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T04:00:00+00:00
[2022-01-03 04:04:46,708] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: dev, Login: awsuser, Password: ***, extra: {}
[2022-01-03 04:06:57,519] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/postgres/operators/postgres.py", line 69, in execute
    self.hook.run(self.sql, self.autocommit, parameters=self.parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/hooks/dbapi.py", line 198, in run
    with closing(self.get_conn()) as conn:
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/postgres/hooks/postgres.py", line 115, in get_conn
    self.conn = psycopg2.connect(**conn_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com" (172.31.45.95), port 5439 failed: Connection timed out
	Is the server running on that host and accepting TCP/IP connections?

[2022-01-03 04:06:57,537] {taskinstance.py:1277} INFO - Marking task as FAILED. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T040000, start_date=20220103T040446, end_date=20220103T040657
[2022-01-03 04:06:57,561] {standard_task_runner.py:92} ERROR - Failed to execute job 20 for task tweet_load
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/postgres/operators/postgres.py", line 69, in execute
    self.hook.run(self.sql, self.autocommit, parameters=self.parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/hooks/dbapi.py", line 198, in run
    with closing(self.get_conn()) as conn:
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/postgres/hooks/postgres.py", line 115, in get_conn
    self.conn = psycopg2.connect(**conn_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com" (172.31.45.95), port 5439 failed: Connection timed out
	Is the server running on that host and accepting TCP/IP connections?

[2022-01-03 04:06:57,601] {local_task_job.py:154} INFO - Task exited with return code 1
[2022-01-03 04:06:57,647] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-01-05 05:18:33,706] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [queued]>
[2022-01-05 05:18:33,727] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [queued]>
[2022-01-05 05:18:33,728] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 05:18:33,730] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 05:18:33,730] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 05:18:33,769] {taskinstance.py:1259} INFO - Executing <Task(PostgresOperator): tweet_load> on 2021-12-31 04:00:00+00:00
[2022-01-05 05:18:33,775] {standard_task_runner.py:52} INFO - Started process 2950 to run task
[2022-01-05 05:18:33,779] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T04:00:00+00:00', '--job-id', '42', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmpuzdv6sgc', '--error-file', '/tmp/tmp0b0j2fd1']
[2022-01-05 05:18:33,782] {standard_task_runner.py:77} INFO - Job 42: Subtask tweet_load
[2022-01-05 05:18:33,925] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [running]> on host 2b1d65872a35
[2022-01-05 05:18:34,051] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T04:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T04:00:00+00:00
[2022-01-05 05:18:34,076] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 05:18:34,527] {dbapi.py:225} INFO - Running statement: select * test, parameters: None
[2022-01-05 05:18:34,652] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/postgres/operators/postgres.py", line 69, in execute
    self.hook.run(self.sql, self.autocommit, parameters=self.parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/hooks/dbapi.py", line 205, in run
    self._run_command(cur, sql_statement, parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/hooks/dbapi.py", line 229, in _run_command
    cur.execute(sql_statement)
psycopg2.errors.SyntaxError: syntax error at or near "test"
LINE 1: select * test
                 ^

[2022-01-05 05:18:34,688] {taskinstance.py:1277} INFO - Marking task as FAILED. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T040000, start_date=20220105T051833, end_date=20220105T051834
[2022-01-05 05:18:34,720] {standard_task_runner.py:92} ERROR - Failed to execute job 42 for task tweet_load
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/postgres/operators/postgres.py", line 69, in execute
    self.hook.run(self.sql, self.autocommit, parameters=self.parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/hooks/dbapi.py", line 205, in run
    self._run_command(cur, sql_statement, parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/hooks/dbapi.py", line 229, in _run_command
    cur.execute(sql_statement)
psycopg2.errors.SyntaxError: syntax error at or near "test"
LINE 1: select * test
                 ^

[2022-01-05 05:18:34,734] {local_task_job.py:154} INFO - Task exited with return code 1
[2022-01-05 05:18:34,902] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-01-05 05:23:15,989] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [queued]>
[2022-01-05 05:23:16,007] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [queued]>
[2022-01-05 05:23:16,007] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 05:23:16,008] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 05:23:16,008] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 05:23:16,042] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 04:00:00+00:00
[2022-01-05 05:23:16,057] {standard_task_runner.py:52} INFO - Started process 3248 to run task
[2022-01-05 05:23:16,066] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T04:00:00+00:00', '--job-id', '75', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmpaxauyt99', '--error-file', '/tmp/tmpiz_sb59a']
[2022-01-05 05:23:16,067] {standard_task_runner.py:77} INFO - Job 75: Subtask tweet_load
[2022-01-05 05:23:16,283] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [running]> on host 2b1d65872a35
[2022-01-05 05:23:16,447] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T04:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T04:00:00+00:00
[2022-01-05 05:23:16,449] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:23:16,450] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:23:16,450] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:23:16,450] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:23:16,450] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:23:16,451] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:23:16,451] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:23:16,451] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:23:16,451] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:23:16,451] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:23:16,451] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:23:16,451] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:23:16,458] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7f88b8fac810>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 04:00:00+00:00: scheduled__2021-12-31T04:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-31', 'prev_ds_nodash': '20211231', 'prev_execution_date': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T04:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T04:00:00+00:00', 'ts_nodash': '20211231T040000', 'ts_nodash_with_tz': '20211231T040000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T04:00:00+00:00', 'tsnodash_var': '20211231T040000', 'templates_dict': None}
[2022-01-05 05:23:16,458] {logging_mixin.py:109} INFO - Hello, Current Time:05:23:16 Execution time is 2021-12-31T04:00:00+00:00
[2022-01-05 05:23:16,498] {logging_mixin.py:109} INFO -    Unnamed: 0  ...       location
0           0  ...            NaN
1           1  ...            NaN
2           2  ...            NaN
3           3  ...      UofGuelph
4           4  ...            NaN
5           5  ...  Westbrook, ME
6           6  ...            NaN
7           7  ...            NaN
8           8  ...            NaN
9           9  ...   General Roca

[10 rows x 6 columns]
[2022-01-05 05:23:16,522] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 05:23:16,539] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 05:23:17,089] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2336, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 364, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 778, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 495, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 140, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 137, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 309, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 440, in __init__
    self.__connect(first_connect_check=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 656, in __connect
    connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/strategies.py", line 114, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 508, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com" (3.132.179.48), port 5439 failed: FATAL:  password authentication failed for user "awsuser"
connection to server at "tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com" (3.132.179.48), port 5439 failed: FATAL:  password authentication failed for user "awsuser"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 139, in load_tweets
    df.to_sql('test', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1758, in to_sql
    dtype=dtype,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1650, in prep_table
    table.create()
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 856, in create
    if self.exists():
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 840, in exists
    return self.pd_sql.has_table(self.name, self.schema)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1787, in has_table
    self.connectable.dialect.has_table, name, schema or self.meta.schema
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2211, in run_callable
    with self._contextual_connect() as conn:
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2302, in _contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2340, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1584, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2336, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 364, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 778, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 495, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 140, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 137, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 309, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 440, in __init__
    self.__connect(first_connect_check=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 656, in __connect
    connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/strategies.py", line 114, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 508, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com" (3.132.179.48), port 5439 failed: FATAL:  password authentication failed for user "awsuser"
connection to server at "tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com" (3.132.179.48), port 5439 failed: FATAL:  password authentication failed for user "awsuser"

(Background on this error at: http://sqlalche.me/e/13/e3q8)
[2022-01-05 05:23:17,145] {taskinstance.py:1277} INFO - Marking task as FAILED. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T040000, start_date=20220105T052315, end_date=20220105T052317
[2022-01-05 05:23:17,166] {standard_task_runner.py:92} ERROR - Failed to execute job 75 for task tweet_load
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2336, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 364, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 778, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 495, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 140, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 137, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 309, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 440, in __init__
    self.__connect(first_connect_check=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 656, in __connect
    connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/strategies.py", line 114, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 508, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com" (3.132.179.48), port 5439 failed: FATAL:  password authentication failed for user "awsuser"
connection to server at "tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com" (3.132.179.48), port 5439 failed: FATAL:  password authentication failed for user "awsuser"


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 139, in load_tweets
    df.to_sql('test', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1758, in to_sql
    dtype=dtype,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1650, in prep_table
    table.create()
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 856, in create
    if self.exists():
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 840, in exists
    return self.pd_sql.has_table(self.name, self.schema)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1787, in has_table
    self.connectable.dialect.has_table, name, schema or self.meta.schema
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2211, in run_callable
    with self._contextual_connect() as conn:
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2302, in _contextual_connect
    self._wrap_pool_connect(self.pool.connect, None),
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2340, in _wrap_pool_connect
    e, dialect, self
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1584, in _handle_dbapi_exception_noconnection
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 2336, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 364, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 778, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 495, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 140, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/impl.py", line 137, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 309, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 440, in __init__
    self.__connect(first_connect_check=True)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 661, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    with_traceback=exc_tb,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/pool/base.py", line 656, in __connect
    connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/strategies.py", line 114, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/default.py", line 508, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.7/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com" (3.132.179.48), port 5439 failed: FATAL:  password authentication failed for user "awsuser"
connection to server at "tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com" (3.132.179.48), port 5439 failed: FATAL:  password authentication failed for user "awsuser"

(Background on this error at: http://sqlalche.me/e/13/e3q8)
[2022-01-05 05:23:17,179] {local_task_job.py:154} INFO - Task exited with return code 1
[2022-01-05 05:23:17,232] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-01-05 05:35:10,847] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [queued]>
[2022-01-05 05:35:10,873] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [queued]>
[2022-01-05 05:35:10,874] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 05:35:10,874] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 05:35:10,875] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 05:35:10,904] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 04:00:00+00:00
[2022-01-05 05:35:10,920] {standard_task_runner.py:52} INFO - Started process 223 to run task
[2022-01-05 05:35:10,931] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T04:00:00+00:00', '--job-id', '107', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmpxdqofruu', '--error-file', '/tmp/tmpqetpake9']
[2022-01-05 05:35:10,933] {standard_task_runner.py:77} INFO - Job 107: Subtask tweet_load
[2022-01-05 05:35:11,078] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [running]> on host 2b1d65872a35
[2022-01-05 05:35:11,186] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T04:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T04:00:00+00:00
[2022-01-05 05:35:11,188] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:35:11,188] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:35:11,188] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:35:11,188] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:35:11,189] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:35:11,189] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:35:11,189] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:35:11,189] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:35:11,189] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:35:11,189] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:35:11,189] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:35:11,190] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:35:11,190] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7fd8b40b1950>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 04:00:00+00:00: scheduled__2021-12-31T04:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-31', 'prev_ds_nodash': '20211231', 'prev_execution_date': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T04:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T04:00:00+00:00', 'ts_nodash': '20211231T040000', 'ts_nodash_with_tz': '20211231T040000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T04:00:00+00:00', 'tsnodash_var': '20211231T040000', 'templates_dict': None}
[2022-01-05 05:35:11,190] {logging_mixin.py:109} INFO - Hello, Current Time:05:35:11 Execution time is 2021-12-31T04:00:00+00:00
[2022-01-05 05:35:11,226] {logging_mixin.py:109} INFO -    Unnamed: 0  ...       location
0           0  ...            NaN
1           1  ...            NaN
2           2  ...            NaN
3           3  ...      UofGuelph
4           4  ...            NaN
5           5  ...  Westbrook, ME
6           6  ...            NaN
7           7  ...            NaN
8           8  ...            NaN
9           9  ...   General Roca

[10 rows x 6 columns]
[2022-01-05 05:35:11,245] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 05:35:11,259] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 05:35:12,909] {python.py:175} INFO - Done. Returned value was: None
[2022-01-05 05:35:12,927] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T040000, start_date=20220105T053510, end_date=20220105T053512
[2022-01-05 05:35:12,970] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-01-05 05:35:13,021] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-01-05 05:49:55,035] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [queued]>
[2022-01-05 05:49:55,082] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [queued]>
[2022-01-05 05:49:55,082] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 05:49:55,082] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 05:49:55,082] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 05:49:55,121] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 04:00:00+00:00
[2022-01-05 05:49:55,131] {standard_task_runner.py:52} INFO - Started process 923 to run task
[2022-01-05 05:49:55,151] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T04:00:00+00:00', '--job-id', '124', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmpzl_w1rsh', '--error-file', '/tmp/tmpd8rbcjzw']
[2022-01-05 05:49:55,153] {standard_task_runner.py:77} INFO - Job 124: Subtask tweet_load
[2022-01-05 05:49:55,332] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [running]> on host 2b1d65872a35
[2022-01-05 05:49:55,485] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T04:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T04:00:00+00:00
[2022-01-05 05:49:55,486] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:49:55,487] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:49:55,487] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:49:55,487] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:49:55,487] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:49:55,487] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:49:55,487] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:49:55,488] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:49:55,490] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:49:55,491] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:49:55,491] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:49:55,491] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:49:55,492] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7fd8b40b1950>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 04:00:00+00:00: scheduled__2021-12-31T04:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-31', 'prev_ds_nodash': '20211231', 'prev_execution_date': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T04:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T04:00:00+00:00', 'ts_nodash': '20211231T040000', 'ts_nodash_with_tz': '20211231T040000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T04:00:00+00:00', 'tsnodash_var': '20211231T040000', 'templates_dict': None}
[2022-01-05 05:49:55,492] {logging_mixin.py:109} INFO - Hello, Current Time:05:49:55 Execution time is 2021-12-31T04:00:00+00:00
[2022-01-05 05:49:55,543] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 05:49:55,569] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 05:49:57,054] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
psycopg2.errors.UndefinedColumn: column "unnamed: 0" of relation "tweet" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 133, in load_tweets
    tweet_data.to_sql('tweet', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1770, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1350, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1340, in insert_records
    table.insert(chunksize=chunksize, method=method)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 967, in insert
    exec_insert(conn, keys, chunk_iter)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 882, in _execute_insert
    conn.execute(self.table.insert(), data)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "unnamed: 0" of relation "tweet" does not exist

[SQL: INSERT INTO tweet ("Unnamed: 0", author_id, id, created_at, original_text, location) VALUES (%(Unnamed: 0)s, %(author_id)s, %(id)s, %(created_at)s, %(original_text)s, %(location)s)]
[parameters: ({'Unnamed: 0': 0, 'author_id': 1164924322890297344, 'id': 1476767568446869504, 'created_at': '2021-12-31T04:09:59.000Z', 'original_text': "STOP FUCKING GOING TO STARBUCKS TO GET A MEDICINE BALL BC YOU HAVE A SORE THROAT IF YOU KNOW YOU HAVE COVID OR EVEN IF YOU'RE NOT SURE, AND YES IT MATTERS IF YOU GO THROUGH THE DRIVE-THRU", 'location': 'Georgetown, TX'}, {'Unnamed: 0': 1, 'author_id': 797483317364826112, 'id': 1476767568404705282, 'created_at': '2021-12-31T04:09:59.000Z', 'original_text': 'Free rapid COVID testing at 380 S 17th St. Richmond CA. No appt needed, stay safe ya’ll!', 'location': 'bay area'}, {'Unnamed: 0': 2, 'author_id': 1454583445657686025, 'id': 1476767568329388048, 'created_at': '2021-12-31T04:09:59.000Z', 'original_text': 'So I’m the exiting chief of surgery at my hospital. My two years of stupid meetings, babysitting disruptive surgeons, managing Covid staffing issues, etc has culminated in receiving a $50 gift card. That’s how out of touch hospitals are. SMH. #MedTwitter', 'location': None}, {'Unnamed: 0': 3, 'author_id': 773485929969414148, 'id': 1476767568203431938, 'created_at': '2021-12-31T04:09:59.000Z', 'original_text': 'Quebec imposes COVID-19 curfew; Ontario limits eligibility for PCR tests amid Omicron surge - The Globe and Mail   https://t.co/bWEvGrc5Zg', 'location': 'Hyderabad, India'}, {'Unnamed: 0': 4, 'author_id': 1452284405502840837, 'id': 1476767567813308420, 'created_at': '2021-12-31T04:09:59.000Z', 'original_text': '[News]\n\n케플러 샤오팅·마시로 코로나 완치..1월3일 데뷔 프로모션 재개\n\nAs members fully recovered from COVID-19, Kep1er will continue promotion for its January 3rd debut\n\n📎 https://t.co/TX8szPF3EP\n\n#Kep1er #케플러', 'location': 'she/her༄stan ot9!'}, {'Unnamed: 0': 5, 'author_id': 1393949294965657603, 'id': 1476767567800795136, 'created_at': '2021-12-31T04:09:59.000Z', 'original_text': '@yuyuniwerse We are stolen two years by epidemic', 'location': 'she/her'}, {'Unnamed: 0': 6, 'author_id': 1439581822871015432, 'id': 1476767567771541505, 'created_at': '2021-12-31T04:09:59.000Z', 'original_text': 'NEW - Dr. Fauci: "Important thing: Many of the children are hospitalized with Covid as opposed to because of Covid."\n\nhttps://t.co/g7NzfpKTsQ', 'location': 'Texas, USA'}, {'Unnamed: 0': 7, 'author_id': 184331718, 'id': 1476767567746269187, 'created_at': '2021-12-31T04:09:59.000Z', 'original_text': 'No todo malestar es #Covid, 37 no es fiebre. Siguen existiendo las sinusitis alérgicas, las otitis y demás itis. Si tienen la suerte q tuve de buenos médicos q vieron más allá, todo es más fácil. Pataleen , no se queden con dudas... Nada... Eso.', 'location': 'Ciudad Autónoma de Buenos Aire'}, {'Unnamed: 0': 8, 'author_id': 2166890976, 'id': 1476767567159169028, 'created_at': '2021-12-31T04:09:59.000Z', 'original_text': 'Participants who received a booster at least 5 months after a second dose of Pfizer vaccine had 90% lower mortality due to Covid-19 than participants who did not receive a booster #covid19 #booster #mortality @NEJM https://t.co/uaBi6CjLJL', 'location': 'Helsinki, Finland'}, {'Unnamed: 0': 9, 'author_id': 280267313, 'id': 1476767566941073409, 'created_at': '2021-12-31T04:09:59.000Z', 'original_text': 'Should Tucker and Fox News be sued over COVID misinformation?', 'location': 'cape cod, ma'})]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-01-05 05:49:57,084] {taskinstance.py:1277} INFO - Marking task as FAILED. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T040000, start_date=20220105T054955, end_date=20220105T054957
[2022-01-05 05:49:57,130] {standard_task_runner.py:92} ERROR - Failed to execute job 124 for task tweet_load
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
psycopg2.errors.UndefinedColumn: column "unnamed: 0" of relation "tweet" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 133, in load_tweets
    tweet_data.to_sql('tweet', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1770, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1350, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1340, in insert_records
    table.insert(chunksize=chunksize, method=method)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 967, in insert
    exec_insert(conn, keys, chunk_iter)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 882, in _execute_insert
    conn.execute(self.table.insert(), data)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "unnamed: 0" of relation "tweet" does not exist

[SQL: INSERT INTO tweet ("Unnamed: 0", author_id, id, created_at, original_text, location) VALUES (%(Unnamed: 0)s, %(author_id)s, %(id)s, %(created_at)s, %(original_text)s, %(location)s)]
[parameters: ({'Unnamed: 0': 0, 'author_id': 1164924322890297344, 'id': 1476767568446869504, 'created_at': '2021-12-31T04:09:59.000Z', 'original_text': "STOP FUCKING GOING TO STARBUCKS TO GET A MEDICINE BALL BC YOU HAVE A SORE THROAT IF YOU KNOW YOU HAVE COVID OR EVEN IF YOU'RE NOT SURE, AND YES IT MATTERS IF YOU GO THROUGH THE DRIVE-THRU", 'location': 'Georgetown, TX'}, {'Unnamed: 0': 1, 'author_id': 797483317364826112, 'id': 1476767568404705282, 'created_at': '2021-12-31T04:09:59.000Z', 'original_text': 'Free rapid COVID testing at 380 S 17th St. Richmond CA. No appt needed, stay safe ya’ll!', 'location': 'bay area'}, {'Unnamed: 0': 2, 'author_id': 1454583445657686025, 'id': 1476767568329388048, 'created_at': '2021-12-31T04:09:59.000Z', 'original_text': 'So I’m the exiting chief of surgery at my hospital. My two years of stupid meetings, babysitting disruptive surgeons, managing Covid staffing issues, etc has culminated in receiving a $50 gift card. That’s how out of touch hospitals are. SMH. #MedTwitter', 'location': None}, {'Unnamed: 0': 3, 'author_id': 773485929969414148, 'id': 1476767568203431938, 'created_at': '2021-12-31T04:09:59.000Z', 'original_text': 'Quebec imposes COVID-19 curfew; Ontario limits eligibility for PCR tests amid Omicron surge - The Globe and Mail   https://t.co/bWEvGrc5Zg', 'location': 'Hyderabad, India'}, {'Unnamed: 0': 4, 'author_id': 1452284405502840837, 'id': 1476767567813308420, 'created_at': '2021-12-31T04:09:59.000Z', 'original_text': '[News]\n\n케플러 샤오팅·마시로 코로나 완치..1월3일 데뷔 프로모션 재개\n\nAs members fully recovered from COVID-19, Kep1er will continue promotion for its January 3rd debut\n\n📎 https://t.co/TX8szPF3EP\n\n#Kep1er #케플러', 'location': 'she/her༄stan ot9!'}, {'Unnamed: 0': 5, 'author_id': 1393949294965657603, 'id': 1476767567800795136, 'created_at': '2021-12-31T04:09:59.000Z', 'original_text': '@yuyuniwerse We are stolen two years by epidemic', 'location': 'she/her'}, {'Unnamed: 0': 6, 'author_id': 1439581822871015432, 'id': 1476767567771541505, 'created_at': '2021-12-31T04:09:59.000Z', 'original_text': 'NEW - Dr. Fauci: "Important thing: Many of the children are hospitalized with Covid as opposed to because of Covid."\n\nhttps://t.co/g7NzfpKTsQ', 'location': 'Texas, USA'}, {'Unnamed: 0': 7, 'author_id': 184331718, 'id': 1476767567746269187, 'created_at': '2021-12-31T04:09:59.000Z', 'original_text': 'No todo malestar es #Covid, 37 no es fiebre. Siguen existiendo las sinusitis alérgicas, las otitis y demás itis. Si tienen la suerte q tuve de buenos médicos q vieron más allá, todo es más fácil. Pataleen , no se queden con dudas... Nada... Eso.', 'location': 'Ciudad Autónoma de Buenos Aire'}, {'Unnamed: 0': 8, 'author_id': 2166890976, 'id': 1476767567159169028, 'created_at': '2021-12-31T04:09:59.000Z', 'original_text': 'Participants who received a booster at least 5 months after a second dose of Pfizer vaccine had 90% lower mortality due to Covid-19 than participants who did not receive a booster #covid19 #booster #mortality @NEJM https://t.co/uaBi6CjLJL', 'location': 'Helsinki, Finland'}, {'Unnamed: 0': 9, 'author_id': 280267313, 'id': 1476767566941073409, 'created_at': '2021-12-31T04:09:59.000Z', 'original_text': 'Should Tucker and Fox News be sued over COVID misinformation?', 'location': 'cape cod, ma'})]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-01-05 05:49:57,153] {local_task_job.py:154} INFO - Task exited with return code 1
[2022-01-05 05:49:57,335] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-01-05 05:51:30,389] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [queued]>
[2022-01-05 05:51:30,403] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [queued]>
[2022-01-05 05:51:30,403] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 05:51:30,404] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 05:51:30,404] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 05:51:30,419] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 04:00:00+00:00
[2022-01-05 05:51:30,425] {standard_task_runner.py:52} INFO - Started process 1056 to run task
[2022-01-05 05:51:30,429] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T04:00:00+00:00', '--job-id', '146', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmp7tqe6m_c', '--error-file', '/tmp/tmpacpvte6v']
[2022-01-05 05:51:30,430] {standard_task_runner.py:77} INFO - Job 146: Subtask tweet_load
[2022-01-05 05:51:30,484] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [running]> on host 2b1d65872a35
[2022-01-05 05:51:30,540] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T04:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T04:00:00+00:00
[2022-01-05 05:51:30,542] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:51:30,542] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:51:30,542] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:51:30,542] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:51:30,542] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:51:30,542] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:51:30,542] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:51:30,542] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:51:30,542] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:51:30,543] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:51:30,543] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:51:30,543] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 05:51:30,543] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7fd8b40b1950>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 04:00:00+00:00: scheduled__2021-12-31T04:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-31', 'prev_ds_nodash': '20211231', 'prev_execution_date': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T04:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T04:00:00+00:00', 'ts_nodash': '20211231T040000', 'ts_nodash_with_tz': '20211231T040000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T04:00:00+00:00', 'tsnodash_var': '20211231T040000', 'templates_dict': None}
[2022-01-05 05:51:30,543] {logging_mixin.py:109} INFO - Hello, Current Time:05:51:30 Execution time is 2021-12-31T04:00:00+00:00
[2022-01-05 05:51:30,558] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 05:51:30,570] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 05:51:31,908] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
psycopg2.errors.UndefinedColumn: column "original_text" of relation "tweet" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 133, in load_tweets
    tweet_data.to_sql('tweet', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1770, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1350, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1340, in insert_records
    table.insert(chunksize=chunksize, method=method)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 967, in insert
    exec_insert(conn, keys, chunk_iter)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 882, in _execute_insert
    conn.execute(self.table.insert(), data)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "original_text" of relation "tweet" does not exist

[SQL: INSERT INTO tweet (id, created_at, author_id, original_text, location) VALUES (%(id)s, %(created_at)s, %(author_id)s, %(original_text)s, %(location)s)]
[parameters: ({'id': 1476767568446869504, 'created_at': '2021-12-31T04:09:59.000Z', 'author_id': 1164924322890297344, 'original_text': "STOP FUCKING GOING TO STARBUCKS TO GET A MEDICINE BALL BC YOU HAVE A SORE THROAT IF YOU KNOW YOU HAVE COVID OR EVEN IF YOU'RE NOT SURE, AND YES IT MATTERS IF YOU GO THROUGH THE DRIVE-THRU", 'location': 'Georgetown, TX'}, {'id': 1476767568404705282, 'created_at': '2021-12-31T04:09:59.000Z', 'author_id': 797483317364826112, 'original_text': 'Free rapid COVID testing at 380 S 17th St. Richmond CA. No appt needed, stay safe ya’ll!', 'location': 'bay area'}, {'id': 1476767568329388048, 'created_at': '2021-12-31T04:09:59.000Z', 'author_id': 1454583445657686025, 'original_text': 'So I’m the exiting chief of surgery at my hospital. My two years of stupid meetings, babysitting disruptive surgeons, managing Covid staffing issues, etc has culminated in receiving a $50 gift card. That’s how out of touch hospitals are. SMH. #MedTwitter', 'location': None}, {'id': 1476767568203431938, 'created_at': '2021-12-31T04:09:59.000Z', 'author_id': 773485929969414148, 'original_text': 'Quebec imposes COVID-19 curfew; Ontario limits eligibility for PCR tests amid Omicron surge - The Globe and Mail   https://t.co/bWEvGrc5Zg', 'location': 'Hyderabad, India'}, {'id': 1476767567813308420, 'created_at': '2021-12-31T04:09:59.000Z', 'author_id': 1452284405502840837, 'original_text': '[News]\n\n케플러 샤오팅·마시로 코로나 완치..1월3일 데뷔 프로모션 재개\n\nAs members fully recovered from COVID-19, Kep1er will continue promotion for its January 3rd debut\n\n📎 https://t.co/TX8szPF3EP\n\n#Kep1er #케플러', 'location': 'she/her༄stan ot9!'}, {'id': 1476767567800795136, 'created_at': '2021-12-31T04:09:59.000Z', 'author_id': 1393949294965657603, 'original_text': '@yuyuniwerse We are stolen two years by epidemic', 'location': 'she/her'}, {'id': 1476767567771541505, 'created_at': '2021-12-31T04:09:59.000Z', 'author_id': 1439581822871015432, 'original_text': 'NEW - Dr. Fauci: "Important thing: Many of the children are hospitalized with Covid as opposed to because of Covid."\n\nhttps://t.co/g7NzfpKTsQ', 'location': 'Texas, USA'}, {'id': 1476767567746269187, 'created_at': '2021-12-31T04:09:59.000Z', 'author_id': 184331718, 'original_text': 'No todo malestar es #Covid, 37 no es fiebre. Siguen existiendo las sinusitis alérgicas, las otitis y demás itis. Si tienen la suerte q tuve de buenos médicos q vieron más allá, todo es más fácil. Pataleen , no se queden con dudas... Nada... Eso.', 'location': 'Ciudad Autónoma de Buenos Aire'}, {'id': 1476767567159169028, 'created_at': '2021-12-31T04:09:59.000Z', 'author_id': 2166890976, 'original_text': 'Participants who received a booster at least 5 months after a second dose of Pfizer vaccine had 90% lower mortality due to Covid-19 than participants who did not receive a booster #covid19 #booster #mortality @NEJM https://t.co/uaBi6CjLJL', 'location': 'Helsinki, Finland'}, {'id': 1476767566941073409, 'created_at': '2021-12-31T04:09:59.000Z', 'author_id': 280267313, 'original_text': 'Should Tucker and Fox News be sued over COVID misinformation?', 'location': 'cape cod, ma'})]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-01-05 05:51:31,923] {taskinstance.py:1277} INFO - Marking task as FAILED. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T040000, start_date=20220105T055130, end_date=20220105T055131
[2022-01-05 05:51:31,935] {standard_task_runner.py:92} ERROR - Failed to execute job 146 for task tweet_load
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
psycopg2.errors.UndefinedColumn: column "original_text" of relation "tweet" does not exist


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 133, in load_tweets
    tweet_data.to_sql('tweet', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1770, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1350, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1340, in insert_records
    table.insert(chunksize=chunksize, method=method)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 967, in insert
    exec_insert(conn, keys, chunk_iter)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 882, in _execute_insert
    conn.execute(self.table.insert(), data)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
sqlalchemy.exc.ProgrammingError: (psycopg2.errors.UndefinedColumn) column "original_text" of relation "tweet" does not exist

[SQL: INSERT INTO tweet (id, created_at, author_id, original_text, location) VALUES (%(id)s, %(created_at)s, %(author_id)s, %(original_text)s, %(location)s)]
[parameters: ({'id': 1476767568446869504, 'created_at': '2021-12-31T04:09:59.000Z', 'author_id': 1164924322890297344, 'original_text': "STOP FUCKING GOING TO STARBUCKS TO GET A MEDICINE BALL BC YOU HAVE A SORE THROAT IF YOU KNOW YOU HAVE COVID OR EVEN IF YOU'RE NOT SURE, AND YES IT MATTERS IF YOU GO THROUGH THE DRIVE-THRU", 'location': 'Georgetown, TX'}, {'id': 1476767568404705282, 'created_at': '2021-12-31T04:09:59.000Z', 'author_id': 797483317364826112, 'original_text': 'Free rapid COVID testing at 380 S 17th St. Richmond CA. No appt needed, stay safe ya’ll!', 'location': 'bay area'}, {'id': 1476767568329388048, 'created_at': '2021-12-31T04:09:59.000Z', 'author_id': 1454583445657686025, 'original_text': 'So I’m the exiting chief of surgery at my hospital. My two years of stupid meetings, babysitting disruptive surgeons, managing Covid staffing issues, etc has culminated in receiving a $50 gift card. That’s how out of touch hospitals are. SMH. #MedTwitter', 'location': None}, {'id': 1476767568203431938, 'created_at': '2021-12-31T04:09:59.000Z', 'author_id': 773485929969414148, 'original_text': 'Quebec imposes COVID-19 curfew; Ontario limits eligibility for PCR tests amid Omicron surge - The Globe and Mail   https://t.co/bWEvGrc5Zg', 'location': 'Hyderabad, India'}, {'id': 1476767567813308420, 'created_at': '2021-12-31T04:09:59.000Z', 'author_id': 1452284405502840837, 'original_text': '[News]\n\n케플러 샤오팅·마시로 코로나 완치..1월3일 데뷔 프로모션 재개\n\nAs members fully recovered from COVID-19, Kep1er will continue promotion for its January 3rd debut\n\n📎 https://t.co/TX8szPF3EP\n\n#Kep1er #케플러', 'location': 'she/her༄stan ot9!'}, {'id': 1476767567800795136, 'created_at': '2021-12-31T04:09:59.000Z', 'author_id': 1393949294965657603, 'original_text': '@yuyuniwerse We are stolen two years by epidemic', 'location': 'she/her'}, {'id': 1476767567771541505, 'created_at': '2021-12-31T04:09:59.000Z', 'author_id': 1439581822871015432, 'original_text': 'NEW - Dr. Fauci: "Important thing: Many of the children are hospitalized with Covid as opposed to because of Covid."\n\nhttps://t.co/g7NzfpKTsQ', 'location': 'Texas, USA'}, {'id': 1476767567746269187, 'created_at': '2021-12-31T04:09:59.000Z', 'author_id': 184331718, 'original_text': 'No todo malestar es #Covid, 37 no es fiebre. Siguen existiendo las sinusitis alérgicas, las otitis y demás itis. Si tienen la suerte q tuve de buenos médicos q vieron más allá, todo es más fácil. Pataleen , no se queden con dudas... Nada... Eso.', 'location': 'Ciudad Autónoma de Buenos Aire'}, {'id': 1476767567159169028, 'created_at': '2021-12-31T04:09:59.000Z', 'author_id': 2166890976, 'original_text': 'Participants who received a booster at least 5 months after a second dose of Pfizer vaccine had 90% lower mortality due to Covid-19 than participants who did not receive a booster #covid19 #booster #mortality @NEJM https://t.co/uaBi6CjLJL', 'location': 'Helsinki, Finland'}, {'id': 1476767566941073409, 'created_at': '2021-12-31T04:09:59.000Z', 'author_id': 280267313, 'original_text': 'Should Tucker and Fox News be sued over COVID misinformation?', 'location': 'cape cod, ma'})]
(Background on this error at: http://sqlalche.me/e/13/f405)
[2022-01-05 05:51:31,966] {local_task_job.py:154} INFO - Task exited with return code 1
[2022-01-05 05:51:32,000] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-01-05 06:00:47,884] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [queued]>
[2022-01-05 06:00:47,897] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [queued]>
[2022-01-05 06:00:47,897] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 06:00:47,897] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 06:00:47,898] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 06:00:47,914] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 04:00:00+00:00
[2022-01-05 06:00:47,920] {standard_task_runner.py:52} INFO - Started process 1516 to run task
[2022-01-05 06:00:47,924] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T04:00:00+00:00', '--job-id', '164', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmpeug3nj3q', '--error-file', '/tmp/tmp3_my7gbt']
[2022-01-05 06:00:47,925] {standard_task_runner.py:77} INFO - Job 164: Subtask tweet_load
[2022-01-05 06:00:47,968] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [running]> on host 2b1d65872a35
[2022-01-05 06:00:48,011] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T04:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T04:00:00+00:00
[2022-01-05 06:00:48,013] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:00:48,013] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:00:48,013] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:00:48,013] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:00:48,013] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:00:48,013] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:00:48,013] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:00:48,014] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:00:48,014] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:00:48,014] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:00:48,014] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:00:48,014] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:00:48,014] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7fd8b40b1950>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 04:00:00+00:00: scheduled__2021-12-31T04:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-31', 'prev_ds_nodash': '20211231', 'prev_execution_date': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T04:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T04:00:00+00:00', 'ts_nodash': '20211231T040000', 'ts_nodash_with_tz': '20211231T040000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T04:00:00+00:00', 'tsnodash_var': '20211231T040000', 'templates_dict': None}
[2022-01-05 06:00:48,014] {logging_mixin.py:109} INFO - Hello, Current Time:06:00:48 Execution time is 2021-12-31T04:00:00+00:00
[2022-01-05 06:00:48,034] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 06:00:48,040] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 06:00:49,381] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
psycopg2.errors.NumericValueOutOfRange: numeric value "1164924322890297344" out of range for integer


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 133, in load_tweets
    tweet_data.to_sql('tweet', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1770, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1350, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1340, in insert_records
    table.insert(chunksize=chunksize, method=method)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 967, in insert
    exec_insert(conn, keys, chunk_iter)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 882, in _execute_insert
    conn.execute(self.table.insert(), data)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
sqlalchemy.exc.DataError: (psycopg2.errors.NumericValueOutOfRange) numeric value "1164924322890297344" out of range for integer

[SQL: INSERT INTO tweet (created_at, id, author_id, original_text, location) VALUES (%(created_at)s, %(id)s, %(author_id)s, %(original_text)s, %(location)s)]
[parameters: ({'created_at': '2021-12-31T04:09:59.000Z', 'id': 1476767568446869504, 'author_id': 1164924322890297344, 'original_text': "STOP FUCKING GOING TO STARBUCKS TO GET A MEDICINE BALL BC YOU HAVE A SORE THROAT IF YOU KNOW YOU HAVE COVID OR EVEN IF YOU'RE NOT SURE, AND YES IT MATTERS IF YOU GO THROUGH THE DRIVE-THRU", 'location': 'Georgetown, TX'}, {'created_at': '2021-12-31T04:09:59.000Z', 'id': 1476767568404705282, 'author_id': 797483317364826112, 'original_text': 'Free rapid COVID testing at 380 S 17th St. Richmond CA. No appt needed, stay safe ya’ll!', 'location': 'bay area'}, {'created_at': '2021-12-31T04:09:59.000Z', 'id': 1476767568329388048, 'author_id': 1454583445657686025, 'original_text': 'So I’m the exiting chief of surgery at my hospital. My two years of stupid meetings, babysitting disruptive surgeons, managing Covid staffing issues, etc has culminated in receiving a $50 gift card. That’s how out of touch hospitals are. SMH. #MedTwitter', 'location': None}, {'created_at': '2021-12-31T04:09:59.000Z', 'id': 1476767568203431938, 'author_id': 773485929969414148, 'original_text': 'Quebec imposes COVID-19 curfew; Ontario limits eligibility for PCR tests amid Omicron surge - The Globe and Mail   https://t.co/bWEvGrc5Zg', 'location': 'Hyderabad, India'}, {'created_at': '2021-12-31T04:09:59.000Z', 'id': 1476767567813308420, 'author_id': 1452284405502840837, 'original_text': '[News]\n\n케플러 샤오팅·마시로 코로나 완치..1월3일 데뷔 프로모션 재개\n\nAs members fully recovered from COVID-19, Kep1er will continue promotion for its January 3rd debut\n\n📎 https://t.co/TX8szPF3EP\n\n#Kep1er #케플러', 'location': 'she/her༄stan ot9!'}, {'created_at': '2021-12-31T04:09:59.000Z', 'id': 1476767567800795136, 'author_id': 1393949294965657603, 'original_text': '@yuyuniwerse We are stolen two years by epidemic', 'location': 'she/her'}, {'created_at': '2021-12-31T04:09:59.000Z', 'id': 1476767567771541505, 'author_id': 1439581822871015432, 'original_text': 'NEW - Dr. Fauci: "Important thing: Many of the children are hospitalized with Covid as opposed to because of Covid."\n\nhttps://t.co/g7NzfpKTsQ', 'location': 'Texas, USA'}, {'created_at': '2021-12-31T04:09:59.000Z', 'id': 1476767567746269187, 'author_id': 184331718, 'original_text': 'No todo malestar es #Covid, 37 no es fiebre. Siguen existiendo las sinusitis alérgicas, las otitis y demás itis. Si tienen la suerte q tuve de buenos médicos q vieron más allá, todo es más fácil. Pataleen , no se queden con dudas... Nada... Eso.', 'location': 'Ciudad Autónoma de Buenos Aire'}, {'created_at': '2021-12-31T04:09:59.000Z', 'id': 1476767567159169028, 'author_id': 2166890976, 'original_text': 'Participants who received a booster at least 5 months after a second dose of Pfizer vaccine had 90% lower mortality due to Covid-19 than participants who did not receive a booster #covid19 #booster #mortality @NEJM https://t.co/uaBi6CjLJL', 'location': 'Helsinki, Finland'}, {'created_at': '2021-12-31T04:09:59.000Z', 'id': 1476767566941073409, 'author_id': 280267313, 'original_text': 'Should Tucker and Fox News be sued over COVID misinformation?', 'location': 'cape cod, ma'})]
(Background on this error at: http://sqlalche.me/e/13/9h9h)
[2022-01-05 06:00:49,394] {taskinstance.py:1277} INFO - Marking task as FAILED. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T040000, start_date=20220105T060047, end_date=20220105T060049
[2022-01-05 06:00:49,405] {standard_task_runner.py:92} ERROR - Failed to execute job 164 for task tweet_load
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
psycopg2.errors.NumericValueOutOfRange: numeric value "1164924322890297344" out of range for integer


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 133, in load_tweets
    tweet_data.to_sql('tweet', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1770, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1350, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1340, in insert_records
    table.insert(chunksize=chunksize, method=method)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 967, in insert
    exec_insert(conn, keys, chunk_iter)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 882, in _execute_insert
    conn.execute(self.table.insert(), data)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
sqlalchemy.exc.DataError: (psycopg2.errors.NumericValueOutOfRange) numeric value "1164924322890297344" out of range for integer

[SQL: INSERT INTO tweet (created_at, id, author_id, original_text, location) VALUES (%(created_at)s, %(id)s, %(author_id)s, %(original_text)s, %(location)s)]
[parameters: ({'created_at': '2021-12-31T04:09:59.000Z', 'id': 1476767568446869504, 'author_id': 1164924322890297344, 'original_text': "STOP FUCKING GOING TO STARBUCKS TO GET A MEDICINE BALL BC YOU HAVE A SORE THROAT IF YOU KNOW YOU HAVE COVID OR EVEN IF YOU'RE NOT SURE, AND YES IT MATTERS IF YOU GO THROUGH THE DRIVE-THRU", 'location': 'Georgetown, TX'}, {'created_at': '2021-12-31T04:09:59.000Z', 'id': 1476767568404705282, 'author_id': 797483317364826112, 'original_text': 'Free rapid COVID testing at 380 S 17th St. Richmond CA. No appt needed, stay safe ya’ll!', 'location': 'bay area'}, {'created_at': '2021-12-31T04:09:59.000Z', 'id': 1476767568329388048, 'author_id': 1454583445657686025, 'original_text': 'So I’m the exiting chief of surgery at my hospital. My two years of stupid meetings, babysitting disruptive surgeons, managing Covid staffing issues, etc has culminated in receiving a $50 gift card. That’s how out of touch hospitals are. SMH. #MedTwitter', 'location': None}, {'created_at': '2021-12-31T04:09:59.000Z', 'id': 1476767568203431938, 'author_id': 773485929969414148, 'original_text': 'Quebec imposes COVID-19 curfew; Ontario limits eligibility for PCR tests amid Omicron surge - The Globe and Mail   https://t.co/bWEvGrc5Zg', 'location': 'Hyderabad, India'}, {'created_at': '2021-12-31T04:09:59.000Z', 'id': 1476767567813308420, 'author_id': 1452284405502840837, 'original_text': '[News]\n\n케플러 샤오팅·마시로 코로나 완치..1월3일 데뷔 프로모션 재개\n\nAs members fully recovered from COVID-19, Kep1er will continue promotion for its January 3rd debut\n\n📎 https://t.co/TX8szPF3EP\n\n#Kep1er #케플러', 'location': 'she/her༄stan ot9!'}, {'created_at': '2021-12-31T04:09:59.000Z', 'id': 1476767567800795136, 'author_id': 1393949294965657603, 'original_text': '@yuyuniwerse We are stolen two years by epidemic', 'location': 'she/her'}, {'created_at': '2021-12-31T04:09:59.000Z', 'id': 1476767567771541505, 'author_id': 1439581822871015432, 'original_text': 'NEW - Dr. Fauci: "Important thing: Many of the children are hospitalized with Covid as opposed to because of Covid."\n\nhttps://t.co/g7NzfpKTsQ', 'location': 'Texas, USA'}, {'created_at': '2021-12-31T04:09:59.000Z', 'id': 1476767567746269187, 'author_id': 184331718, 'original_text': 'No todo malestar es #Covid, 37 no es fiebre. Siguen existiendo las sinusitis alérgicas, las otitis y demás itis. Si tienen la suerte q tuve de buenos médicos q vieron más allá, todo es más fácil. Pataleen , no se queden con dudas... Nada... Eso.', 'location': 'Ciudad Autónoma de Buenos Aire'}, {'created_at': '2021-12-31T04:09:59.000Z', 'id': 1476767567159169028, 'author_id': 2166890976, 'original_text': 'Participants who received a booster at least 5 months after a second dose of Pfizer vaccine had 90% lower mortality due to Covid-19 than participants who did not receive a booster #covid19 #booster #mortality @NEJM https://t.co/uaBi6CjLJL', 'location': 'Helsinki, Finland'}, {'created_at': '2021-12-31T04:09:59.000Z', 'id': 1476767566941073409, 'author_id': 280267313, 'original_text': 'Should Tucker and Fox News be sued over COVID misinformation?', 'location': 'cape cod, ma'})]
(Background on this error at: http://sqlalche.me/e/13/9h9h)
[2022-01-05 06:00:49,421] {local_task_job.py:154} INFO - Task exited with return code 1
[2022-01-05 06:00:49,453] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-01-05 06:01:49,660] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [queued]>
[2022-01-05 06:01:49,672] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [queued]>
[2022-01-05 06:01:49,672] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 06:01:49,672] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 06:01:49,672] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 06:01:49,685] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 04:00:00+00:00
[2022-01-05 06:01:49,691] {standard_task_runner.py:52} INFO - Started process 1617 to run task
[2022-01-05 06:01:49,695] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T04:00:00+00:00', '--job-id', '182', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmpys8miijj', '--error-file', '/tmp/tmpzoosbgu7']
[2022-01-05 06:01:49,696] {standard_task_runner.py:77} INFO - Job 182: Subtask tweet_load
[2022-01-05 06:01:49,753] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [running]> on host 2b1d65872a35
[2022-01-05 06:01:49,808] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T04:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T04:00:00+00:00
[2022-01-05 06:01:49,810] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:01:49,810] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:01:49,810] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:01:49,810] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:01:49,810] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:01:49,810] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:01:49,810] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:01:49,811] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:01:49,811] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:01:49,811] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:01:49,811] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:01:49,811] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:01:49,811] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7fd8b40b1950>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 04:00:00+00:00: scheduled__2021-12-31T04:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-31', 'prev_ds_nodash': '20211231', 'prev_execution_date': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T04:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T04:00:00+00:00', 'ts_nodash': '20211231T040000', 'ts_nodash_with_tz': '20211231T040000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T04:00:00+00:00', 'tsnodash_var': '20211231T040000', 'templates_dict': None}
[2022-01-05 06:01:49,811] {logging_mixin.py:109} INFO - Hello, Current Time:06:01:49 Execution time is 2021-12-31T04:00:00+00:00
[2022-01-05 06:01:49,827] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 06:01:49,835] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 06:01:51,282] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
psycopg2.errors.NumericValueOutOfRange: numeric value "1164924322890297344" out of range for integer


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 133, in load_tweets
    tweet_data.to_sql('tweet', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1770, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1350, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1340, in insert_records
    table.insert(chunksize=chunksize, method=method)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 967, in insert
    exec_insert(conn, keys, chunk_iter)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 882, in _execute_insert
    conn.execute(self.table.insert(), data)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
sqlalchemy.exc.DataError: (psycopg2.errors.NumericValueOutOfRange) numeric value "1164924322890297344" out of range for integer

[SQL: INSERT INTO tweet (author_id, created_at, id, original_text, location) VALUES (%(author_id)s, %(created_at)s, %(id)s, %(original_text)s, %(location)s)]
[parameters: ({'author_id': 1164924322890297344, 'created_at': '2021-12-31T04:09:59.000Z', 'id': 1476767568446869504, 'original_text': "STOP FUCKING GOING TO STARBUCKS TO GET A MEDICINE BALL BC YOU HAVE A SORE THROAT IF YOU KNOW YOU HAVE COVID OR EVEN IF YOU'RE NOT SURE, AND YES IT MATTERS IF YOU GO THROUGH THE DRIVE-THRU", 'location': 'Georgetown, TX'}, {'author_id': 797483317364826112, 'created_at': '2021-12-31T04:09:59.000Z', 'id': 1476767568404705282, 'original_text': 'Free rapid COVID testing at 380 S 17th St. Richmond CA. No appt needed, stay safe ya’ll!', 'location': 'bay area'}, {'author_id': 1454583445657686025, 'created_at': '2021-12-31T04:09:59.000Z', 'id': 1476767568329388048, 'original_text': 'So I’m the exiting chief of surgery at my hospital. My two years of stupid meetings, babysitting disruptive surgeons, managing Covid staffing issues, etc has culminated in receiving a $50 gift card. That’s how out of touch hospitals are. SMH. #MedTwitter', 'location': None}, {'author_id': 773485929969414148, 'created_at': '2021-12-31T04:09:59.000Z', 'id': 1476767568203431938, 'original_text': 'Quebec imposes COVID-19 curfew; Ontario limits eligibility for PCR tests amid Omicron surge - The Globe and Mail   https://t.co/bWEvGrc5Zg', 'location': 'Hyderabad, India'}, {'author_id': 1452284405502840837, 'created_at': '2021-12-31T04:09:59.000Z', 'id': 1476767567813308420, 'original_text': '[News]\n\n케플러 샤오팅·마시로 코로나 완치..1월3일 데뷔 프로모션 재개\n\nAs members fully recovered from COVID-19, Kep1er will continue promotion for its January 3rd debut\n\n📎 https://t.co/TX8szPF3EP\n\n#Kep1er #케플러', 'location': 'she/her༄stan ot9!'}, {'author_id': 1393949294965657603, 'created_at': '2021-12-31T04:09:59.000Z', 'id': 1476767567800795136, 'original_text': '@yuyuniwerse We are stolen two years by epidemic', 'location': 'she/her'}, {'author_id': 1439581822871015432, 'created_at': '2021-12-31T04:09:59.000Z', 'id': 1476767567771541505, 'original_text': 'NEW - Dr. Fauci: "Important thing: Many of the children are hospitalized with Covid as opposed to because of Covid."\n\nhttps://t.co/g7NzfpKTsQ', 'location': 'Texas, USA'}, {'author_id': 184331718, 'created_at': '2021-12-31T04:09:59.000Z', 'id': 1476767567746269187, 'original_text': 'No todo malestar es #Covid, 37 no es fiebre. Siguen existiendo las sinusitis alérgicas, las otitis y demás itis. Si tienen la suerte q tuve de buenos médicos q vieron más allá, todo es más fácil. Pataleen , no se queden con dudas... Nada... Eso.', 'location': 'Ciudad Autónoma de Buenos Aire'}, {'author_id': 2166890976, 'created_at': '2021-12-31T04:09:59.000Z', 'id': 1476767567159169028, 'original_text': 'Participants who received a booster at least 5 months after a second dose of Pfizer vaccine had 90% lower mortality due to Covid-19 than participants who did not receive a booster #covid19 #booster #mortality @NEJM https://t.co/uaBi6CjLJL', 'location': 'Helsinki, Finland'}, {'author_id': 280267313, 'created_at': '2021-12-31T04:09:59.000Z', 'id': 1476767566941073409, 'original_text': 'Should Tucker and Fox News be sued over COVID misinformation?', 'location': 'cape cod, ma'})]
(Background on this error at: http://sqlalche.me/e/13/9h9h)
[2022-01-05 06:01:51,308] {taskinstance.py:1277} INFO - Marking task as FAILED. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T040000, start_date=20220105T060149, end_date=20220105T060151
[2022-01-05 06:01:51,332] {standard_task_runner.py:92} ERROR - Failed to execute job 182 for task tweet_load
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
psycopg2.errors.NumericValueOutOfRange: numeric value "1164924322890297344" out of range for integer


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 133, in load_tweets
    tweet_data.to_sql('tweet', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1770, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1350, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1340, in insert_records
    table.insert(chunksize=chunksize, method=method)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 967, in insert
    exec_insert(conn, keys, chunk_iter)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 882, in _execute_insert
    conn.execute(self.table.insert(), data)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
sqlalchemy.exc.DataError: (psycopg2.errors.NumericValueOutOfRange) numeric value "1164924322890297344" out of range for integer

[SQL: INSERT INTO tweet (author_id, created_at, id, original_text, location) VALUES (%(author_id)s, %(created_at)s, %(id)s, %(original_text)s, %(location)s)]
[parameters: ({'author_id': 1164924322890297344, 'created_at': '2021-12-31T04:09:59.000Z', 'id': 1476767568446869504, 'original_text': "STOP FUCKING GOING TO STARBUCKS TO GET A MEDICINE BALL BC YOU HAVE A SORE THROAT IF YOU KNOW YOU HAVE COVID OR EVEN IF YOU'RE NOT SURE, AND YES IT MATTERS IF YOU GO THROUGH THE DRIVE-THRU", 'location': 'Georgetown, TX'}, {'author_id': 797483317364826112, 'created_at': '2021-12-31T04:09:59.000Z', 'id': 1476767568404705282, 'original_text': 'Free rapid COVID testing at 380 S 17th St. Richmond CA. No appt needed, stay safe ya’ll!', 'location': 'bay area'}, {'author_id': 1454583445657686025, 'created_at': '2021-12-31T04:09:59.000Z', 'id': 1476767568329388048, 'original_text': 'So I’m the exiting chief of surgery at my hospital. My two years of stupid meetings, babysitting disruptive surgeons, managing Covid staffing issues, etc has culminated in receiving a $50 gift card. That’s how out of touch hospitals are. SMH. #MedTwitter', 'location': None}, {'author_id': 773485929969414148, 'created_at': '2021-12-31T04:09:59.000Z', 'id': 1476767568203431938, 'original_text': 'Quebec imposes COVID-19 curfew; Ontario limits eligibility for PCR tests amid Omicron surge - The Globe and Mail   https://t.co/bWEvGrc5Zg', 'location': 'Hyderabad, India'}, {'author_id': 1452284405502840837, 'created_at': '2021-12-31T04:09:59.000Z', 'id': 1476767567813308420, 'original_text': '[News]\n\n케플러 샤오팅·마시로 코로나 완치..1월3일 데뷔 프로모션 재개\n\nAs members fully recovered from COVID-19, Kep1er will continue promotion for its January 3rd debut\n\n📎 https://t.co/TX8szPF3EP\n\n#Kep1er #케플러', 'location': 'she/her༄stan ot9!'}, {'author_id': 1393949294965657603, 'created_at': '2021-12-31T04:09:59.000Z', 'id': 1476767567800795136, 'original_text': '@yuyuniwerse We are stolen two years by epidemic', 'location': 'she/her'}, {'author_id': 1439581822871015432, 'created_at': '2021-12-31T04:09:59.000Z', 'id': 1476767567771541505, 'original_text': 'NEW - Dr. Fauci: "Important thing: Many of the children are hospitalized with Covid as opposed to because of Covid."\n\nhttps://t.co/g7NzfpKTsQ', 'location': 'Texas, USA'}, {'author_id': 184331718, 'created_at': '2021-12-31T04:09:59.000Z', 'id': 1476767567746269187, 'original_text': 'No todo malestar es #Covid, 37 no es fiebre. Siguen existiendo las sinusitis alérgicas, las otitis y demás itis. Si tienen la suerte q tuve de buenos médicos q vieron más allá, todo es más fácil. Pataleen , no se queden con dudas... Nada... Eso.', 'location': 'Ciudad Autónoma de Buenos Aire'}, {'author_id': 2166890976, 'created_at': '2021-12-31T04:09:59.000Z', 'id': 1476767567159169028, 'original_text': 'Participants who received a booster at least 5 months after a second dose of Pfizer vaccine had 90% lower mortality due to Covid-19 than participants who did not receive a booster #covid19 #booster #mortality @NEJM https://t.co/uaBi6CjLJL', 'location': 'Helsinki, Finland'}, {'author_id': 280267313, 'created_at': '2021-12-31T04:09:59.000Z', 'id': 1476767566941073409, 'original_text': 'Should Tucker and Fox News be sued over COVID misinformation?', 'location': 'cape cod, ma'})]
(Background on this error at: http://sqlalche.me/e/13/9h9h)
[2022-01-05 06:01:51,352] {local_task_job.py:154} INFO - Task exited with return code 1
[2022-01-05 06:01:51,426] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-01-05 06:06:15,565] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [queued]>
[2022-01-05 06:06:15,584] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [queued]>
[2022-01-05 06:06:15,584] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 06:06:15,584] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 06:06:15,585] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 06:06:15,603] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 04:00:00+00:00
[2022-01-05 06:06:15,615] {standard_task_runner.py:52} INFO - Started process 1865 to run task
[2022-01-05 06:06:15,619] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T04:00:00+00:00', '--job-id', '199', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmpzauqjf1j', '--error-file', '/tmp/tmpbah86e63']
[2022-01-05 06:06:15,620] {standard_task_runner.py:77} INFO - Job 199: Subtask tweet_load
[2022-01-05 06:06:15,683] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [running]> on host 2b1d65872a35
[2022-01-05 06:06:15,746] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T04:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T04:00:00+00:00
[2022-01-05 06:06:15,748] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:06:15,748] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:06:15,748] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:06:15,749] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:06:15,749] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:06:15,749] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:06:15,749] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:06:15,749] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:06:15,749] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:06:15,749] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:06:15,750] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:06:15,750] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:06:15,750] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7fd8b40b1950>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 04:00:00+00:00: scheduled__2021-12-31T04:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-31', 'prev_ds_nodash': '20211231', 'prev_execution_date': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T04:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T04:00:00+00:00', 'ts_nodash': '20211231T040000', 'ts_nodash_with_tz': '20211231T040000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T04:00:00+00:00', 'tsnodash_var': '20211231T040000', 'templates_dict': None}
[2022-01-05 06:06:15,750] {logging_mixin.py:109} INFO - Hello, Current Time:06:06:15 Execution time is 2021-12-31T04:00:00+00:00
[2022-01-05 06:06:15,771] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 06:06:15,782] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 06:06:27,055] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
psycopg2.errors.StringDataRightTruncation: value too long for type character varying(200)


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 136, in load_tweets
    tweet_data.to_sql('tweet', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1770, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1350, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1340, in insert_records
    table.insert(chunksize=chunksize, method=method)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 967, in insert
    exec_insert(conn, keys, chunk_iter)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 882, in _execute_insert
    conn.execute(self.table.insert(), data)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
sqlalchemy.exc.DataError: (psycopg2.errors.StringDataRightTruncation) value too long for type character varying(200)

[SQL: INSERT INTO tweet (id, author_id, created_at, original_text, location) VALUES (%(id)s, %(author_id)s, %(created_at)s, %(original_text)s, %(location)s)]
[parameters: ({'id': 1164924322890297344, 'author_id': 1164924322890297344, 'created_at': '2021-12-31T04:09:59.000Z', 'original_text': "STOP FUCKING GOING TO STARBUCKS TO GET A MEDICINE BALL BC YOU HAVE A SORE THROAT IF YOU KNOW YOU HAVE COVID OR EVEN IF YOU'RE NOT SURE, AND YES IT MATTERS IF YOU GO THROUGH THE DRIVE-THRU", 'location': 'Georgetown, TX'}, {'id': 797483317364826112, 'author_id': 797483317364826112, 'created_at': '2021-12-31T04:09:59.000Z', 'original_text': 'Free rapid COVID testing at 380 S 17th St. Richmond CA. No appt needed, stay safe ya’ll!', 'location': 'bay area'}, {'id': 1454583445657686025, 'author_id': 1454583445657686025, 'created_at': '2021-12-31T04:09:59.000Z', 'original_text': 'So I’m the exiting chief of surgery at my hospital. My two years of stupid meetings, babysitting disruptive surgeons, managing Covid staffing issues, etc has culminated in receiving a $50 gift card. That’s how out of touch hospitals are. SMH. #MedTwitter', 'location': None}, {'id': 773485929969414148, 'author_id': 773485929969414148, 'created_at': '2021-12-31T04:09:59.000Z', 'original_text': 'Quebec imposes COVID-19 curfew; Ontario limits eligibility for PCR tests amid Omicron surge - The Globe and Mail   https://t.co/bWEvGrc5Zg', 'location': 'Hyderabad, India'}, {'id': 1452284405502840837, 'author_id': 1452284405502840837, 'created_at': '2021-12-31T04:09:59.000Z', 'original_text': '[News]\n\n케플러 샤오팅·마시로 코로나 완치..1월3일 데뷔 프로모션 재개\n\nAs members fully recovered from COVID-19, Kep1er will continue promotion for its January 3rd debut\n\n📎 https://t.co/TX8szPF3EP\n\n#Kep1er #케플러', 'location': 'she/her༄stan ot9!'}, {'id': 1393949294965657603, 'author_id': 1393949294965657603, 'created_at': '2021-12-31T04:09:59.000Z', 'original_text': '@yuyuniwerse We are stolen two years by epidemic', 'location': 'she/her'}, {'id': 1439581822871015432, 'author_id': 1439581822871015432, 'created_at': '2021-12-31T04:09:59.000Z', 'original_text': 'NEW - Dr. Fauci: "Important thing: Many of the children are hospitalized with Covid as opposed to because of Covid."\n\nhttps://t.co/g7NzfpKTsQ', 'location': 'Texas, USA'}, {'id': 184331718, 'author_id': 184331718, 'created_at': '2021-12-31T04:09:59.000Z', 'original_text': 'No todo malestar es #Covid, 37 no es fiebre. Siguen existiendo las sinusitis alérgicas, las otitis y demás itis. Si tienen la suerte q tuve de buenos médicos q vieron más allá, todo es más fácil. Pataleen , no se queden con dudas... Nada... Eso.', 'location': 'Ciudad Autónoma de Buenos Aire'}, {'id': 2166890976, 'author_id': 2166890976, 'created_at': '2021-12-31T04:09:59.000Z', 'original_text': 'Participants who received a booster at least 5 months after a second dose of Pfizer vaccine had 90% lower mortality due to Covid-19 than participants who did not receive a booster #covid19 #booster #mortality @NEJM https://t.co/uaBi6CjLJL', 'location': 'Helsinki, Finland'}, {'id': 280267313, 'author_id': 280267313, 'created_at': '2021-12-31T04:09:59.000Z', 'original_text': 'Should Tucker and Fox News be sued over COVID misinformation?', 'location': 'cape cod, ma'})]
(Background on this error at: http://sqlalche.me/e/13/9h9h)
[2022-01-05 06:06:27,068] {taskinstance.py:1277} INFO - Marking task as FAILED. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T040000, start_date=20220105T060615, end_date=20220105T060627
[2022-01-05 06:06:27,079] {standard_task_runner.py:92} ERROR - Failed to execute job 199 for task tweet_load
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
psycopg2.errors.StringDataRightTruncation: value too long for type character varying(200)


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 136, in load_tweets
    tweet_data.to_sql('tweet', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1770, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1350, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1340, in insert_records
    table.insert(chunksize=chunksize, method=method)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 967, in insert
    exec_insert(conn, keys, chunk_iter)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 882, in _execute_insert
    conn.execute(self.table.insert(), data)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
sqlalchemy.exc.DataError: (psycopg2.errors.StringDataRightTruncation) value too long for type character varying(200)

[SQL: INSERT INTO tweet (id, author_id, created_at, original_text, location) VALUES (%(id)s, %(author_id)s, %(created_at)s, %(original_text)s, %(location)s)]
[parameters: ({'id': 1164924322890297344, 'author_id': 1164924322890297344, 'created_at': '2021-12-31T04:09:59.000Z', 'original_text': "STOP FUCKING GOING TO STARBUCKS TO GET A MEDICINE BALL BC YOU HAVE A SORE THROAT IF YOU KNOW YOU HAVE COVID OR EVEN IF YOU'RE NOT SURE, AND YES IT MATTERS IF YOU GO THROUGH THE DRIVE-THRU", 'location': 'Georgetown, TX'}, {'id': 797483317364826112, 'author_id': 797483317364826112, 'created_at': '2021-12-31T04:09:59.000Z', 'original_text': 'Free rapid COVID testing at 380 S 17th St. Richmond CA. No appt needed, stay safe ya’ll!', 'location': 'bay area'}, {'id': 1454583445657686025, 'author_id': 1454583445657686025, 'created_at': '2021-12-31T04:09:59.000Z', 'original_text': 'So I’m the exiting chief of surgery at my hospital. My two years of stupid meetings, babysitting disruptive surgeons, managing Covid staffing issues, etc has culminated in receiving a $50 gift card. That’s how out of touch hospitals are. SMH. #MedTwitter', 'location': None}, {'id': 773485929969414148, 'author_id': 773485929969414148, 'created_at': '2021-12-31T04:09:59.000Z', 'original_text': 'Quebec imposes COVID-19 curfew; Ontario limits eligibility for PCR tests amid Omicron surge - The Globe and Mail   https://t.co/bWEvGrc5Zg', 'location': 'Hyderabad, India'}, {'id': 1452284405502840837, 'author_id': 1452284405502840837, 'created_at': '2021-12-31T04:09:59.000Z', 'original_text': '[News]\n\n케플러 샤오팅·마시로 코로나 완치..1월3일 데뷔 프로모션 재개\n\nAs members fully recovered from COVID-19, Kep1er will continue promotion for its January 3rd debut\n\n📎 https://t.co/TX8szPF3EP\n\n#Kep1er #케플러', 'location': 'she/her༄stan ot9!'}, {'id': 1393949294965657603, 'author_id': 1393949294965657603, 'created_at': '2021-12-31T04:09:59.000Z', 'original_text': '@yuyuniwerse We are stolen two years by epidemic', 'location': 'she/her'}, {'id': 1439581822871015432, 'author_id': 1439581822871015432, 'created_at': '2021-12-31T04:09:59.000Z', 'original_text': 'NEW - Dr. Fauci: "Important thing: Many of the children are hospitalized with Covid as opposed to because of Covid."\n\nhttps://t.co/g7NzfpKTsQ', 'location': 'Texas, USA'}, {'id': 184331718, 'author_id': 184331718, 'created_at': '2021-12-31T04:09:59.000Z', 'original_text': 'No todo malestar es #Covid, 37 no es fiebre. Siguen existiendo las sinusitis alérgicas, las otitis y demás itis. Si tienen la suerte q tuve de buenos médicos q vieron más allá, todo es más fácil. Pataleen , no se queden con dudas... Nada... Eso.', 'location': 'Ciudad Autónoma de Buenos Aire'}, {'id': 2166890976, 'author_id': 2166890976, 'created_at': '2021-12-31T04:09:59.000Z', 'original_text': 'Participants who received a booster at least 5 months after a second dose of Pfizer vaccine had 90% lower mortality due to Covid-19 than participants who did not receive a booster #covid19 #booster #mortality @NEJM https://t.co/uaBi6CjLJL', 'location': 'Helsinki, Finland'}, {'id': 280267313, 'author_id': 280267313, 'created_at': '2021-12-31T04:09:59.000Z', 'original_text': 'Should Tucker and Fox News be sued over COVID misinformation?', 'location': 'cape cod, ma'})]
(Background on this error at: http://sqlalche.me/e/13/9h9h)
[2022-01-05 06:06:27,123] {local_task_job.py:154} INFO - Task exited with return code 1
[2022-01-05 06:06:27,153] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-01-05 06:09:22,207] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [queued]>
[2022-01-05 06:09:22,224] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [queued]>
[2022-01-05 06:09:22,224] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 06:09:22,224] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 06:09:22,224] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 06:09:22,243] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 04:00:00+00:00
[2022-01-05 06:09:22,249] {standard_task_runner.py:52} INFO - Started process 2059 to run task
[2022-01-05 06:09:22,253] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T04:00:00+00:00', '--job-id', '217', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmpbt_2s7zy', '--error-file', '/tmp/tmpgqkoos4r']
[2022-01-05 06:09:22,254] {standard_task_runner.py:77} INFO - Job 217: Subtask tweet_load
[2022-01-05 06:09:22,322] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [running]> on host 2b1d65872a35
[2022-01-05 06:09:22,395] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T04:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T04:00:00+00:00
[2022-01-05 06:09:22,397] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:09:22,397] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:09:22,397] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:09:22,397] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:09:22,397] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:09:22,397] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:09:22,397] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:09:22,397] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:09:22,398] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:09:22,398] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:09:22,398] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:09:22,398] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:09:22,398] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7fd8b40b1950>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 04:00:00+00:00: scheduled__2021-12-31T04:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-31', 'prev_ds_nodash': '20211231', 'prev_execution_date': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T04:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T04:00:00+00:00', 'ts_nodash': '20211231T040000', 'ts_nodash_with_tz': '20211231T040000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T04:00:00+00:00', 'tsnodash_var': '20211231T040000', 'templates_dict': None}
[2022-01-05 06:09:22,398] {logging_mixin.py:109} INFO - Hello, Current Time:06:09:22 Execution time is 2021-12-31T04:00:00+00:00
[2022-01-05 06:09:22,412] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 06:09:22,422] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 06:09:24,307] {taskinstance.py:1700} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
psycopg2.errors.StringDataRightTruncation: value too long for type character varying(256)


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 136, in load_tweets
    tweet_data.to_sql('tweet', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1770, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1350, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1340, in insert_records
    table.insert(chunksize=chunksize, method=method)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 967, in insert
    exec_insert(conn, keys, chunk_iter)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 882, in _execute_insert
    conn.execute(self.table.insert(), data)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
sqlalchemy.exc.DataError: (psycopg2.errors.StringDataRightTruncation) value too long for type character varying(256)

[SQL: INSERT INTO tweet (author_id, id, created_at, original_text, location) VALUES (%(author_id)s, %(id)s, %(created_at)s, %(original_text)s, %(location)s)]
[parameters: ({'author_id': 1164924322890297344, 'id': 1164924322890297344, 'created_at': '2021-12-31T04:09:59.000Z', 'original_text': "STOP FUCKING GOING TO STARBUCKS TO GET A MEDICINE BALL BC YOU HAVE A SORE THROAT IF YOU KNOW YOU HAVE COVID OR EVEN IF YOU'RE NOT SURE, AND YES IT MATTERS IF YOU GO THROUGH THE DRIVE-THRU", 'location': 'Georgetown, TX'}, {'author_id': 797483317364826112, 'id': 797483317364826112, 'created_at': '2021-12-31T04:09:59.000Z', 'original_text': 'Free rapid COVID testing at 380 S 17th St. Richmond CA. No appt needed, stay safe ya’ll!', 'location': 'bay area'}, {'author_id': 1454583445657686025, 'id': 1454583445657686025, 'created_at': '2021-12-31T04:09:59.000Z', 'original_text': 'So I’m the exiting chief of surgery at my hospital. My two years of stupid meetings, babysitting disruptive surgeons, managing Covid staffing issues, etc has culminated in receiving a $50 gift card. That’s how out of touch hospitals are. SMH. #MedTwitter', 'location': None}, {'author_id': 773485929969414148, 'id': 773485929969414148, 'created_at': '2021-12-31T04:09:59.000Z', 'original_text': 'Quebec imposes COVID-19 curfew; Ontario limits eligibility for PCR tests amid Omicron surge - The Globe and Mail   https://t.co/bWEvGrc5Zg', 'location': 'Hyderabad, India'}, {'author_id': 1452284405502840837, 'id': 1452284405502840837, 'created_at': '2021-12-31T04:09:59.000Z', 'original_text': '[News]\n\n케플러 샤오팅·마시로 코로나 완치..1월3일 데뷔 프로모션 재개\n\nAs members fully recovered from COVID-19, Kep1er will continue promotion for its January 3rd debut\n\n📎 https://t.co/TX8szPF3EP\n\n#Kep1er #케플러', 'location': 'she/her༄stan ot9!'}, {'author_id': 1393949294965657603, 'id': 1393949294965657603, 'created_at': '2021-12-31T04:09:59.000Z', 'original_text': '@yuyuniwerse We are stolen two years by epidemic', 'location': 'she/her'}, {'author_id': 1439581822871015432, 'id': 1439581822871015432, 'created_at': '2021-12-31T04:09:59.000Z', 'original_text': 'NEW - Dr. Fauci: "Important thing: Many of the children are hospitalized with Covid as opposed to because of Covid."\n\nhttps://t.co/g7NzfpKTsQ', 'location': 'Texas, USA'}, {'author_id': 184331718, 'id': 184331718, 'created_at': '2021-12-31T04:09:59.000Z', 'original_text': 'No todo malestar es #Covid, 37 no es fiebre. Siguen existiendo las sinusitis alérgicas, las otitis y demás itis. Si tienen la suerte q tuve de buenos médicos q vieron más allá, todo es más fácil. Pataleen , no se queden con dudas... Nada... Eso.', 'location': 'Ciudad Autónoma de Buenos Aire'}, {'author_id': 2166890976, 'id': 2166890976, 'created_at': '2021-12-31T04:09:59.000Z', 'original_text': 'Participants who received a booster at least 5 months after a second dose of Pfizer vaccine had 90% lower mortality due to Covid-19 than participants who did not receive a booster #covid19 #booster #mortality @NEJM https://t.co/uaBi6CjLJL', 'location': 'Helsinki, Finland'}, {'author_id': 280267313, 'id': 280267313, 'created_at': '2021-12-31T04:09:59.000Z', 'original_text': 'Should Tucker and Fox News be sued over COVID misinformation?', 'location': 'cape cod, ma'})]
(Background on this error at: http://sqlalche.me/e/13/9h9h)
[2022-01-05 06:09:24,330] {taskinstance.py:1277} INFO - Marking task as FAILED. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T040000, start_date=20220105T060922, end_date=20220105T060924
[2022-01-05 06:09:24,348] {standard_task_runner.py:92} ERROR - Failed to execute job 217 for task tweet_load
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
psycopg2.errors.StringDataRightTruncation: value too long for type character varying(256)


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/task/task_runner/standard_task_runner.py", line 85, in _start_by_fork
    args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/cli_parser.py", line 48, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/cli.py", line 92, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 298, in task_run
    _run_task_by_selected_method(args, dag, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 107, in _run_task_by_selected_method
    _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/cli/commands/task_command.py", line 184, in _run_raw_task
    error_file=args.error_file,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 70, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1329, in _run_raw_task
    self._execute_task_with_callbacks(context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1455, in _execute_task_with_callbacks
    result = self._execute_task(context, self.task)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 1511, in _execute_task
    result = execute_callable(context=context)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 174, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/operators/python.py", line 185, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/load_redshift.py", line 136, in load_tweets
    tweet_data.to_sql('tweet', redshift_hook.get_sqlalchemy_engine(), if_exists='append', index=False)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/core/generic.py", line 2882, in to_sql
    method=method,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 728, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1770, in to_sql
    **engine_kwargs,
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1350, in insert_records
    raise err
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 1340, in insert_records
    table.insert(chunksize=chunksize, method=method)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 967, in insert
    exec_insert(conn, keys, chunk_iter)
  File "/home/airflow/.local/lib/python3.7/site-packages/pandas/io/sql.py", line 882, in _execute_insert
    conn.execute(self.table.insert(), data)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1011, in execute
    return meth(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/sql/elements.py", line 298, in _execute_on_connection
    return connection._execute_clauseelement(self, multiparams, params)
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1130, in _execute_clauseelement
    distilled_params,
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1317, in _execute_context
    e, statement, parameters, cursor, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1511, in _handle_dbapi_exception
    sqlalchemy_exception, with_traceback=exc_info[2], from_=e
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/util/compat.py", line 182, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/engine/base.py", line 1257, in _execute_context
    cursor, statement, parameters, context
  File "/home/airflow/.local/lib/python3.7/site-packages/sqlalchemy/dialects/postgresql/psycopg2.py", line 912, in do_executemany
    cursor.executemany(statement, parameters)
sqlalchemy.exc.DataError: (psycopg2.errors.StringDataRightTruncation) value too long for type character varying(256)

[SQL: INSERT INTO tweet (author_id, id, created_at, original_text, location) VALUES (%(author_id)s, %(id)s, %(created_at)s, %(original_text)s, %(location)s)]
[parameters: ({'author_id': 1164924322890297344, 'id': 1164924322890297344, 'created_at': '2021-12-31T04:09:59.000Z', 'original_text': "STOP FUCKING GOING TO STARBUCKS TO GET A MEDICINE BALL BC YOU HAVE A SORE THROAT IF YOU KNOW YOU HAVE COVID OR EVEN IF YOU'RE NOT SURE, AND YES IT MATTERS IF YOU GO THROUGH THE DRIVE-THRU", 'location': 'Georgetown, TX'}, {'author_id': 797483317364826112, 'id': 797483317364826112, 'created_at': '2021-12-31T04:09:59.000Z', 'original_text': 'Free rapid COVID testing at 380 S 17th St. Richmond CA. No appt needed, stay safe ya’ll!', 'location': 'bay area'}, {'author_id': 1454583445657686025, 'id': 1454583445657686025, 'created_at': '2021-12-31T04:09:59.000Z', 'original_text': 'So I’m the exiting chief of surgery at my hospital. My two years of stupid meetings, babysitting disruptive surgeons, managing Covid staffing issues, etc has culminated in receiving a $50 gift card. That’s how out of touch hospitals are. SMH. #MedTwitter', 'location': None}, {'author_id': 773485929969414148, 'id': 773485929969414148, 'created_at': '2021-12-31T04:09:59.000Z', 'original_text': 'Quebec imposes COVID-19 curfew; Ontario limits eligibility for PCR tests amid Omicron surge - The Globe and Mail   https://t.co/bWEvGrc5Zg', 'location': 'Hyderabad, India'}, {'author_id': 1452284405502840837, 'id': 1452284405502840837, 'created_at': '2021-12-31T04:09:59.000Z', 'original_text': '[News]\n\n케플러 샤오팅·마시로 코로나 완치..1월3일 데뷔 프로모션 재개\n\nAs members fully recovered from COVID-19, Kep1er will continue promotion for its January 3rd debut\n\n📎 https://t.co/TX8szPF3EP\n\n#Kep1er #케플러', 'location': 'she/her༄stan ot9!'}, {'author_id': 1393949294965657603, 'id': 1393949294965657603, 'created_at': '2021-12-31T04:09:59.000Z', 'original_text': '@yuyuniwerse We are stolen two years by epidemic', 'location': 'she/her'}, {'author_id': 1439581822871015432, 'id': 1439581822871015432, 'created_at': '2021-12-31T04:09:59.000Z', 'original_text': 'NEW - Dr. Fauci: "Important thing: Many of the children are hospitalized with Covid as opposed to because of Covid."\n\nhttps://t.co/g7NzfpKTsQ', 'location': 'Texas, USA'}, {'author_id': 184331718, 'id': 184331718, 'created_at': '2021-12-31T04:09:59.000Z', 'original_text': 'No todo malestar es #Covid, 37 no es fiebre. Siguen existiendo las sinusitis alérgicas, las otitis y demás itis. Si tienen la suerte q tuve de buenos médicos q vieron más allá, todo es más fácil. Pataleen , no se queden con dudas... Nada... Eso.', 'location': 'Ciudad Autónoma de Buenos Aire'}, {'author_id': 2166890976, 'id': 2166890976, 'created_at': '2021-12-31T04:09:59.000Z', 'original_text': 'Participants who received a booster at least 5 months after a second dose of Pfizer vaccine had 90% lower mortality due to Covid-19 than participants who did not receive a booster #covid19 #booster #mortality @NEJM https://t.co/uaBi6CjLJL', 'location': 'Helsinki, Finland'}, {'author_id': 280267313, 'id': 280267313, 'created_at': '2021-12-31T04:09:59.000Z', 'original_text': 'Should Tucker and Fox News be sued over COVID misinformation?', 'location': 'cape cod, ma'})]
(Background on this error at: http://sqlalche.me/e/13/9h9h)
[2022-01-05 06:09:24,378] {local_task_job.py:154} INFO - Task exited with return code 1
[2022-01-05 06:09:24,424] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-01-05 06:25:34,332] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [queued]>
[2022-01-05 06:25:34,349] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [queued]>
[2022-01-05 06:25:34,349] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 06:25:34,349] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 06:25:34,349] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 06:25:34,368] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 04:00:00+00:00
[2022-01-05 06:25:34,376] {standard_task_runner.py:52} INFO - Started process 2828 to run task
[2022-01-05 06:25:34,381] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T04:00:00+00:00', '--job-id', '235', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmpfxkvs1_6', '--error-file', '/tmp/tmp3wfalzq4']
[2022-01-05 06:25:34,383] {standard_task_runner.py:77} INFO - Job 235: Subtask tweet_load
[2022-01-05 06:25:34,460] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [running]> on host 2b1d65872a35
[2022-01-05 06:25:34,608] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T04:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T04:00:00+00:00
[2022-01-05 06:25:34,613] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:25:34,614] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:25:34,614] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:25:34,614] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:25:34,614] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:25:34,614] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:25:34,615] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:25:34,615] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:25:34,615] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:25:34,615] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:25:34,615] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:25:34,615] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:25:34,616] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7fd8b40b1950>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 04:00:00+00:00: scheduled__2021-12-31T04:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-31', 'prev_ds_nodash': '20211231', 'prev_execution_date': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T04:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T04:00:00+00:00', 'ts_nodash': '20211231T040000', 'ts_nodash_with_tz': '20211231T040000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T04:00:00+00:00', 'tsnodash_var': '20211231T040000', 'templates_dict': None}
[2022-01-05 06:25:34,616] {logging_mixin.py:109} INFO - Hello, Current Time:06:25:34 Execution time is 2021-12-31T04:00:00+00:00
[2022-01-05 06:25:34,633] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 06:25:34,643] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 06:25:37,038] {python.py:175} INFO - Done. Returned value was: None
[2022-01-05 06:25:37,052] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T040000, start_date=20220105T062534, end_date=20220105T062537
[2022-01-05 06:25:37,088] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-01-05 06:25:37,137] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-01-05 06:28:28,289] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [queued]>
[2022-01-05 06:28:28,311] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [queued]>
[2022-01-05 06:28:28,311] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 06:28:28,311] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 06:28:28,311] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 06:28:28,342] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 04:00:00+00:00
[2022-01-05 06:28:28,348] {standard_task_runner.py:52} INFO - Started process 3008 to run task
[2022-01-05 06:28:28,360] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T04:00:00+00:00', '--job-id', '253', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmpycb7s9vq', '--error-file', '/tmp/tmp5ofnfc8g']
[2022-01-05 06:28:28,361] {standard_task_runner.py:77} INFO - Job 253: Subtask tweet_load
[2022-01-05 06:28:28,494] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [running]> on host 2b1d65872a35
[2022-01-05 06:28:28,616] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T04:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T04:00:00+00:00
[2022-01-05 06:28:28,617] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:28:28,618] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:28:28,618] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:28:28,618] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:28:28,618] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:28:28,618] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:28:28,618] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:28:28,618] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:28:28,619] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:28:28,619] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:28:28,619] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:28:28,619] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:28:28,619] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7fd8b40b1950>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 04:00:00+00:00: scheduled__2021-12-31T04:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-31', 'prev_ds_nodash': '20211231', 'prev_execution_date': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T04:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T04:00:00+00:00', 'ts_nodash': '20211231T040000', 'ts_nodash_with_tz': '20211231T040000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T04:00:00+00:00', 'tsnodash_var': '20211231T040000', 'templates_dict': None}
[2022-01-05 06:28:28,633] {logging_mixin.py:109} INFO - Hello, Current Time:06:28:28 Execution time is 2021-12-31T04:00:00+00:00
[2022-01-05 06:28:28,683] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 06:28:28,698] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 06:28:30,954] {python.py:175} INFO - Done. Returned value was: None
[2022-01-05 06:28:30,967] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T040000, start_date=20220105T062828, end_date=20220105T062830
[2022-01-05 06:28:31,016] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-01-05 06:28:31,060] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-01-05 06:32:02,548] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [queued]>
[2022-01-05 06:32:02,566] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [queued]>
[2022-01-05 06:32:02,566] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 06:32:02,566] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 06:32:02,566] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 06:32:02,584] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 04:00:00+00:00
[2022-01-05 06:32:02,591] {standard_task_runner.py:52} INFO - Started process 3226 to run task
[2022-01-05 06:32:02,597] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T04:00:00+00:00', '--job-id', '271', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmpvwspm6u_', '--error-file', '/tmp/tmpub9er9mw']
[2022-01-05 06:32:02,598] {standard_task_runner.py:77} INFO - Job 271: Subtask tweet_load
[2022-01-05 06:32:02,677] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [running]> on host 2b1d65872a35
[2022-01-05 06:32:02,785] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T04:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T04:00:00+00:00
[2022-01-05 06:32:02,790] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:32:02,790] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:32:02,790] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:32:02,790] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:32:02,791] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:32:02,791] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:32:02,791] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:32:02,791] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:32:02,791] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:32:02,791] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:32:02,791] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:32:02,791] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 06:32:02,794] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7fd8b40b1950>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 04:00:00+00:00: scheduled__2021-12-31T04:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-31', 'prev_ds_nodash': '20211231', 'prev_execution_date': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T04:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T04:00:00+00:00', 'ts_nodash': '20211231T040000', 'ts_nodash_with_tz': '20211231T040000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T04:00:00+00:00', 'tsnodash_var': '20211231T040000', 'templates_dict': None}
[2022-01-05 06:32:02,794] {logging_mixin.py:109} INFO - Hello, Current Time:06:32:02 Execution time is 2021-12-31T04:00:00+00:00
[2022-01-05 06:32:02,840] {warnings.py:110} WARNING - /opt/***/dags/load_redshift.py:137: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only
  tweet_data = tweet_data.drop('original_text', 1)

[2022-01-05 06:32:02,891] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 06:32:02,922] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 06:32:17,757] {python.py:175} INFO - Done. Returned value was: None
[2022-01-05 06:32:17,774] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T040000, start_date=20220105T063202, end_date=20220105T063217
[2022-01-05 06:32:17,832] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-01-05 06:32:17,921] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-01-05 07:02:31,124] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [queued]>
[2022-01-05 07:02:31,157] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [queued]>
[2022-01-05 07:02:31,158] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 07:02:31,158] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 07:02:31,158] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 07:02:31,214] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 04:00:00+00:00
[2022-01-05 07:02:31,223] {standard_task_runner.py:52} INFO - Started process 122 to run task
[2022-01-05 07:02:31,246] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T04:00:00+00:00', '--job-id', '324', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmp_wa36uix', '--error-file', '/tmp/tmpps4p__8i']
[2022-01-05 07:02:31,247] {standard_task_runner.py:77} INFO - Job 324: Subtask tweet_load
[2022-01-05 07:02:31,469] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [running]> on host e544fdb7c66e
[2022-01-05 07:02:31,764] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T04:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T04:00:00+00:00
[2022-01-05 07:02:31,765] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:02:31,765] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:02:31,766] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:02:31,766] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:02:31,766] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:02:31,766] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:02:31,766] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:02:31,766] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:02:31,767] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:02:31,767] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:02:31,767] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:02:31,767] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:02:31,767] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7fa6a9eda8d0>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 04:00:00+00:00: scheduled__2021-12-31T04:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-31', 'prev_ds_nodash': '20211231', 'prev_execution_date': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T04:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T04:00:00+00:00', 'ts_nodash': '20211231T040000', 'ts_nodash_with_tz': '20211231T040000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T04:00:00+00:00', 'tsnodash_var': '20211231T040000', 'templates_dict': None}
[2022-01-05 07:02:31,768] {logging_mixin.py:109} INFO - Hello, Current Time:07:02:31 Execution time is 2021-12-31T04:00:00+00:00
[2022-01-05 07:02:31,783] {warnings.py:110} WARNING - /opt/***/dags/load_redshift.py:137: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only
  tweet_data = tweet_data.drop('original_text', 1)

[2022-01-05 07:02:31,853] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 07:02:31,879] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 07:02:35,685] {python.py:175} INFO - Done. Returned value was: None
[2022-01-05 07:02:35,695] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T040000, start_date=20220105T070231, end_date=20220105T070235
[2022-01-05 07:02:35,733] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-01-05 07:02:35,764] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-01-05 07:04:28,720] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [queued]>
[2022-01-05 07:04:28,730] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [queued]>
[2022-01-05 07:04:28,730] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 07:04:28,730] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 07:04:28,730] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 07:04:28,741] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 04:00:00+00:00
[2022-01-05 07:04:28,747] {standard_task_runner.py:52} INFO - Started process 265 to run task
[2022-01-05 07:04:28,751] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T04:00:00+00:00', '--job-id', '345', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmpcjj2aet5', '--error-file', '/tmp/tmp0if9sztg']
[2022-01-05 07:04:28,752] {standard_task_runner.py:77} INFO - Job 345: Subtask tweet_load
[2022-01-05 07:04:28,801] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [running]> on host e544fdb7c66e
[2022-01-05 07:04:28,849] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T04:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T04:00:00+00:00
[2022-01-05 07:04:28,850] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:04:28,851] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:04:28,851] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:04:28,851] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:04:28,851] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:04:28,851] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:04:28,851] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:04:28,851] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:04:28,851] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:04:28,851] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:04:28,851] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:04:28,852] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 07:04:28,852] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7fa6a9eda8d0>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 04:00:00+00:00: scheduled__2021-12-31T04:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-31', 'prev_ds_nodash': '20211231', 'prev_execution_date': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T04:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T04:00:00+00:00', 'ts_nodash': '20211231T040000', 'ts_nodash_with_tz': '20211231T040000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T04:00:00+00:00', 'tsnodash_var': '20211231T040000', 'templates_dict': None}
[2022-01-05 07:04:28,852] {logging_mixin.py:109} INFO - Hello, Current Time:07:04:28 Execution time is 2021-12-31T04:00:00+00:00
[2022-01-05 07:04:28,866] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 07:04:28,872] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 07:04:44,984] {python.py:175} INFO - Done. Returned value was: None
[2022-01-05 07:04:44,993] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T040000, start_date=20220105T070428, end_date=20220105T070444
[2022-01-05 07:04:45,019] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-01-05 07:04:45,046] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-01-05 18:45:41,037] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [queued]>
[2022-01-05 18:45:41,058] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [queued]>
[2022-01-05 18:45:41,058] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 18:45:41,058] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 18:45:41,058] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 18:45:41,096] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 04:00:00+00:00
[2022-01-05 18:45:41,118] {standard_task_runner.py:52} INFO - Started process 765 to run task
[2022-01-05 18:45:41,127] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T04:00:00+00:00', '--job-id', '385', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmp5lz1cmql', '--error-file', '/tmp/tmpfuioz58p']
[2022-01-05 18:45:41,132] {standard_task_runner.py:77} INFO - Job 385: Subtask tweet_load
[2022-01-05 18:45:41,336] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [running]> on host e544fdb7c66e
[2022-01-05 18:45:41,526] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T04:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T04:00:00+00:00
[2022-01-05 18:45:41,528] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:45:41,528] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:45:41,528] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:45:41,528] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:45:41,529] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:45:41,529] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:45:41,529] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:45:41,529] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:45:41,529] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:45:41,529] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:45:41,529] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:45:41,529] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:45:41,530] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7ffaccd8cb10>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 04:00:00+00:00: scheduled__2021-12-31T04:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-31', 'prev_ds_nodash': '20211231', 'prev_execution_date': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T04:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T04:00:00+00:00', 'ts_nodash': '20211231T040000', 'ts_nodash_with_tz': '20211231T040000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T04:00:00+00:00', 'tsnodash_var': '20211231T040000', 'templates_dict': None}
[2022-01-05 18:45:41,530] {logging_mixin.py:109} INFO - Hello, Current Time:18:45:41 Execution time is 2021-12-31T04:00:00+00:00
[2022-01-05 18:45:41,565] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 18:45:41,586] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 18:45:45,420] {python.py:175} INFO - Done. Returned value was: None
[2022-01-05 18:45:45,447] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T040000, start_date=20220105T184541, end_date=20220105T184545
[2022-01-05 18:45:45,519] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-01-05 18:45:45,570] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-01-05 18:45:45,606] {dagrun.py:545} INFO - Marking run <DagRun load_dimensions @ 2021-12-31 04:00:00+00:00: scheduled__2021-12-31T04:00:00+00:00, externally triggered: False> successful
[2022-01-05 18:45:45,606] {dagrun.py:605} INFO - DagRun Finished: dag_id=load_dimensions, execution_date=2021-12-31 04:00:00+00:00, run_id=scheduled__2021-12-31T04:00:00+00:00, run_start_date=2022-01-05 18:45:38.288418+00:00, run_end_date=2022-01-05 18:45:45.606770+00:00, run_duration=7.318352, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2021-12-31 04:00:00+00:00, data_interval_end=2021-12-31 05:00:00+00:00, dag_hash=ea59270a290c9c2a836a4c05215d2937
[2022-01-05 18:46:43,954] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [queued]>
[2022-01-05 18:46:44,030] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [queued]>
[2022-01-05 18:46:44,030] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 18:46:44,031] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 18:46:44,031] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 18:46:44,078] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 04:00:00+00:00
[2022-01-05 18:46:44,095] {standard_task_runner.py:52} INFO - Started process 883 to run task
[2022-01-05 18:46:44,117] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T04:00:00+00:00', '--job-id', '411', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmpmkq2aa0l', '--error-file', '/tmp/tmpl8m_u5oi']
[2022-01-05 18:46:44,122] {standard_task_runner.py:77} INFO - Job 411: Subtask tweet_load
[2022-01-05 18:46:44,263] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [running]> on host e544fdb7c66e
[2022-01-05 18:46:44,454] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T04:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T04:00:00+00:00
[2022-01-05 18:46:44,456] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:46:44,457] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:46:44,458] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:46:44,458] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:46:44,458] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:46:44,458] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:46:44,459] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:46:44,459] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:46:44,465] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:46:44,465] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:46:44,465] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:46:44,466] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 18:46:44,466] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7ffaccd8cb10>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 04:00:00+00:00: scheduled__2021-12-31T04:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': DateTime(2021, 12, 31, 2, 0, 0, tzinfo=Timezone('UTC')), 'prev_data_interval_end_success': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'prev_ds': '2021-12-31', 'prev_ds_nodash': '20211231', 'prev_execution_date': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': DateTime(2021, 12, 31, 2, 0, 0, tzinfo=Timezone('UTC')), 'prev_start_date_success': DateTime(2022, 1, 5, 18, 46, 38, 770355, tzinfo=Timezone('UTC')), 'run_id': 'scheduled__2021-12-31T04:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T04:00:00+00:00', 'ts_nodash': '20211231T040000', 'ts_nodash_with_tz': '20211231T040000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T04:00:00+00:00', 'tsnodash_var': '20211231T040000', 'templates_dict': None}
[2022-01-05 18:46:44,466] {logging_mixin.py:109} INFO - Hello, Current Time:18:46:44 Execution time is 2021-12-31T04:00:00+00:00
[2022-01-05 18:46:44,568] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 18:46:44,614] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 18:46:46,859] {python.py:175} INFO - Done. Returned value was: None
[2022-01-05 18:46:46,897] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T040000, start_date=20220105T184643, end_date=20220105T184646
[2022-01-05 18:46:46,961] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-01-05 18:46:47,004] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-01-05 19:23:56,377] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [queued]>
[2022-01-05 19:23:56,402] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [queued]>
[2022-01-05 19:23:56,402] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 19:23:56,402] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 19:23:56,402] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 19:23:56,430] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 04:00:00+00:00
[2022-01-05 19:23:56,440] {standard_task_runner.py:52} INFO - Started process 2682 to run task
[2022-01-05 19:23:56,451] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T04:00:00+00:00', '--job-id', '451', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmp23vw9c5d', '--error-file', '/tmp/tmp4y5j5ne1']
[2022-01-05 19:23:56,453] {standard_task_runner.py:77} INFO - Job 451: Subtask tweet_load
[2022-01-05 19:23:56,593] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [running]> on host e544fdb7c66e
[2022-01-05 19:23:56,736] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T04:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T04:00:00+00:00
[2022-01-05 19:23:56,738] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:23:56,738] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:23:56,738] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:23:56,741] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:23:56,741] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:23:56,742] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:23:56,742] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:23:56,742] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:23:56,742] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:23:56,742] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:23:56,742] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:23:56,742] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:23:56,743] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7ffaccd8cb10>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 04:00:00+00:00: scheduled__2021-12-31T04:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-31', 'prev_ds_nodash': '20211231', 'prev_execution_date': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T04:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T04:00:00+00:00', 'ts_nodash': '20211231T040000', 'ts_nodash_with_tz': '20211231T040000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T04:00:00+00:00', 'tsnodash_var': '20211231T040000', 'templates_dict': None}
[2022-01-05 19:23:56,743] {logging_mixin.py:109} INFO - Hello, Current Time:19:23:56 Execution time is 2021-12-31T04:00:00+00:00
[2022-01-05 19:23:56,772] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 19:23:56,806] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 19:23:59,410] {python.py:175} INFO - Done. Returned value was: None
[2022-01-05 19:23:59,424] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T040000, start_date=20220105T192356, end_date=20220105T192359
[2022-01-05 19:23:59,442] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-01-05 19:23:59,468] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-01-05 19:28:23,637] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [queued]>
[2022-01-05 19:28:23,664] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [queued]>
[2022-01-05 19:28:23,664] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 19:28:23,664] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 19:28:23,664] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 19:28:23,706] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 04:00:00+00:00
[2022-01-05 19:28:23,722] {standard_task_runner.py:52} INFO - Started process 2935 to run task
[2022-01-05 19:28:23,735] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T04:00:00+00:00', '--job-id', '471', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmpo99axhlo', '--error-file', '/tmp/tmp19j1cttk']
[2022-01-05 19:28:23,737] {standard_task_runner.py:77} INFO - Job 471: Subtask tweet_load
[2022-01-05 19:28:23,918] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [running]> on host e544fdb7c66e
[2022-01-05 19:28:24,039] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T04:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T04:00:00+00:00
[2022-01-05 19:28:24,047] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:28:24,047] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:28:24,048] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:28:24,048] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:28:24,048] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:28:24,049] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:28:24,049] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:28:24,049] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:28:24,049] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:28:24,049] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:28:24,049] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:28:24,050] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:28:24,050] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7ffaccd8cb10>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 04:00:00+00:00: scheduled__2021-12-31T04:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': DateTime(2021, 12, 31, 0, 0, 0, tzinfo=Timezone('UTC')), 'prev_data_interval_end_success': DateTime(2021, 12, 31, 1, 0, 0, tzinfo=Timezone('UTC')), 'prev_ds': '2021-12-31', 'prev_ds_nodash': '20211231', 'prev_execution_date': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': DateTime(2021, 12, 31, 0, 0, 0, tzinfo=Timezone('UTC')), 'prev_start_date_success': DateTime(2022, 1, 5, 19, 28, 20, 55248, tzinfo=Timezone('UTC')), 'run_id': 'scheduled__2021-12-31T04:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T04:00:00+00:00', 'ts_nodash': '20211231T040000', 'ts_nodash_with_tz': '20211231T040000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T04:00:00+00:00', 'tsnodash_var': '20211231T040000', 'templates_dict': None}
[2022-01-05 19:28:24,050] {logging_mixin.py:109} INFO - Hello, Current Time:19:28:24 Execution time is 2021-12-31T04:00:00+00:00
[2022-01-05 19:28:24,076] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 19:28:24,090] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 19:28:27,162] {python.py:175} INFO - Done. Returned value was: None
[2022-01-05 19:28:27,180] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T040000, start_date=20220105T192823, end_date=20220105T192827
[2022-01-05 19:28:27,219] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-01-05 19:28:27,261] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-01-05 19:29:19,497] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [queued]>
[2022-01-05 19:29:19,504] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [queued]>
[2022-01-05 19:29:19,504] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 19:29:19,504] {taskinstance.py:1239} INFO - Starting attempt 1 of 1
[2022-01-05 19:29:19,504] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-01-05 19:29:19,514] {taskinstance.py:1259} INFO - Executing <Task(PythonOperator): tweet_load> on 2021-12-31 04:00:00+00:00
[2022-01-05 19:29:19,518] {standard_task_runner.py:52} INFO - Started process 3032 to run task
[2022-01-05 19:29:19,521] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'load_dimensions', 'tweet_load', 'scheduled__2021-12-31T04:00:00+00:00', '--job-id', '492', '--raw', '--subdir', 'DAGS_FOLDER/load_redshift.py', '--cfg-path', '/tmp/tmpyk28n__e', '--error-file', '/tmp/tmpxquoubq4']
[2022-01-05 19:29:19,521] {standard_task_runner.py:77} INFO - Job 492: Subtask tweet_load
[2022-01-05 19:29:19,564] {logging_mixin.py:109} INFO - Running <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [running]> on host e544fdb7c66e
[2022-01-05 19:29:19,605] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=test_owner
AIRFLOW_CTX_DAG_ID=load_dimensions
AIRFLOW_CTX_TASK_ID=tweet_load
AIRFLOW_CTX_EXECUTION_DATE=2021-12-31T04:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2021-12-31T04:00:00+00:00
[2022-01-05 19:29:19,606] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:29:19,606] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:29:19,606] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_ds_nodash' from the template is deprecated and will be removed in a future version. Please use '{{ data_interval_end | ds_nodash }}' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:29:19,606] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'next_execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_end' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:29:19,607] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:29:19,607] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:29:19,607] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:29:19,607] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'prev_execution_date_success' from the template is deprecated and will be removed in a future version. Please use 'prev_data_interval_start_success' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:29:19,607] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:29:19,607] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'tomorrow_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:29:19,607] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:29:19,607] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'yesterday_ds_nodash' from the template is deprecated and will be removed in a future version.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-01-05 19:29:19,607] {logging_mixin.py:109} INFO - {'conf': <***.configuration.AirflowConfigParser object at 0x7ffaccd8cb10>, 'dag': <DAG: load_dimensions>, 'dag_run': <DagRun load_dimensions @ 2021-12-31 04:00:00+00:00: scheduled__2021-12-31T04:00:00+00:00, externally triggered: False>, 'data_interval_end': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'data_interval_start': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'ds': '2021-12-31', 'ds_nodash': '20211231', 'execution_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'inlets': [], 'logical_date': DateTime(2021, 12, 31, 4, 0, 0, tzinfo=Timezone('UTC')), 'macros': <module '***.macros' from '/home/***/.local/lib/python3.7/site-packages/***/macros/__init__.py'>, 'next_ds': '2021-12-31', 'next_ds_nodash': '20211231', 'next_execution_date': DateTime(2021, 12, 31, 5, 0, 0, tzinfo=Timezone('UTC')), 'outlets': [], 'params': {}, 'prev_data_interval_start_success': None, 'prev_data_interval_end_success': None, 'prev_ds': '2021-12-31', 'prev_ds_nodash': '20211231', 'prev_execution_date': DateTime(2021, 12, 31, 3, 0, 0, tzinfo=Timezone('UTC')), 'prev_execution_date_success': None, 'prev_start_date_success': None, 'run_id': 'scheduled__2021-12-31T04:00:00+00:00', 'task': <Task(PythonOperator): tweet_load>, 'task_instance': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [running]>, 'task_instance_key_str': 'load_dimensions__tweet_load__20211231', 'test_mode': False, 'ti': <TaskInstance: load_dimensions.tweet_load scheduled__2021-12-31T04:00:00+00:00 [running]>, 'tomorrow_ds': '2022-01-01', 'tomorrow_ds_nodash': '20220101', 'ts': '2021-12-31T04:00:00+00:00', 'ts_nodash': '20211231T040000', 'ts_nodash_with_tz': '20211231T040000+0000', 'var': {'json': None, 'value': None}, 'conn': None, 'yesterday_ds': '2021-12-30', 'yesterday_ds_nodash': '20211230', 'key': 'value', 'ts_var': '2021-12-31T04:00:00+00:00', 'tsnodash_var': '20211231T040000', 'templates_dict': None}
[2022-01-05 19:29:19,607] {logging_mixin.py:109} INFO - Hello, Current Time:19:29:19 Execution time is 2021-12-31T04:00:00+00:00
[2022-01-05 19:29:19,619] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 19:29:19,624] {base.py:79} INFO - Using connection to: id: redshift. Host: tweet-data.ciyer0z3ifyd.us-east-2.redshift.amazonaws.com, Port: 5439, Schema: tweetdb, Login: awsuser, Password: ***, extra: {}
[2022-01-05 19:29:24,571] {python.py:175} INFO - Done. Returned value was: None
[2022-01-05 19:29:24,581] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=load_dimensions, task_id=tweet_load, execution_date=20211231T040000, start_date=20220105T192919, end_date=20220105T192924
[2022-01-05 19:29:24,611] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-01-05 19:29:24,639] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
